{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 23:53:14,045][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s1a2_s1a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_235315-hsg1m3hk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s1a2_s1a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/hsg1m3hk\u001b[0m\n",
      "[2023-08-08 23:53:20,252][root][INFO] - => Done in 6.206 s\n",
      "[2023-08-08 23:53:20,252][root][INFO] - \n",
      "[2023-08-08 23:53:20,252][root][INFO] - => Env setup ...\n",
      "[2023-08-08 23:53:20,255][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 23:53:20,255][root][INFO] - => Done in 3.267 ms\n",
      "[2023-08-08 23:53:20,255][root][INFO] - \n",
      "[2023-08-08 23:53:20,255][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 23:53:20,868][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 23:53:20,868][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 23:53:20,868][root][INFO] - => Done in 612.879 ms\n",
      "[2023-08-08 23:53:20,868][root][INFO] - \n",
      "[2023-08-08 23:53:20,868][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 23:53:20,869][root][INFO] - => Done in 112.057 us\n",
      "[2023-08-08 23:53:20,869][root][INFO] - \n",
      "[2023-08-08 23:53:20,869][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 23:53:20,869][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 23:53:21,718][root][INFO] - => Done in 849.211 ms\n",
      "[2023-08-08 23:53:21,718][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 1.861 MB of 1.873 MB uploaded (0.676 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01525\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01525\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99239\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s1a2_s1a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/hsg1m3hk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 77 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_235315-hsg1m3hk/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 23:53:56,991][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s1a2_s2a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_235358-q688plg1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s1a2_s2a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/q688plg1\u001b[0m\n",
      "[2023-08-08 23:54:02,937][root][INFO] - => Done in 5.946 s\n",
      "[2023-08-08 23:54:02,938][root][INFO] - \n",
      "[2023-08-08 23:54:02,938][root][INFO] - => Env setup ...\n",
      "[2023-08-08 23:54:02,944][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 23:54:02,945][root][INFO] - => Done in 6.661 ms\n",
      "[2023-08-08 23:54:02,945][root][INFO] - \n",
      "[2023-08-08 23:54:02,945][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 23:54:03,510][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 23:54:03,510][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 23:54:03,510][root][INFO] - => Done in 565.461 ms\n",
      "[2023-08-08 23:54:03,510][root][INFO] - \n",
      "[2023-08-08 23:54:03,510][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 23:54:03,511][root][INFO] - => Done in 144.243 us\n",
      "[2023-08-08 23:54:03,511][root][INFO] - \n",
      "[2023-08-08 23:54:03,511][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 23:54:03,511][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 23:54:04,286][root][INFO] - => Done in 775.650 ms\n",
      "[2023-08-08 23:54:04,287][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.967 MB of 0.967 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01524\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01525\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99238\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1979.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s1a2_s2a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/q688plg1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_235358-q688plg1/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 23:54:38,345][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s1a2_s3a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_235439-irl1tlit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s1a2_s3a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/irl1tlit\u001b[0m\n",
      "[2023-08-08 23:54:43,667][root][INFO] - => Done in 5.322 s\n",
      "[2023-08-08 23:54:43,668][root][INFO] - \n",
      "[2023-08-08 23:54:43,668][root][INFO] - => Env setup ...\n",
      "[2023-08-08 23:54:43,671][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 23:54:43,671][root][INFO] - => Done in 3.283 ms\n",
      "[2023-08-08 23:54:43,671][root][INFO] - \n",
      "[2023-08-08 23:54:43,671][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 23:54:44,224][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 23:54:44,224][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 23:54:44,224][root][INFO] - => Done in 552.874 ms\n",
      "[2023-08-08 23:54:44,224][root][INFO] - \n",
      "[2023-08-08 23:54:44,224][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 23:54:44,224][root][INFO] - => Done in 115.156 us\n",
      "[2023-08-08 23:54:44,224][root][INFO] - \n",
      "[2023-08-08 23:54:44,224][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 23:54:44,224][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 23:54:44,988][root][INFO] - => Done in 763.787 ms\n",
      "[2023-08-08 23:54:44,988][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01537\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01519\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.9925\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1979.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s1a2_s3a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/irl1tlit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_235439-irl1tlit/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 23:55:19,291][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s1a2_s4a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_235520-z6fdh0ko\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s1a2_s4a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/z6fdh0ko\u001b[0m\n",
      "[2023-08-08 23:55:25,005][root][INFO] - => Done in 5.715 s\n",
      "[2023-08-08 23:55:25,006][root][INFO] - \n",
      "[2023-08-08 23:55:25,006][root][INFO] - => Env setup ...\n",
      "[2023-08-08 23:55:25,010][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 23:55:25,010][root][INFO] - => Done in 4.494 ms\n",
      "[2023-08-08 23:55:25,010][root][INFO] - \n",
      "[2023-08-08 23:55:25,010][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 23:55:25,568][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 23:55:25,568][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 23:55:25,569][root][INFO] - => Done in 558.234 ms\n",
      "[2023-08-08 23:55:25,569][root][INFO] - \n",
      "[2023-08-08 23:55:25,569][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 23:55:25,569][root][INFO] - => Done in 107.050 us\n",
      "[2023-08-08 23:55:25,569][root][INFO] - \n",
      "[2023-08-08 23:55:25,569][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 23:55:25,569][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 23:55:26,332][root][INFO] - => Done in 762.997 ms\n",
      "[2023-08-08 23:55:26,332][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01555\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01524\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99254\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s1a2_s4a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/z6fdh0ko\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_235520-z6fdh0ko/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 23:56:01,176][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s1a2_s5a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_235602-fno6rhes\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s1a2_s5a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/fno6rhes\u001b[0m\n",
      "[2023-08-08 23:56:07,151][root][INFO] - => Done in 5.975 s\n",
      "[2023-08-08 23:56:07,151][root][INFO] - \n",
      "[2023-08-08 23:56:07,151][root][INFO] - => Env setup ...\n",
      "[2023-08-08 23:56:07,158][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 23:56:07,158][root][INFO] - => Done in 6.556 ms\n",
      "[2023-08-08 23:56:07,158][root][INFO] - \n",
      "[2023-08-08 23:56:07,158][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 23:56:07,724][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 23:56:07,724][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 23:56:07,725][root][INFO] - => Done in 566.567 ms\n",
      "[2023-08-08 23:56:07,725][root][INFO] - \n",
      "[2023-08-08 23:56:07,725][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 23:56:07,725][root][INFO] - => Done in 159.979 us\n",
      "[2023-08-08 23:56:07,725][root][INFO] - \n",
      "[2023-08-08 23:56:07,725][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 23:56:07,725][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 23:56:08,485][root][INFO] - => Done in 760.429 ms\n",
      "[2023-08-08 23:56:08,486][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 0.958 MB of 0.970 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01541\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01522\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.9925\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1979.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s1a2_s5a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/fno6rhes\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_235602-fno6rhes/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 23:56:42,197][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s2a2_s1a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_235643-51j4fbb0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s2a2_s1a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/51j4fbb0\u001b[0m\n",
      "[2023-08-08 23:56:48,694][root][INFO] - => Done in 6.496 s\n",
      "[2023-08-08 23:56:48,694][root][INFO] - \n",
      "[2023-08-08 23:56:48,694][root][INFO] - => Env setup ...\n",
      "[2023-08-08 23:56:48,697][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 23:56:48,697][root][INFO] - => Done in 3.130 ms\n",
      "[2023-08-08 23:56:48,697][root][INFO] - \n",
      "[2023-08-08 23:56:48,697][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 23:56:49,279][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 23:56:49,279][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 23:56:49,279][root][INFO] - => Done in 582.045 ms\n",
      "[2023-08-08 23:56:49,279][root][INFO] - \n",
      "[2023-08-08 23:56:49,279][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 23:56:49,279][root][INFO] - => Done in 113.964 us\n",
      "[2023-08-08 23:56:49,279][root][INFO] - \n",
      "[2023-08-08 23:56:49,280][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 23:56:49,280][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 23:56:50,040][root][INFO] - => Done in 760.174 ms\n",
      "[2023-08-08 23:56:50,040][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01525\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01525\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99239\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s2a2_s1a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/51j4fbb0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_235643-51j4fbb0/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 23:57:24,903][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s2a2_s2a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_235725-8hefgpwp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s2a2_s2a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/8hefgpwp\u001b[0m\n",
      "[2023-08-08 23:57:29,664][root][INFO] - => Done in 4.761 s\n",
      "[2023-08-08 23:57:29,664][root][INFO] - \n",
      "[2023-08-08 23:57:29,664][root][INFO] - => Env setup ...\n",
      "[2023-08-08 23:57:29,668][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 23:57:29,668][root][INFO] - => Done in 3.303 ms\n",
      "[2023-08-08 23:57:29,668][root][INFO] - \n",
      "[2023-08-08 23:57:29,668][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 23:57:30,256][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 23:57:30,256][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 23:57:30,256][root][INFO] - => Done in 587.932 ms\n",
      "[2023-08-08 23:57:30,256][root][INFO] - \n",
      "[2023-08-08 23:57:30,256][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 23:57:30,256][root][INFO] - => Done in 113.726 us\n",
      "[2023-08-08 23:57:30,256][root][INFO] - \n",
      "[2023-08-08 23:57:30,256][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 23:57:30,256][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 23:57:31,024][root][INFO] - => Done in 768.212 ms\n",
      "[2023-08-08 23:57:31,025][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01524\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01526\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99238\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1979.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s2a2_s2a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/8hefgpwp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_235725-8hefgpwp/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 23:58:05,344][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s2a2_s3a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_235806-p0uqkfpg\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s2a2_s3a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/p0uqkfpg\u001b[0m\n",
      "[2023-08-08 23:58:10,560][root][INFO] - => Done in 5.216 s\n",
      "[2023-08-08 23:58:10,560][root][INFO] - \n",
      "[2023-08-08 23:58:10,560][root][INFO] - => Env setup ...\n",
      "[2023-08-08 23:58:10,564][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 23:58:10,564][root][INFO] - => Done in 3.246 ms\n",
      "[2023-08-08 23:58:10,564][root][INFO] - \n",
      "[2023-08-08 23:58:10,564][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 23:58:11,149][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 23:58:11,149][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 23:58:11,149][root][INFO] - => Done in 585.385 ms\n",
      "[2023-08-08 23:58:11,149][root][INFO] - \n",
      "[2023-08-08 23:58:11,149][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 23:58:11,149][root][INFO] - => Done in 113.726 us\n",
      "[2023-08-08 23:58:11,149][root][INFO] - \n",
      "[2023-08-08 23:58:11,149][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 23:58:11,150][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 23:58:11,916][root][INFO] - => Done in 766.089 ms\n",
      "[2023-08-08 23:58:11,916][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01537\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01519\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.9925\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1979.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s2a2_s3a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/p0uqkfpg\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_235806-p0uqkfpg/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 23:58:47,164][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s2a2_s4a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_235848-mpo32q4j\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s2a2_s4a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/mpo32q4j\u001b[0m\n",
      "[2023-08-08 23:58:52,634][root][INFO] - => Done in 5.471 s\n",
      "[2023-08-08 23:58:52,635][root][INFO] - \n",
      "[2023-08-08 23:58:52,635][root][INFO] - => Env setup ...\n",
      "[2023-08-08 23:58:52,639][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 23:58:52,639][root][INFO] - => Done in 3.973 ms\n",
      "[2023-08-08 23:58:52,639][root][INFO] - \n",
      "[2023-08-08 23:58:52,639][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 23:58:53,201][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 23:58:53,201][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 23:58:53,201][root][INFO] - => Done in 562.302 ms\n",
      "[2023-08-08 23:58:53,201][root][INFO] - \n",
      "[2023-08-08 23:58:53,201][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 23:58:53,201][root][INFO] - => Done in 110.865 us\n",
      "[2023-08-08 23:58:53,201][root][INFO] - \n",
      "[2023-08-08 23:58:53,201][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 23:58:53,201][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 23:58:53,961][root][INFO] - => Done in 759.319 ms\n",
      "[2023-08-08 23:58:53,961][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01554\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01524\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99255\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s2a2_s4a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/mpo32q4j\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_235848-mpo32q4j/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 23:59:29,078][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s2a2_s5a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_235930-eoxkii3m\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s2a2_s5a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/eoxkii3m\u001b[0m\n",
      "[2023-08-08 23:59:33,980][root][INFO] - => Done in 4.902 s\n",
      "[2023-08-08 23:59:33,980][root][INFO] - \n",
      "[2023-08-08 23:59:33,980][root][INFO] - => Env setup ...\n",
      "[2023-08-08 23:59:33,983][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 23:59:33,983][root][INFO] - => Done in 2.993 ms\n",
      "[2023-08-08 23:59:33,983][root][INFO] - \n",
      "[2023-08-08 23:59:33,984][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 23:59:34,553][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 23:59:34,553][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 23:59:34,553][root][INFO] - => Done in 569.586 ms\n",
      "[2023-08-08 23:59:34,553][root][INFO] - \n",
      "[2023-08-08 23:59:34,553][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 23:59:34,553][root][INFO] - => Done in 108.719 us\n",
      "[2023-08-08 23:59:34,553][root][INFO] - \n",
      "[2023-08-08 23:59:34,553][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 23:59:34,554][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 23:59:35,308][root][INFO] - => Done in 754.110 ms\n",
      "[2023-08-08 23:59:35,308][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01541\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01522\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.9925\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1979.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s2a2_s5a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/eoxkii3m\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_235930-eoxkii3m/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:00:09,730][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s3a1_s1a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_000010-gy4f6f68\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s3a1_s1a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/gy4f6f68\u001b[0m\n",
      "[2023-08-09 00:00:15,361][root][INFO] - => Done in 5.631 s\n",
      "[2023-08-09 00:00:15,361][root][INFO] - \n",
      "[2023-08-09 00:00:15,361][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:00:15,365][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:00:15,365][root][INFO] - => Done in 3.970 ms\n",
      "[2023-08-09 00:00:15,365][root][INFO] - \n",
      "[2023-08-09 00:00:15,365][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:00:15,922][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:00:15,922][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:00:15,922][root][INFO] - => Done in 556.851 ms\n",
      "[2023-08-09 00:00:15,922][root][INFO] - \n",
      "[2023-08-09 00:00:15,922][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:00:15,922][root][INFO] - => Done in 114.918 us\n",
      "[2023-08-09 00:00:15,922][root][INFO] - \n",
      "[2023-08-09 00:00:15,922][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:00:15,922][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:00:16,688][root][INFO] - => Done in 765.767 ms\n",
      "[2023-08-09 00:00:16,688][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01527\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01543\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99246\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s3a1_s1a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/gy4f6f68\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_000010-gy4f6f68/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:00:50,325][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s3a1_s2a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_000051-pvv4cx2t\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s3a1_s2a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/pvv4cx2t\u001b[0m\n",
      "[2023-08-09 00:00:55,003][root][INFO] - => Done in 4.678 s\n",
      "[2023-08-09 00:00:55,003][root][INFO] - \n",
      "[2023-08-09 00:00:55,003][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:00:55,009][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:00:55,009][root][INFO] - => Done in 6.148 ms\n",
      "[2023-08-09 00:00:55,009][root][INFO] - \n",
      "[2023-08-09 00:00:55,009][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:00:55,602][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:00:55,602][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:00:55,602][root][INFO] - => Done in 592.999 ms\n",
      "[2023-08-09 00:00:55,603][root][INFO] - \n",
      "[2023-08-09 00:00:55,603][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:00:55,603][root][INFO] - => Done in 117.064 us\n",
      "[2023-08-09 00:00:55,603][root][INFO] - \n",
      "[2023-08-09 00:00:55,603][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:00:55,603][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:00:56,375][root][INFO] - => Done in 772.585 ms\n",
      "[2023-08-09 00:00:56,376][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01524\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01542\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99246\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1979.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s3a1_s2a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/pvv4cx2t\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_000051-pvv4cx2t/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:01:30,166][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s3a1_s3a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_000131-uavrl40z\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s3a1_s3a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/uavrl40z\u001b[0m\n",
      "[2023-08-09 00:01:34,833][root][INFO] - => Done in 4.666 s\n",
      "[2023-08-09 00:01:34,833][root][INFO] - \n",
      "[2023-08-09 00:01:34,833][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:01:34,837][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:01:34,837][root][INFO] - => Done in 3.836 ms\n",
      "[2023-08-09 00:01:34,837][root][INFO] - \n",
      "[2023-08-09 00:01:34,837][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:01:35,432][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:01:35,433][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:01:35,433][root][INFO] - => Done in 595.459 ms\n",
      "[2023-08-09 00:01:35,433][root][INFO] - \n",
      "[2023-08-09 00:01:35,433][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:01:35,433][root][INFO] - => Done in 127.077 us\n",
      "[2023-08-09 00:01:35,433][root][INFO] - \n",
      "[2023-08-09 00:01:35,433][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:01:35,433][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:01:36,199][root][INFO] - => Done in 765.906 ms\n",
      "[2023-08-09 00:01:36,199][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01539\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01538\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99257\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s3a1_s3a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/uavrl40z\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_000131-uavrl40z/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:02:09,863][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s3a1_s4a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_000210-0hosnmze\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s3a1_s4a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/0hosnmze\u001b[0m\n",
      "[2023-08-09 00:02:14,727][root][INFO] - => Done in 4.864 s\n",
      "[2023-08-09 00:02:14,727][root][INFO] - \n",
      "[2023-08-09 00:02:14,727][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:02:14,730][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:02:14,730][root][INFO] - => Done in 2.936 ms\n",
      "[2023-08-09 00:02:14,730][root][INFO] - \n",
      "[2023-08-09 00:02:14,730][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:02:15,305][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:02:15,305][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:02:15,305][root][INFO] - => Done in 574.728 ms\n",
      "[2023-08-09 00:02:15,305][root][INFO] - \n",
      "[2023-08-09 00:02:15,305][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:02:15,305][root][INFO] - => Done in 108.004 us\n",
      "[2023-08-09 00:02:15,305][root][INFO] - \n",
      "[2023-08-09 00:02:15,305][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:02:15,305][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:02:16,066][root][INFO] - => Done in 760.749 ms\n",
      "[2023-08-09 00:02:16,066][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.980 MB of 0.980 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01553\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01539\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99264\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1979.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s3a1_s4a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/0hosnmze\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_000210-0hosnmze/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:02:50,097][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s3a1_s5a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_000251-fc8ztqls\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s3a1_s5a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/fc8ztqls\u001b[0m\n",
      "[2023-08-09 00:02:55,017][root][INFO] - => Done in 4.919 s\n",
      "[2023-08-09 00:02:55,017][root][INFO] - \n",
      "[2023-08-09 00:02:55,017][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:02:55,020][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:02:55,020][root][INFO] - => Done in 3.466 ms\n",
      "[2023-08-09 00:02:55,021][root][INFO] - \n",
      "[2023-08-09 00:02:55,021][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:02:55,579][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:02:55,580][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:02:55,580][root][INFO] - => Done in 559.068 ms\n",
      "[2023-08-09 00:02:55,580][root][INFO] - \n",
      "[2023-08-09 00:02:55,580][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:02:55,580][root][INFO] - => Done in 226.021 us\n",
      "[2023-08-09 00:02:55,580][root][INFO] - \n",
      "[2023-08-09 00:02:55,580][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:02:55,580][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:02:56,339][root][INFO] - => Done in 758.352 ms\n",
      "[2023-08-09 00:02:56,339][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01541\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01538\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99258\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1979.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s3a1_s5a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/fc8ztqls\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_000251-fc8ztqls/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:03:31,771][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s4a2_s1a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_000332-fhlvlc33\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s4a2_s1a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/fhlvlc33\u001b[0m\n",
      "[2023-08-09 00:03:36,939][root][INFO] - => Done in 5.168 s\n",
      "[2023-08-09 00:03:36,939][root][INFO] - \n",
      "[2023-08-09 00:03:36,939][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:03:36,942][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:03:36,942][root][INFO] - => Done in 3.065 ms\n",
      "[2023-08-09 00:03:36,942][root][INFO] - \n",
      "[2023-08-09 00:03:36,942][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:03:37,506][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:03:37,507][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:03:37,507][root][INFO] - => Done in 564.336 ms\n",
      "[2023-08-09 00:03:37,507][root][INFO] - \n",
      "[2023-08-09 00:03:37,507][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:03:37,507][root][INFO] - => Done in 126.839 us\n",
      "[2023-08-09 00:03:37,507][root][INFO] - \n",
      "[2023-08-09 00:03:37,507][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:03:37,507][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:03:38,268][root][INFO] - => Done in 760.777 ms\n",
      "[2023-08-09 00:03:38,268][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.0152\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01554\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99259\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s4a2_s1a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/fhlvlc33\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_000332-fhlvlc33/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:04:13,243][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s4a2_s2a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_000414-wg6wx480\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s4a2_s2a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/wg6wx480\u001b[0m\n",
      "[2023-08-09 00:04:19,161][root][INFO] - => Done in 5.919 s\n",
      "[2023-08-09 00:04:19,162][root][INFO] - \n",
      "[2023-08-09 00:04:19,162][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:04:19,166][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:04:19,166][root][INFO] - => Done in 4.498 ms\n",
      "[2023-08-09 00:04:19,166][root][INFO] - \n",
      "[2023-08-09 00:04:19,166][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:04:19,725][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:04:19,725][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:04:19,725][root][INFO] - => Done in 558.555 ms\n",
      "[2023-08-09 00:04:19,725][root][INFO] - \n",
      "[2023-08-09 00:04:19,725][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:04:19,725][root][INFO] - => Done in 112.057 us\n",
      "[2023-08-09 00:04:19,725][root][INFO] - \n",
      "[2023-08-09 00:04:19,725][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:04:19,725][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:04:20,482][root][INFO] - => Done in 756.622 ms\n",
      "[2023-08-09 00:04:20,482][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01516\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01553\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99259\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s4a2_s2a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/wg6wx480\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_000414-wg6wx480/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:04:53,839][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s4a2_s3a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_000454-2g9csih9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s4a2_s3a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/2g9csih9\u001b[0m\n",
      "[2023-08-09 00:04:58,954][root][INFO] - => Done in 5.115 s\n",
      "[2023-08-09 00:04:58,954][root][INFO] - \n",
      "[2023-08-09 00:04:58,954][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:04:58,958][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:04:58,958][root][INFO] - => Done in 3.436 ms\n",
      "[2023-08-09 00:04:58,958][root][INFO] - \n",
      "[2023-08-09 00:04:58,958][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:04:59,510][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:04:59,511][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:04:59,511][root][INFO] - => Done in 552.954 ms\n",
      "[2023-08-09 00:04:59,511][root][INFO] - \n",
      "[2023-08-09 00:04:59,511][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:04:59,511][root][INFO] - => Done in 107.765 us\n",
      "[2023-08-09 00:04:59,511][root][INFO] - \n",
      "[2023-08-09 00:04:59,511][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:04:59,511][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:05:00,272][root][INFO] - => Done in 760.555 ms\n",
      "[2023-08-09 00:05:00,272][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01531\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01549\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99271\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1979.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s4a2_s3a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/2g9csih9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_000454-2g9csih9/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:05:37,232][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s4a2_s4a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_000538-paplfgpi\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s4a2_s4a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/paplfgpi\u001b[0m\n",
      "[2023-08-09 00:05:44,757][root][INFO] - => Done in 7.525 s\n",
      "[2023-08-09 00:05:44,757][root][INFO] - \n",
      "[2023-08-09 00:05:44,757][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:05:44,761][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:05:44,761][root][INFO] - => Done in 3.513 ms\n",
      "[2023-08-09 00:05:44,761][root][INFO] - \n",
      "[2023-08-09 00:05:44,761][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:05:45,346][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:05:45,347][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:05:45,347][root][INFO] - => Done in 585.909 ms\n",
      "[2023-08-09 00:05:45,347][root][INFO] - \n",
      "[2023-08-09 00:05:45,347][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:05:45,347][root][INFO] - => Done in 132.084 us\n",
      "[2023-08-09 00:05:45,347][root][INFO] - \n",
      "[2023-08-09 00:05:45,347][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:05:45,347][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:05:46,109][root][INFO] - => Done in 762.305 ms\n",
      "[2023-08-09 00:05:46,110][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: | 0.982 MB of 0.986 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01548\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01552\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99275\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.989\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1978.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.989\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1978\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s4a2_s4a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/paplfgpi\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_000538-paplfgpi/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:06:23,433][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s4a2_s5a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_000624-04vxk8w8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s4a2_s5a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/04vxk8w8\u001b[0m\n",
      "[2023-08-09 00:06:29,151][root][INFO] - => Done in 5.718 s\n",
      "[2023-08-09 00:06:29,151][root][INFO] - \n",
      "[2023-08-09 00:06:29,152][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:06:29,158][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:06:29,158][root][INFO] - => Done in 6.242 ms\n",
      "[2023-08-09 00:06:29,158][root][INFO] - \n",
      "[2023-08-09 00:06:29,158][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:06:29,725][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:06:29,725][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:06:29,725][root][INFO] - => Done in 566.922 ms\n",
      "[2023-08-09 00:06:29,725][root][INFO] - \n",
      "[2023-08-09 00:06:29,725][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:06:29,725][root][INFO] - => Done in 111.818 us\n",
      "[2023-08-09 00:06:29,725][root][INFO] - \n",
      "[2023-08-09 00:06:29,725][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:06:29,725][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:06:30,546][root][INFO] - => Done in 820.869 ms\n",
      "[2023-08-09 00:06:30,546][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 0.975 MB of 0.987 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01531\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01547\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99272\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.998\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.998\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.988\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 4.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1976.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.988\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1976\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s4a2_s5a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/04vxk8w8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_000624-04vxk8w8/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:07:07,169][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s5a1_s1a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_000708-asu0u44e\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s5a1_s1a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/asu0u44e\u001b[0m\n",
      "[2023-08-09 00:07:12,300][root][INFO] - => Done in 5.130 s\n",
      "[2023-08-09 00:07:12,300][root][INFO] - \n",
      "[2023-08-09 00:07:12,300][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:07:12,303][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:07:12,303][root][INFO] - => Done in 3.282 ms\n",
      "[2023-08-09 00:07:12,303][root][INFO] - \n",
      "[2023-08-09 00:07:12,303][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:07:12,866][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:07:12,866][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:07:12,866][root][INFO] - => Done in 563.253 ms\n",
      "[2023-08-09 00:07:12,867][root][INFO] - \n",
      "[2023-08-09 00:07:12,867][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:07:12,867][root][INFO] - => Done in 110.149 us\n",
      "[2023-08-09 00:07:12,867][root][INFO] - \n",
      "[2023-08-09 00:07:12,867][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:07:12,867][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:07:13,643][root][INFO] - => Done in 775.800 ms\n",
      "[2023-08-09 00:07:13,643][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01527\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01562\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1979.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s5a1_s1a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/asu0u44e\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_000708-asu0u44e/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:07:48,009][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s5a1_s2a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_000749-pk9jsel6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s5a1_s2a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/pk9jsel6\u001b[0m\n",
      "[2023-08-09 00:07:54,192][root][INFO] - => Done in 6.183 s\n",
      "[2023-08-09 00:07:54,193][root][INFO] - \n",
      "[2023-08-09 00:07:54,193][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:07:54,196][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:07:54,196][root][INFO] - => Done in 3.179 ms\n",
      "[2023-08-09 00:07:54,196][root][INFO] - \n",
      "[2023-08-09 00:07:54,196][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:07:54,785][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:07:54,785][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:07:54,785][root][INFO] - => Done in 589.446 ms\n",
      "[2023-08-09 00:07:54,785][root][INFO] - \n",
      "[2023-08-09 00:07:54,786][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:07:54,786][root][INFO] - => Done in 106.096 us\n",
      "[2023-08-09 00:07:54,786][root][INFO] - \n",
      "[2023-08-09 00:07:54,786][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:07:54,786][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:07:55,587][root][INFO] - => Done in 801.170 ms\n",
      "[2023-08-09 00:07:55,587][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 0.977 MB of 0.989 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.0152\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01557\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99258\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s5a1_s2a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/pk9jsel6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_000749-pk9jsel6/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:08:29,978][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s5a1_s3a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_000831-4k9m8i4k\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s5a1_s3a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/4k9m8i4k\u001b[0m\n",
      "[2023-08-09 00:08:34,969][root][INFO] - => Done in 4.991 s\n",
      "[2023-08-09 00:08:34,969][root][INFO] - \n",
      "[2023-08-09 00:08:34,969][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:08:34,973][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:08:34,973][root][INFO] - => Done in 3.600 ms\n",
      "[2023-08-09 00:08:34,973][root][INFO] - \n",
      "[2023-08-09 00:08:34,973][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:08:35,557][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:08:35,557][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:08:35,557][root][INFO] - => Done in 584.324 ms\n",
      "[2023-08-09 00:08:35,557][root][INFO] - \n",
      "[2023-08-09 00:08:35,558][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:08:35,558][root][INFO] - => Done in 111.103 us\n",
      "[2023-08-09 00:08:35,558][root][INFO] - \n",
      "[2023-08-09 00:08:35,558][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:08:35,558][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:08:36,321][root][INFO] - => Done in 762.914 ms\n",
      "[2023-08-09 00:08:36,321][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01534\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01553\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99269\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.989\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1978.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.989\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1978\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s5a1_s3a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/4k9m8i4k\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_000831-4k9m8i4k/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:09:10,590][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s5a1_s4a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_000911-26w5vwt9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s5a1_s4a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/26w5vwt9\u001b[0m\n",
      "[2023-08-09 00:09:15,534][root][INFO] - => Done in 4.944 s\n",
      "[2023-08-09 00:09:15,535][root][INFO] - \n",
      "[2023-08-09 00:09:15,535][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:09:15,538][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:09:15,538][root][INFO] - => Done in 3.147 ms\n",
      "[2023-08-09 00:09:15,538][root][INFO] - \n",
      "[2023-08-09 00:09:15,538][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:09:16,112][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:09:16,112][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:09:16,112][root][INFO] - => Done in 573.985 ms\n",
      "[2023-08-09 00:09:16,112][root][INFO] - \n",
      "[2023-08-09 00:09:16,112][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:09:16,112][root][INFO] - => Done in 130.892 us\n",
      "[2023-08-09 00:09:16,112][root][INFO] - \n",
      "[2023-08-09 00:09:16,112][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:09:16,112][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:09:16,871][root][INFO] - => Done in 759.145 ms\n",
      "[2023-08-09 00:09:16,872][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01546\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01551\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99277\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s5a1_s4a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/26w5vwt9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_000911-26w5vwt9/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:09:50,889][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s5a1_s5a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_000952-sgmofyp9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s5a1_s5a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/sgmofyp9\u001b[0m\n",
      "[2023-08-09 00:09:55,433][root][INFO] - => Done in 4.544 s\n",
      "[2023-08-09 00:09:55,433][root][INFO] - \n",
      "[2023-08-09 00:09:55,433][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:09:55,436][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:09:55,436][root][INFO] - => Done in 3.501 ms\n",
      "[2023-08-09 00:09:55,436][root][INFO] - \n",
      "[2023-08-09 00:09:55,436][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:09:56,033][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:09:56,033][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:09:56,033][root][INFO] - => Done in 596.750 ms\n",
      "[2023-08-09 00:09:56,033][root][INFO] - \n",
      "[2023-08-09 00:09:56,033][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:09:56,034][root][INFO] - => Done in 186.920 us\n",
      "[2023-08-09 00:09:56,034][root][INFO] - \n",
      "[2023-08-09 00:09:56,034][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:09:56,034][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:09:56,801][root][INFO] - => Done in 767.300 ms\n",
      "[2023-08-09 00:09:56,801][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01536\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01553\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.9927\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1979.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s5a1_s5a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/sgmofyp9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_000952-sgmofyp9/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:10:31,294][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s1a1_s1a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_001032-n2xneidy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s1a1_s1a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/n2xneidy\u001b[0m\n",
      "[2023-08-09 00:10:36,290][root][INFO] - => Done in 4.996 s\n",
      "[2023-08-09 00:10:36,290][root][INFO] - \n",
      "[2023-08-09 00:10:36,290][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:10:36,293][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:10:36,294][root][INFO] - => Done in 3.179 ms\n",
      "[2023-08-09 00:10:36,294][root][INFO] - \n",
      "[2023-08-09 00:10:36,294][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:10:36,867][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:10:36,867][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:10:36,868][root][INFO] - => Done in 573.817 ms\n",
      "[2023-08-09 00:10:36,868][root][INFO] - \n",
      "[2023-08-09 00:10:36,868][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:10:36,868][root][INFO] - => Done in 256.062 us\n",
      "[2023-08-09 00:10:36,868][root][INFO] - \n",
      "[2023-08-09 00:10:36,868][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:10:36,868][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:10:37,624][root][INFO] - => Done in 755.813 ms\n",
      "[2023-08-09 00:10:37,624][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 0.993 MB of 0.993 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–„â–…â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–ˆâ–†â–†â–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–â–â–‚â–â–â–‚â–â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–â–ƒâ–â–â–‚â–‚â–â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–…â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–ˆâ–†â–†â–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–â–â–‚â–â–â–‚â–â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–â–ƒâ–â–â–‚â–‚â–â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–†â–ˆâ–‡â–†â–„â–‡â–‡â–†â–…â–…â–†â–…â–…â–…â–…â–†â–†â–…â–…â–…â–†â–†â–†â–…â–†â–†â–…â–…â–†â–…â–…â–‡â–…â–…â–†â–†â–…â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–ˆâ–…â–„â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–„â–„â–…â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–†â–ˆâ–‡â–†â–„â–‡â–‡â–†â–…â–…â–†â–…â–…â–…â–…â–†â–†â–…â–…â–…â–†â–†â–†â–…â–†â–†â–…â–…â–†â–…â–…â–‡â–…â–…â–†â–†â–…â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–ˆâ–…â–„â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–„â–„â–…â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–†â–ˆâ–‡â–†â–„â–‡â–‡â–†â–…â–…â–†â–…â–…â–…â–…â–†â–†â–…â–…â–…â–†â–†â–†â–…â–†â–†â–…â–…â–†â–…â–…â–‡â–…â–…â–†â–†â–…â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–ˆâ–…â–„â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–„â–„â–…â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–†â–ˆâ–‡â–†â–„â–‡â–‡â–†â–…â–…â–†â–…â–…â–…â–…â–†â–†â–…â–…â–…â–†â–†â–†â–…â–†â–†â–…â–…â–†â–…â–…â–‡â–…â–…â–†â–†â–…â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–ˆâ–…â–„â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–„â–„â–…â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.24133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 2.70807\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 3.42518\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.50463\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 2.721\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 3.483\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.52\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.52\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.2525\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.7255\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0105\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 505.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 3.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1451.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 21.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.2525\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.7255\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0105\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 505\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1451\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s1a1_s1a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/n2xneidy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_001032-n2xneidy/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:11:13,072][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s1a1_s2a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_001114-nxig5gtq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s1a1_s2a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/nxig5gtq\u001b[0m\n",
      "[2023-08-09 00:11:17,782][root][INFO] - => Done in 4.710 s\n",
      "[2023-08-09 00:11:17,783][root][INFO] - \n",
      "[2023-08-09 00:11:17,783][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:11:17,786][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:11:17,786][root][INFO] - => Done in 3.419 ms\n",
      "[2023-08-09 00:11:17,786][root][INFO] - \n",
      "[2023-08-09 00:11:17,786][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:11:18,377][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:11:18,377][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:11:18,377][root][INFO] - => Done in 590.402 ms\n",
      "[2023-08-09 00:11:18,377][root][INFO] - \n",
      "[2023-08-09 00:11:18,377][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:11:18,377][root][INFO] - => Done in 101.805 us\n",
      "[2023-08-09 00:11:18,377][root][INFO] - \n",
      "[2023-08-09 00:11:18,377][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:11:18,377][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:11:19,145][root][INFO] - => Done in 767.417 ms\n",
      "[2023-08-09 00:11:19,145][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–„â–…â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–…â–†â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–ˆâ–†â–…â–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–‚â–â–â–‚â–â–‚â–‚â–â–â–â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–â–‚â–â–â–‚â–‚â–â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–…â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–ˆâ–†â–…â–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–‚â–â–â–‚â–â–‚â–‚â–â–â–â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–â–‚â–â–â–‚â–‚â–â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–†â–…â–„â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–‡â–‡â–ˆâ–…â–‡â–‡â–†â–†â–…â–…â–†â–…â–…â–†â–…â–†â–†â–…â–…â–…â–†â–†â–†â–„â–†â–†â–†â–…â–†â–†â–…â–ˆâ–…â–…â–‡â–‡â–„â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–ˆâ–…â–„â–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–ˆâ–‡â–…â–„â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–ƒâ–„â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–†â–…â–„â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–‡â–‡â–ˆâ–…â–‡â–‡â–†â–†â–…â–…â–†â–…â–…â–†â–…â–†â–†â–…â–…â–…â–†â–†â–†â–„â–†â–†â–†â–…â–†â–†â–…â–ˆâ–…â–…â–‡â–‡â–„â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–ˆâ–…â–„â–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–ˆâ–‡â–…â–„â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–ƒâ–„â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–†â–…â–„â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–ˆâ–„â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–‡â–‡â–ˆâ–†â–‡â–‡â–‡â–†â–†â–…â–†â–†â–†â–†â–…â–†â–†â–†â–…â–…â–†â–‡â–‡â–…â–‡â–†â–†â–†â–†â–†â–†â–ˆâ–…â–…â–‡â–‡â–…â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–ˆâ–…â–„â–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–ˆâ–‡â–…â–„â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–„â–„â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–†â–…â–„â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–ˆâ–„â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–‡â–‡â–ˆâ–†â–‡â–‡â–‡â–†â–†â–…â–†â–†â–†â–†â–…â–†â–†â–†â–…â–…â–†â–‡â–‡â–…â–‡â–†â–†â–†â–†â–†â–†â–ˆâ–…â–…â–‡â–‡â–…â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–ˆâ–…â–„â–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–ˆâ–‡â–…â–„â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–„â–„â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.23783\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 2.71545\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 3.41918\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.51219\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 2.7275\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 3.4745\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.5115\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.5115\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.2485\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.7295\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.011\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 497.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1459.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 22.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.2485\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.7295\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.011\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 497\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1459\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 22\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s1a1_s2a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/nxig5gtq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_001114-nxig5gtq/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:11:53,589][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s1a1_s3a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_001154-6j6449oi\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s1a1_s3a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/6j6449oi\u001b[0m\n",
      "[2023-08-09 00:11:58,357][root][INFO] - => Done in 4.768 s\n",
      "[2023-08-09 00:11:58,357][root][INFO] - \n",
      "[2023-08-09 00:11:58,357][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:11:58,360][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:11:58,361][root][INFO] - => Done in 3.437 ms\n",
      "[2023-08-09 00:11:58,361][root][INFO] - \n",
      "[2023-08-09 00:11:58,361][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:11:58,945][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:11:58,945][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:11:58,945][root][INFO] - => Done in 584.603 ms\n",
      "[2023-08-09 00:11:58,945][root][INFO] - \n",
      "[2023-08-09 00:11:58,945][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:11:58,945][root][INFO] - => Done in 109.673 us\n",
      "[2023-08-09 00:11:58,946][root][INFO] - \n",
      "[2023-08-09 00:11:58,946][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:11:58,946][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:11:59,707][root][INFO] - => Done in 761.618 ms\n",
      "[2023-08-09 00:11:59,707][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 0.995 MB of 0.995 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–ˆâ–‡â–…â–„â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–â–â–â–â–‚â–‚â–‚â–â–â–‚â–‚â–â–â–â–‚â–â–‚â–‚â–â–â–‚â–â–â–‚â–‚â–â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–†â–…â–‡â–†â–†â–†â–…â–†â–…â–…â–†â–…â–…â–…â–„â–…â–…â–„â–†â–„â–†â–…â–…â–…â–…â–†â–…â–„â–†â–†â–…â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–„â–ƒâ–ƒâ–ƒâ–„â–…â–†â–†â–†â–…â–†â–†â–†â–‡â–†â–‡â–‡â–†â–†â–‡â–‡â–ˆâ–‡â–†â–ˆâ–†â–ˆâ–†â–†â–‡â–‡â–‡â–†â–†â–‡â–†â–†â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–ˆâ–ˆâ–‡â–…â–„â–ƒâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–ˆâ–ˆâ–‡â–…â–„â–ƒâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–†â–ˆâ–‡â–„â–ƒâ–â–‚â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–ƒâ–â–‚â–â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–†â–…â–„â–‚â–ƒâ–â–„â–„â–ƒâ–…â–â–„â–ƒâ–„â–…â–ƒâ–…â–…â–„â–„â–…â–…â–‡â–„â–„â–‡â–…â–ˆâ–ƒâ–„â–…â–…â–†â–ƒâ–ƒâ–‡â–„â–ƒâ–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–ƒâ–‡â–ˆâ–ˆâ–ˆâ–‡â–…â–„â–„â–ƒâ–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–„â–ƒâ–‚â–‚â–â–‚â–ƒâ–â–ƒâ–â–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–â–‚â–ƒâ–„â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–†â–ˆâ–‡â–„â–ƒâ–â–‚â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–ƒâ–â–‚â–â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–†â–…â–„â–‚â–ƒâ–â–„â–„â–ƒâ–…â–â–„â–ƒâ–„â–…â–ƒâ–…â–…â–„â–„â–…â–…â–‡â–„â–„â–‡â–…â–ˆâ–ƒâ–„â–…â–…â–†â–ƒâ–ƒâ–‡â–„â–ƒâ–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–ƒâ–‡â–ˆâ–ˆâ–ˆâ–‡â–…â–„â–„â–ƒâ–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–„â–ƒâ–‚â–‚â–â–‚â–ƒâ–â–ƒâ–â–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–â–‚â–ƒâ–„â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–†â–ˆâ–‡â–„â–ƒâ–â–‚â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–ƒâ–â–‚â–â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–‚â–ƒâ–‚â–â–ƒâ–â–„â–„â–ƒâ–…â–â–„â–ƒâ–„â–…â–ƒâ–…â–…â–„â–„â–…â–…â–‡â–„â–„â–‡â–…â–ˆâ–ƒâ–„â–…â–…â–†â–ƒâ–ƒâ–‡â–„â–ƒâ–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–ƒâ–‡â–ˆâ–ˆâ–ˆâ–‡â–…â–„â–„â–ƒâ–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–„â–ƒâ–‚â–‚â–â–‚â–ƒâ–â–ƒâ–â–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–†â–…â–„â–„â–ƒâ–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–â–‚â–„â–„â–†â–†â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–†â–ˆâ–‡â–„â–ƒâ–â–‚â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–ƒâ–â–‚â–â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–‚â–ƒâ–‚â–â–ƒâ–â–„â–„â–ƒâ–…â–â–„â–ƒâ–„â–…â–ƒâ–…â–…â–„â–„â–…â–…â–‡â–„â–„â–‡â–…â–ˆâ–ƒâ–„â–…â–…â–†â–ƒâ–ƒâ–‡â–„â–ƒâ–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–ƒâ–‡â–ˆâ–ˆâ–ˆâ–‡â–…â–„â–„â–ƒâ–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–„â–ƒâ–‚â–‚â–â–‚â–ƒâ–â–ƒâ–â–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–†â–…â–„â–„â–ƒâ–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–â–‚â–„â–„â–†â–†â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.2785\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 3.10511\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 3.12429\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.66923\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 3.159\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 3.117\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.5595\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.138\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.5595\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0205\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.1265\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.7305\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 41.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 224.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 253.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1461.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0205\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.1265\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.7305\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 41\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 224\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 253\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1461\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s1a1_s3a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/6j6449oi\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_001154-6j6449oi/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:12:36,022][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s1a1_s4a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_001237-olpzswu6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s1a1_s4a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/olpzswu6\u001b[0m\n",
      "[2023-08-09 00:12:40,733][root][INFO] - => Done in 4.711 s\n",
      "[2023-08-09 00:12:40,733][root][INFO] - \n",
      "[2023-08-09 00:12:40,734][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:12:40,738][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:12:40,738][root][INFO] - => Done in 4.708 ms\n",
      "[2023-08-09 00:12:40,738][root][INFO] - \n",
      "[2023-08-09 00:12:40,738][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:12:41,351][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:12:41,351][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:12:41,351][root][INFO] - => Done in 612.913 ms\n",
      "[2023-08-09 00:12:41,351][root][INFO] - \n",
      "[2023-08-09 00:12:41,351][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:12:41,352][root][INFO] - => Done in 102.043 us\n",
      "[2023-08-09 00:12:41,352][root][INFO] - \n",
      "[2023-08-09 00:12:41,352][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:12:41,352][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:12:42,119][root][INFO] - => Done in 767.823 ms\n",
      "[2023-08-09 00:12:42,120][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–…â–†â–…â–…â–…â–†â–…â–…â–†â–…â–…â–†â–†â–†â–…â–…â–†â–†â–‡â–†â–…â–†â–†â–‡â–„â–‡â–‡â–†â–†â–†â–‡â–ˆâ–†â–†â–‡â–†â–†â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–†â–†â–†â–‡â–†â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–†â–†â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–†â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–…â–…â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–…â–†â–†â–†â–‡â–‡â–†â–‡â–†â–‡â–…â–‡â–‡â–†â–†â–…â–‡â–ˆâ–‡â–†â–‡â–†â–†â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–…â–…â–„â–…â–„â–…â–…â–…â–…â–…â–…â–„â–…â–…â–ƒâ–„â–…â–…â–†â–…â–„â–†â–„â–†â–‚â–‡â–†â–…â–…â–…â–†â–ˆâ–…â–…â–‡â–…â–…â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–…â–†â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–†â–†â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–†â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–…â–…â–„â–…â–„â–…â–…â–…â–…â–…â–…â–„â–…â–…â–ƒâ–„â–…â–…â–†â–…â–„â–†â–„â–†â–‚â–‡â–†â–…â–…â–…â–†â–ˆâ–…â–…â–‡â–…â–…â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–„â–„â–„â–„â–„â–…â–„â–„â–„â–„â–„â–„â–…â–…â–ƒâ–„â–…â–…â–†â–…â–…â–†â–…â–†â–ƒâ–‡â–†â–…â–…â–…â–†â–ˆâ–…â–…â–‡â–…â–…â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–ˆâ–ˆâ–…â–†â–…â–…â–†â–ˆâ–…â–„â–†â–…â–…â–„â–„â–…â–…â–ƒâ–…â–„â–ƒâ–ƒâ–…â–‚â–†â–ƒâ–…â–…â–ƒâ–ƒâ–ƒâ–„â–…â–…â–…â–…â–„â–†â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–…â–…â–†â–‡â–…â–…â–†â–‡â–‡â–…â–…â–†â–‡â–‡â–…â–„â–„â–…â–…â–„â–ƒâ–ƒâ–„â–…â–„â–…â–…â–…â–‡â–ˆâ–„â–‚â–…â–†â–„â–‡â–…â–„â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–‡â–…â–„â–†â–…â–†â–…â–…â–„â–…â–…â–…â–…â–„â–„â–‡â–†â–…â–…â–ƒâ–„â–†â–„â–…â–ƒâ–ˆâ–‚â–ƒâ–„â–„â–…â–ƒâ–â–„â–„â–‚â–„â–„â–ƒâ–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–„â–„â–„â–„â–„â–…â–„â–„â–„â–„â–„â–„â–…â–…â–ƒâ–„â–…â–…â–†â–…â–…â–†â–…â–†â–ƒâ–‡â–†â–…â–…â–…â–†â–ˆâ–…â–…â–‡â–…â–…â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–ˆâ–ˆâ–…â–†â–…â–…â–†â–ˆâ–…â–„â–†â–…â–…â–„â–„â–…â–…â–ƒâ–…â–„â–ƒâ–ƒâ–…â–‚â–†â–ƒâ–…â–…â–ƒâ–ƒâ–ƒâ–„â–…â–…â–…â–…â–„â–†â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–…â–…â–†â–‡â–…â–…â–†â–‡â–‡â–…â–…â–†â–‡â–‡â–…â–„â–„â–…â–…â–„â–ƒâ–ƒâ–„â–…â–„â–…â–…â–…â–‡â–ˆâ–„â–‚â–…â–†â–„â–‡â–…â–„â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–‡â–…â–„â–†â–…â–†â–…â–…â–„â–…â–…â–…â–…â–„â–„â–‡â–†â–…â–…â–ƒâ–„â–†â–„â–…â–ƒâ–ˆâ–‚â–ƒâ–„â–„â–…â–ƒâ–â–„â–„â–‚â–„â–„â–ƒâ–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–„â–„â–„â–„â–„â–…â–„â–„â–„â–„â–„â–„â–…â–…â–ƒâ–„â–…â–…â–†â–…â–…â–†â–…â–†â–ƒâ–‡â–†â–…â–…â–…â–†â–ˆâ–…â–…â–‡â–…â–…â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–ƒâ–‡â–ˆâ–…â–‡â–…â–…â–…â–…â–„â–„â–„â–‚â–ƒâ–ƒâ–‚â–â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–†â–…â–„â–„â–„â–…â–†â–ˆâ–…â–„â–†â–†â–…â–„â–…â–‡â–†â–„â–…â–†â–…â–…â–†â–„â–‡â–„â–‡â–‡â–…â–„â–„â–…â–‡â–†â–†â–†â–†â–ˆâ–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–…â–…â–†â–‡â–…â–…â–†â–‡â–‡â–…â–…â–†â–‡â–‡â–…â–„â–„â–…â–…â–„â–ƒâ–ƒâ–„â–…â–„â–…â–…â–…â–‡â–ˆâ–„â–‚â–…â–†â–„â–‡â–…â–„â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–„â–ˆâ–‡â–…â–‡â–…â–…â–„â–†â–…â–„â–„â–ƒâ–„â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–â–â–â–‚â–â–‚â–â–â–‚â–‚â–â–â–„â–ƒâ–â–â–â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–‡â–„â–ƒâ–…â–„â–†â–„â–…â–„â–„â–…â–…â–…â–„â–„â–‡â–†â–…â–…â–ƒâ–„â–†â–„â–…â–ƒâ–ˆâ–‚â–ƒâ–„â–„â–…â–ƒâ–â–„â–„â–‚â–„â–„â–ƒâ–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–„â–„â–„â–„â–„â–…â–„â–„â–„â–„â–„â–„â–…â–…â–ƒâ–„â–…â–…â–†â–…â–…â–†â–…â–†â–ƒâ–‡â–†â–…â–…â–…â–†â–ˆâ–…â–…â–‡â–…â–…â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–ƒâ–‡â–ˆâ–…â–‡â–…â–…â–…â–…â–„â–„â–„â–‚â–ƒâ–ƒâ–‚â–â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–†â–…â–„â–„â–„â–…â–†â–ˆâ–…â–„â–†â–†â–…â–„â–…â–‡â–†â–„â–…â–†â–…â–…â–†â–„â–‡â–„â–‡â–‡â–…â–„â–„â–…â–‡â–†â–†â–†â–†â–ˆâ–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–…â–…â–†â–‡â–…â–…â–†â–‡â–‡â–…â–…â–†â–‡â–‡â–…â–„â–„â–…â–…â–„â–ƒâ–ƒâ–„â–…â–„â–…â–…â–…â–‡â–ˆâ–„â–‚â–…â–†â–„â–‡â–…â–„â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–„â–ˆâ–‡â–…â–‡â–…â–…â–„â–†â–…â–„â–„â–ƒâ–„â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–â–â–â–‚â–â–‚â–â–â–‚â–‚â–â–â–„â–ƒâ–â–â–â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–‡â–„â–ƒâ–…â–„â–†â–„â–…â–„â–„â–…â–…â–…â–„â–„â–‡â–†â–…â–…â–ƒâ–„â–†â–„â–…â–ƒâ–ˆâ–‚â–ƒâ–„â–„â–…â–ƒâ–â–„â–„â–‚â–„â–„â–ƒâ–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 3.38383\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 3.34482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 3.55907\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 2.37967\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 3.5655\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 3.756\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 2.83\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.66075\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 2.83\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.5245\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.198\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.127\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.1315\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 1049.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 396.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 8.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 254.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 263.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 10.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.5245\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0095\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.1885\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.127\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0025\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.129\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 1049\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 19\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 377\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 254\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 258\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s1a1_s4a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/olpzswu6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_001237-olpzswu6/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:13:19,146][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s1a1_s5a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_001320-c6ywimyb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s1a1_s5a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/c6ywimyb\u001b[0m\n",
      "[2023-08-09 00:13:24,298][root][INFO] - => Done in 5.152 s\n",
      "[2023-08-09 00:13:24,298][root][INFO] - \n",
      "[2023-08-09 00:13:24,298][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:13:24,301][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:13:24,301][root][INFO] - => Done in 3.105 ms\n",
      "[2023-08-09 00:13:24,301][root][INFO] - \n",
      "[2023-08-09 00:13:24,301][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:13:24,869][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:13:24,869][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:13:24,869][root][INFO] - => Done in 567.735 ms\n",
      "[2023-08-09 00:13:24,869][root][INFO] - \n",
      "[2023-08-09 00:13:24,869][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:13:24,869][root][INFO] - => Done in 112.295 us\n",
      "[2023-08-09 00:13:24,869][root][INFO] - \n",
      "[2023-08-09 00:13:24,869][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:13:24,870][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:13:25,630][root][INFO] - => Done in 760.559 ms\n",
      "[2023-08-09 00:13:25,630][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–†â–‡â–‡â–‡â–†â–†â–†â–‡â–†â–†â–†â–‡â–†â–†â–†â–†â–‡â–†â–†â–ˆâ–†â–ˆâ–‡â–†â–‡â–‡â–†â–…â–‡â–‡â–…â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–†â–‡â–†â–‡â–†â–…â–†â–‡â–‡â–…â–†â–†â–‡â–†â–…â–†â–‡â–†â–†â–†â–…â–‡â–†â–…â–ˆâ–†â–ˆâ–‡â–†â–†â–†â–†â–…â–†â–‡â–…â–…â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–ƒâ–…â–…â–†â–…â–†â–‡â–†â–…â–…â–‡â–†â–†â–…â–†â–ˆâ–†â–…â–†â–†â–‡â–‡â–…â–…â–‡â–„â–‡â–„â–…â–‡â–†â–‡â–†â–‡â–‡â–…â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–ˆâ–†â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–‚â–â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–ˆâ–†â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–‚â–â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–‚â–‚â–‚â–ƒâ–â–â–„â–‚â–‚â–â–â–‚â–â–‚â–‚â–‚â–‚â–â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–†â–…â–†â–„â–…â–„â–…â–†â–…â–ƒâ–ƒâ–†â–„â–„â–‚â–„â–ˆâ–…â–„â–„â–„â–†â–†â–„â–ƒâ–†â–â–…â–‚â–„â–†â–ƒâ–†â–…â–…â–…â–ƒâ–„â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–ˆâ–…â–‡â–„â–…â–…â–‚â–„â–†â–†â–ƒâ–„â–…â–†â–„â–â–„â–…â–„â–ƒâ–ƒâ–‚â–…â–„â–‚â–ˆâ–ƒâ–‡â–…â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–†â–‚â–ƒâ–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–ƒâ–„â–…â–†â–†â–†â–‡â–‡â–†â–†â–‡â–‡â–‡â–†â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–†â–‡â–‡â–†â–‡â–…â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–†â–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–‚â–‚â–‚â–ƒâ–â–â–„â–‚â–‚â–â–â–‚â–â–‚â–‚â–‚â–‚â–â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–†â–…â–†â–„â–…â–„â–…â–†â–…â–ƒâ–ƒâ–†â–„â–„â–‚â–„â–ˆâ–…â–„â–„â–„â–†â–†â–„â–ƒâ–†â–â–…â–‚â–„â–†â–ƒâ–†â–…â–…â–…â–ƒâ–„â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–ˆâ–…â–‡â–„â–…â–…â–‚â–„â–†â–†â–ƒâ–„â–…â–†â–„â–â–„â–…â–„â–ƒâ–ƒâ–‚â–…â–„â–‚â–ˆâ–ƒâ–‡â–…â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–†â–‚â–ƒâ–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–ƒâ–„â–…â–†â–†â–†â–‡â–‡â–†â–†â–‡â–‡â–‡â–†â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–†â–‡â–‡â–†â–‡â–…â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–†â–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–‚â–‚â–‚â–ƒâ–â–â–„â–‚â–‚â–â–â–‚â–â–‚â–‚â–‚â–‚â–â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–„â–„â–†â–„â–…â–„â–…â–†â–…â–ƒâ–ƒâ–†â–„â–„â–‚â–„â–ˆâ–…â–„â–„â–„â–†â–†â–„â–ƒâ–†â–â–…â–‚â–„â–†â–ƒâ–†â–…â–…â–…â–ƒâ–„â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–ˆâ–…â–‡â–„â–…â–…â–‚â–„â–†â–†â–ƒâ–„â–…â–†â–„â–â–„â–…â–„â–ƒâ–ƒâ–‚â–…â–„â–‚â–ˆâ–ƒâ–‡â–…â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–†â–‚â–ƒâ–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–ˆâ–„â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–ƒâ–…â–…â–†â–†â–†â–‡â–‡â–†â–†â–‡â–‡â–‡â–†â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–†â–‡â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–†â–ˆâ–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–‚â–‚â–‚â–ƒâ–â–â–„â–‚â–‚â–â–â–‚â–â–‚â–‚â–‚â–‚â–â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–„â–„â–†â–„â–…â–„â–…â–†â–…â–ƒâ–ƒâ–†â–„â–„â–‚â–„â–ˆâ–…â–„â–„â–„â–†â–†â–„â–ƒâ–†â–â–…â–‚â–„â–†â–ƒâ–†â–…â–…â–…â–ƒâ–„â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–ˆâ–…â–‡â–„â–…â–…â–‚â–„â–†â–†â–ƒâ–„â–…â–†â–„â–â–„â–…â–„â–ƒâ–ƒâ–‚â–…â–„â–‚â–ˆâ–ƒâ–‡â–…â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–†â–‚â–ƒâ–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–ˆâ–„â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–ƒâ–…â–…â–†â–†â–†â–‡â–‡â–†â–†â–‡â–‡â–‡â–†â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–†â–‡â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–†â–ˆâ–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.379\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 3.24369\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 3.01585\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.6758\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 3.5715\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 2.8005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.765\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.186\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.765\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.017\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0455\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.3015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.6245\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 34.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 91.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 603.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1249.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 3.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.017\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0455\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.3015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.624\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 34\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 603\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1248\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s1a1_s5a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/c6ywimyb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_001320-c6ywimyb/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:14:00,050][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s2a1_s1a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_001401-e8qotgm0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s2a1_s1a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/e8qotgm0\u001b[0m\n",
      "[2023-08-09 00:14:05,318][root][INFO] - => Done in 5.268 s\n",
      "[2023-08-09 00:14:05,318][root][INFO] - \n",
      "[2023-08-09 00:14:05,318][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:14:05,322][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:14:05,322][root][INFO] - => Done in 3.648 ms\n",
      "[2023-08-09 00:14:05,322][root][INFO] - \n",
      "[2023-08-09 00:14:05,322][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:14:05,894][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:14:05,894][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:14:05,894][root][INFO] - => Done in 572.621 ms\n",
      "[2023-08-09 00:14:05,895][root][INFO] - \n",
      "[2023-08-09 00:14:05,895][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:14:05,895][root][INFO] - => Done in 128.984 us\n",
      "[2023-08-09 00:14:05,895][root][INFO] - \n",
      "[2023-08-09 00:14:05,895][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:14:05,895][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:14:06,654][root][INFO] - => Done in 759.424 ms\n",
      "[2023-08-09 00:14:06,655][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–†â–†â–ˆâ–…â–‡â–‡â–†â–†â–„â–†â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–…â–†â–‡â–†â–…â–†â–†â–†â–ˆâ–…â–…â–…â–†â–„â–†â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–…â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–‡â–†â–†â–ˆâ–…â–‡â–‡â–†â–†â–„â–†â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–…â–†â–‡â–†â–…â–†â–†â–†â–‡â–…â–…â–…â–†â–„â–†â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–ˆâ–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–‚â–â–‚â–â–â–‚â–‚â–â–â–â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–ˆâ–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–‚â–â–‚â–â–â–‚â–‚â–â–â–â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–ˆâ–‡â–„â–ƒâ–„â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–„â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–ˆâ–‡â–„â–ƒâ–„â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–„â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–ˆâ–‡â–„â–ƒâ–„â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–„â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–ˆâ–‡â–„â–ƒâ–„â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–„â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.121\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 2.83399\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 3.23055\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.28133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 2.8775\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 3.242\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.2435\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.05975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.2435\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.1215\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.868\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 243.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1736.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.1215\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.868\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 243\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1736\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s2a1_s1a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/e8qotgm0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_001401-e8qotgm0/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:14:41,981][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s2a1_s2a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_001443-ux579ro5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s2a1_s2a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/ux579ro5\u001b[0m\n",
      "[2023-08-09 00:14:47,383][root][INFO] - => Done in 5.402 s\n",
      "[2023-08-09 00:14:47,383][root][INFO] - \n",
      "[2023-08-09 00:14:47,383][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:14:47,386][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:14:47,386][root][INFO] - => Done in 2.920 ms\n",
      "[2023-08-09 00:14:47,386][root][INFO] - \n",
      "[2023-08-09 00:14:47,386][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:14:47,935][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:14:47,935][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:14:47,935][root][INFO] - => Done in 548.969 ms\n",
      "[2023-08-09 00:14:47,935][root][INFO] - \n",
      "[2023-08-09 00:14:47,935][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:14:47,935][root][INFO] - => Done in 118.732 us\n",
      "[2023-08-09 00:14:47,936][root][INFO] - \n",
      "[2023-08-09 00:14:47,936][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:14:47,936][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:14:48,699][root][INFO] - => Done in 763.422 ms\n",
      "[2023-08-09 00:14:48,699][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–„â–ˆâ–„â–„â–…â–‚â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–„â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–„â–‚â–‚â–‚â–ƒâ–â–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–„â–…â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–†â–‡â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–†â–‡â–‡â–‡â–†â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–ˆâ–…â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–ˆâ–…â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–…â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–‡â–ˆâ–…â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–ˆâ–„â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–ˆâ–„â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–ƒâ–…â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–…â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–…â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–‡â–ˆâ–…â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–ˆâ–„â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–ˆâ–„â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–ƒâ–…â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–…â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–…â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–†â–ˆâ–†â–„â–…â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–ˆâ–„â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–ˆâ–„â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–„â–…â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–…â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–…â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–†â–ˆâ–†â–„â–…â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–ˆâ–„â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–ˆâ–„â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–„â–…â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–…â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.12033\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 2.831\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 3.22878\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.29946\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 2.8765\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 3.241\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.2435\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.05875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.2435\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.1215\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.868\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 243.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1736.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.1215\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.868\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 243\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1736\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s2a1_s2a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/ux579ro5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_001443-ux579ro5/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:15:23,804][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s2a1_s3a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_001525-b25ufy5x\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s2a1_s3a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/b25ufy5x\u001b[0m\n",
      "[2023-08-09 00:15:28,400][root][INFO] - => Done in 4.596 s\n",
      "[2023-08-09 00:15:28,400][root][INFO] - \n",
      "[2023-08-09 00:15:28,400][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:15:28,404][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:15:28,404][root][INFO] - => Done in 4.325 ms\n",
      "[2023-08-09 00:15:28,404][root][INFO] - \n",
      "[2023-08-09 00:15:28,404][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:15:29,004][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:15:29,005][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:15:29,005][root][INFO] - => Done in 600.286 ms\n",
      "[2023-08-09 00:15:29,005][root][INFO] - \n",
      "[2023-08-09 00:15:29,005][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:15:29,005][root][INFO] - => Done in 114.918 us\n",
      "[2023-08-09 00:15:29,005][root][INFO] - \n",
      "[2023-08-09 00:15:29,005][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:15:29,005][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:15:29,777][root][INFO] - => Done in 772.317 ms\n",
      "[2023-08-09 00:15:29,778][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 1.001 MB of 1.001 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–‡â–…â–†â–…â–…â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–†â–†â–†â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–…â–„â–ƒâ–…â–‡â–…â–†â–†â–†â–‡â–†â–†â–†â–†â–†â–†â–„â–‡â–†â–‡â–†â–†â–†â–‡â–†â–‡â–†â–…â–„â–…â–…â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–†â–ˆâ–ˆâ–ˆâ–ˆâ–†â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–â–‚â–â–‚â–â–â–â–â–â–‚â–‚â–â–‚â–‚â–â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–†â–†â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–†â–ˆâ–ˆâ–ˆâ–ˆâ–†â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–â–‚â–â–‚â–â–â–â–â–â–‚â–‚â–â–‚â–‚â–â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–…â–ˆâ–‡â–‡â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–‚â–â–â–â–â–â–â–‚â–â–â–â–â–â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–ˆâ–„â–†â–…â–„â–‚â–â–‚â–ƒâ–ƒâ–â–‚â–…â–‚â–ƒâ–„â–„â–„â–„â–„â–ƒâ–ƒâ–„â–ƒâ–â–…â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–…â–‚â–ƒâ–â–‚â–‚â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–ˆâ–„â–…â–ƒâ–ƒâ–ƒâ–‚â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–…â–…â–…â–†â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–†â–‡â–†â–‡â–‡â–†â–‡â–†â–‡â–‡â–†â–†â–ˆâ–†â–‡â–†â–†â–‡â–†â–…â–‡â–†â–†â–‡â–‡â–†â–‡â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ƒâ–‚â–â–‚â–â–‚â–„â–„â–…â–…â–…â–†â–‡â–†â–‡â–†â–†â–‡â–†â–‡â–‡â–†â–†â–‡â–†â–‡â–†â–ˆâ–‡â–‡â–‡â–ˆâ–†â–‡â–‡â–†â–†â–‡â–†â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–…â–ˆâ–‡â–‡â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–‚â–â–â–â–â–â–â–‚â–â–â–â–â–â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–ˆâ–„â–†â–…â–„â–‚â–â–‚â–ƒâ–ƒâ–â–‚â–…â–‚â–ƒâ–„â–„â–„â–„â–„â–ƒâ–ƒâ–„â–ƒâ–â–…â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–…â–‚â–ƒâ–â–‚â–‚â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–ˆâ–„â–…â–ƒâ–ƒâ–ƒâ–‚â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–…â–…â–…â–†â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–†â–‡â–†â–‡â–‡â–†â–‡â–†â–‡â–‡â–†â–†â–ˆâ–†â–‡â–†â–†â–‡â–†â–…â–‡â–†â–†â–‡â–‡â–†â–‡â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ƒâ–‚â–â–‚â–â–‚â–„â–„â–…â–…â–…â–†â–‡â–†â–‡â–†â–†â–‡â–†â–‡â–‡â–†â–†â–‡â–†â–‡â–†â–ˆâ–‡â–‡â–‡â–ˆâ–†â–‡â–‡â–†â–†â–‡â–†â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–…â–ˆâ–‡â–‡â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–‚â–â–â–â–â–â–â–‚â–â–â–â–â–â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–ˆâ–…â–…â–„â–„â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–„â–‚â–„â–„â–ƒâ–‚â–â–‚â–„â–ƒâ–‚â–ƒâ–ˆâ–„â–„â–†â–†â–‡â–†â–†â–…â–…â–‡â–„â–‚â–ˆâ–…â–†â–†â–…â–„â–…â–‡â–ˆâ–„â–„â–‚â–ƒâ–„â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–ˆâ–„â–…â–ƒâ–ƒâ–ƒâ–‚â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–…â–…â–…â–†â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–†â–‡â–†â–‡â–‡â–†â–‡â–†â–‡â–‡â–†â–†â–ˆâ–†â–‡â–†â–†â–‡â–†â–…â–‡â–†â–†â–‡â–‡â–†â–‡â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–‡â–ˆâ–‡â–ˆâ–ˆâ–†â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–‚â–â–â–â–â–‚â–…â–„â–†â–…â–…â–‡â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–†â–‡â–‡â–‡â–‡â–‡â–†â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–…â–ˆâ–‡â–‡â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–‚â–â–â–â–â–â–â–‚â–â–â–â–â–â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–ˆâ–…â–…â–„â–„â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–ƒâ–‚â–„â–ƒâ–ƒâ–‚â–â–‚â–„â–ƒâ–‚â–ƒâ–‡â–„â–„â–†â–†â–‡â–†â–†â–…â–…â–‡â–„â–‚â–‡â–…â–†â–†â–…â–„â–…â–‡â–ˆâ–„â–„â–‚â–ƒâ–„â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–ˆâ–„â–…â–ƒâ–ƒâ–ƒâ–‚â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–…â–…â–…â–†â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–†â–‡â–†â–‡â–‡â–†â–‡â–†â–‡â–‡â–†â–†â–ˆâ–†â–‡â–†â–†â–‡â–†â–…â–‡â–†â–†â–‡â–‡â–†â–‡â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–‡â–ˆâ–‡â–ˆâ–ˆâ–†â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–‚â–â–â–â–â–‚â–…â–„â–†â–…â–…â–‡â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–†â–‡â–‡â–‡â–‡â–‡â–†â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.52667\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 3.57873\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 2.85424\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 1.211\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 3.555\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 2.9595\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.0655\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.25725\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.0655\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0265\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.138\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.3355\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.488\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 53.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 276.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 671.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 976.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 3.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0265\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.138\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.3355\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.4865\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 53\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 973\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s2a1_s3a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/b25ufy5x\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_001525-b25ufy5x/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:16:03,443][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s2a1_s4a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_001604-3garmfje\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s2a1_s4a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/3garmfje\u001b[0m\n",
      "[2023-08-09 00:16:09,090][root][INFO] - => Done in 5.646 s\n",
      "[2023-08-09 00:16:09,090][root][INFO] - \n",
      "[2023-08-09 00:16:09,090][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:16:09,094][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:16:09,094][root][INFO] - => Done in 3.485 ms\n",
      "[2023-08-09 00:16:09,094][root][INFO] - \n",
      "[2023-08-09 00:16:09,094][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:16:09,687][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:16:09,687][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:16:09,687][root][INFO] - => Done in 593.118 ms\n",
      "[2023-08-09 00:16:09,687][root][INFO] - \n",
      "[2023-08-09 00:16:09,687][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:16:09,687][root][INFO] - => Done in 111.103 us\n",
      "[2023-08-09 00:16:09,687][root][INFO] - \n",
      "[2023-08-09 00:16:09,687][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:16:09,687][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:16:10,462][root][INFO] - => Done in 774.424 ms\n",
      "[2023-08-09 00:16:10,462][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–…â–†â–†â–‡â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–‡â–‡â–‡â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–…â–…â–†â–‡â–†â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–†â–†â–†â–…â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–…â–…â–†â–‡â–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–ˆâ–ˆâ–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–…â–…â–†â–†â–†â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–…â–…â–†â–‡â–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–ˆâ–ˆâ–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–…â–…â–†â–†â–†â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–…â–…â–†â–†â–…â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–„â–…â–ƒâ–ƒâ–ƒâ–‚â–‚â–†â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–…â–ƒâ–â–…â–ƒâ–ƒâ–…â–„â–†â–‚â–‡â–†â–…â–„â–‡â–…â–…â–…â–ˆâ–…â–…â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–ˆâ–„â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–„â–…â–…â–‡â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–†â–‡â–‡â–‡â–†â–†â–…â–†â–†â–‡â–…â–…â–†â–†â–…â–…â–…â–…â–…â–‡â–†â–…â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–†â–„â–…â–ƒâ–„â–ƒâ–‚â–â–â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–â–‚â–ƒâ–ƒâ–‚â–„â–ƒâ–…â–…â–ƒâ–„â–„â–…â–„â–…â–…â–…â–†â–‡â–…â–ƒâ–…â–…â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–…â–…â–†â–†â–†â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–…â–…â–†â–†â–…â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–„â–…â–ƒâ–ƒâ–ƒâ–‚â–‚â–†â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–…â–ƒâ–â–…â–ƒâ–ƒâ–…â–„â–†â–‚â–‡â–†â–…â–„â–‡â–…â–…â–…â–ˆâ–…â–…â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–ˆâ–„â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–„â–…â–…â–‡â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–†â–‡â–‡â–‡â–†â–†â–…â–†â–†â–‡â–…â–…â–†â–†â–…â–…â–…â–…â–…â–‡â–†â–…â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–†â–„â–…â–ƒâ–„â–ƒâ–‚â–â–â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–â–‚â–ƒâ–ƒâ–‚â–„â–ƒâ–…â–…â–ƒâ–„â–„â–…â–„â–…â–…â–…â–†â–‡â–…â–ƒâ–…â–…â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–…â–…â–†â–†â–†â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–…â–…â–†â–†â–…â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–„â–„â–…â–„â–…â–ƒâ–ƒâ–‚â–‚â–â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–„â–„â–ƒâ–„â–ƒâ–ƒâ–…â–…â–…â–„â–…â–…â–…â–…â–ˆâ–…â–…â–†â–‡â–†â–…â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–…â–…â–ƒâ–ƒâ–„â–ƒâ–„â–ˆâ–…â–ƒâ–„â–„â–„â–„â–„â–…â–†â–„â–ƒâ–†â–„â–„â–…â–„â–†â–‚â–‡â–†â–…â–ƒâ–„â–…â–…â–…â–‡â–…â–…â–†â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–ˆâ–„â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–„â–…â–…â–‡â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–†â–‡â–‡â–‡â–†â–†â–…â–†â–†â–‡â–…â–…â–†â–†â–…â–…â–…â–…â–…â–‡â–†â–…â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–…â–„â–ƒâ–„â–„â–ƒâ–ƒâ–‚â–‚â–â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–…â–„â–…â–†â–…â–…â–‡â–†â–ˆâ–‡â–†â–…â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–†â–„â–…â–â–„â–ƒâ–‚â–â–â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–â–ƒâ–ƒâ–„â–„â–ƒâ–‚â–„â–„â–ƒâ–…â–…â–ƒâ–„â–…â–ƒâ–â–„â–ƒâ–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–…â–…â–†â–†â–†â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–†â–‡â–†â–†â–†â–†â–†â–†â–†â–…â–…â–†â–†â–…â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–„â–„â–…â–„â–…â–ƒâ–ƒâ–‚â–‚â–â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–„â–„â–ƒâ–„â–ƒâ–ƒâ–…â–…â–…â–„â–…â–…â–…â–…â–ˆâ–…â–…â–†â–‡â–†â–…â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–…â–…â–ƒâ–ƒâ–„â–ƒâ–„â–ˆâ–…â–ƒâ–„â–„â–„â–„â–„â–…â–†â–„â–ƒâ–†â–„â–„â–…â–„â–†â–‚â–‡â–†â–…â–ƒâ–„â–…â–…â–…â–‡â–…â–…â–†â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–ˆâ–„â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–„â–…â–…â–‡â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–†â–‡â–‡â–‡â–†â–†â–…â–†â–†â–‡â–…â–…â–†â–†â–…â–…â–…â–…â–…â–‡â–†â–…â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–…â–…â–ƒâ–„â–„â–ƒâ–ƒâ–‚â–‚â–â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–…â–„â–…â–†â–…â–…â–‡â–†â–ˆâ–‡â–†â–…â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–†â–„â–…â–â–„â–ƒâ–‚â–â–â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–â–ƒâ–ƒâ–„â–„â–ƒâ–‚â–„â–„â–ƒâ–…â–…â–ƒâ–„â–…â–ƒâ–â–„â–ƒâ–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.73067\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 3.15352\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 3.18091\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 2.09308\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 3.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 3.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 2.091\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.0505\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 2.091\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.1665\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.274\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0405\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.1585\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.3095\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.041\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 333.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 548.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 81.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 317.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 619.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 82.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.1665\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0665\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.2075\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0405\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.1585\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.2495\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.041\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 333\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 415\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 81\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 317\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 120\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 499\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 82\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s2a1_s4a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/3garmfje\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_001604-3garmfje/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:16:47,085][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s2a1_s5a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_001648-btva36b3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s2a1_s5a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/btva36b3\u001b[0m\n",
      "[2023-08-09 00:16:51,678][root][INFO] - => Done in 4.593 s\n",
      "[2023-08-09 00:16:51,679][root][INFO] - \n",
      "[2023-08-09 00:16:51,679][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:16:51,683][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:16:51,683][root][INFO] - => Done in 3.952 ms\n",
      "[2023-08-09 00:16:51,683][root][INFO] - \n",
      "[2023-08-09 00:16:51,683][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:16:52,282][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:16:52,282][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:16:52,283][root][INFO] - => Done in 599.426 ms\n",
      "[2023-08-09 00:16:52,283][root][INFO] - \n",
      "[2023-08-09 00:16:52,283][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:16:52,283][root][INFO] - => Done in 133.991 us\n",
      "[2023-08-09 00:16:52,283][root][INFO] - \n",
      "[2023-08-09 00:16:52,283][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:16:52,283][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:16:53,050][root][INFO] - => Done in 767.217 ms\n",
      "[2023-08-09 00:16:53,050][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–†â–‡â–ˆâ–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–…â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–†â–‡â–†â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–†â–ˆâ–‡â–‡â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–‚â–‚â–…â–„â–‚â–„â–…â–…â–ƒâ–…â–ƒâ–‚â–‚â–…â–„â–‚â–„â–…â–†â–‡â–„â–„â–„â–ƒâ–„â–†â–ƒâ–†â–…â–„â–…â–‚â–â–†â–ˆâ–‚â–…â–„â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–ˆâ–…â–„â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–ˆâ–…â–„â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–„â–„â–‚â–‚â–â–‚â–â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–‚â–â–â–‚â–â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–‚â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–ˆâ–…â–†â–„â–‚â–„â–…â–„â–‚â–„â–‚â–â–‚â–…â–ƒâ–‚â–„â–„â–…â–†â–ƒâ–„â–ƒâ–‚â–ƒâ–…â–ƒâ–…â–„â–ƒâ–„â–‚â–â–…â–†â–‚â–…â–ƒâ–…â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–…â–„â–†â–‡â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–†â–†â–‡â–†â–†â–…â–…â–†â–†â–†â–‡â–†â–…â–‡â–…â–†â–‡â–†â–‡â–ˆâ–†â–„â–‡â–†â–†â–…â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–„â–…â–†â–†â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–†â–‡â–†â–†â–‡â–ˆâ–‡â–†â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–„â–„â–‚â–‚â–â–‚â–â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–‚â–â–â–‚â–â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–‚â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–ˆâ–…â–†â–„â–‚â–„â–…â–„â–‚â–„â–‚â–â–‚â–…â–ƒâ–‚â–„â–„â–…â–†â–ƒâ–„â–ƒâ–‚â–ƒâ–…â–ƒâ–…â–„â–ƒâ–„â–‚â–â–…â–†â–‚â–…â–ƒâ–…â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–…â–„â–†â–‡â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–†â–†â–‡â–†â–†â–…â–…â–†â–†â–†â–‡â–†â–…â–‡â–…â–†â–‡â–†â–‡â–ˆâ–†â–„â–‡â–†â–†â–…â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–„â–…â–†â–†â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–†â–‡â–†â–†â–‡â–ˆâ–‡â–†â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–„â–„â–‚â–‚â–â–‚â–â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–‚â–â–â–‚â–â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–‚â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–‡â–†â–‡â–…â–‚â–…â–†â–…â–ƒâ–…â–ƒâ–‚â–‚â–†â–ƒâ–‚â–„â–…â–†â–ˆâ–ƒâ–„â–„â–ƒâ–„â–†â–ƒâ–†â–…â–„â–…â–ƒâ–â–†â–ˆâ–‚â–†â–ƒâ–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–…â–„â–†â–‡â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–†â–†â–‡â–†â–†â–…â–…â–†â–†â–†â–‡â–†â–…â–‡â–…â–†â–‡â–†â–‡â–ˆâ–†â–„â–‡â–†â–†â–…â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–„â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–ƒâ–…â–†â–†â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–ˆâ–‡â–†â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–„â–„â–‚â–‚â–â–‚â–â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–‚â–â–â–‚â–â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–‚â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–‡â–†â–‡â–…â–‚â–…â–†â–…â–ƒâ–…â–ƒâ–‚â–‚â–†â–ƒâ–‚â–„â–…â–†â–ˆâ–ƒâ–„â–„â–ƒâ–„â–†â–ƒâ–†â–…â–„â–…â–ƒâ–â–†â–ˆâ–‚â–†â–ƒâ–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–…â–„â–†â–‡â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–†â–†â–‡â–†â–†â–…â–…â–†â–†â–†â–‡â–†â–…â–‡â–…â–†â–‡â–†â–‡â–ˆâ–†â–„â–‡â–†â–†â–…â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–„â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–ƒâ–…â–†â–†â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–ˆâ–‡â–†â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.42367\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 3.42413\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 2.95545\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.92332\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 3.3995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 3.017\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.8545\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.20825\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.8545\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.142\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.2695\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.5705\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 12.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 284.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 539.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1141.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 4.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.142\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.2695\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.57\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 284\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 539\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1140\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s2a1_s5a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/btva36b3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_001648-btva36b3/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:17:30,434][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s3a2_s1a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_001731-1f7xv1nd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s3a2_s1a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/1f7xv1nd\u001b[0m\n",
      "[2023-08-09 00:17:37,387][root][INFO] - => Done in 6.952 s\n",
      "[2023-08-09 00:17:37,387][root][INFO] - \n",
      "[2023-08-09 00:17:37,387][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:17:37,392][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:17:37,392][root][INFO] - => Done in 5.221 ms\n",
      "[2023-08-09 00:17:37,392][root][INFO] - \n",
      "[2023-08-09 00:17:37,392][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:17:37,956][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:17:37,956][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:17:37,956][root][INFO] - => Done in 563.457 ms\n",
      "[2023-08-09 00:17:37,956][root][INFO] - \n",
      "[2023-08-09 00:17:37,956][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:17:37,956][root][INFO] - => Done in 216.961 us\n",
      "[2023-08-09 00:17:37,956][root][INFO] - \n",
      "[2023-08-09 00:17:37,956][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:17:37,957][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:17:38,768][root][INFO] - => Done in 811.064 ms\n",
      "[2023-08-09 00:17:38,768][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01524\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01544\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1979.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s3a2_s1a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/1f7xv1nd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_001731-1f7xv1nd/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:18:14,579][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s3a2_s2a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_001815-7m2a5a23\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s3a2_s2a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/7m2a5a23\u001b[0m\n",
      "[2023-08-09 00:18:19,562][root][INFO] - => Done in 4.984 s\n",
      "[2023-08-09 00:18:19,563][root][INFO] - \n",
      "[2023-08-09 00:18:19,563][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:18:19,565][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:18:19,566][root][INFO] - => Done in 2.927 ms\n",
      "[2023-08-09 00:18:19,566][root][INFO] - \n",
      "[2023-08-09 00:18:19,566][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:18:20,144][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:18:20,144][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:18:20,145][root][INFO] - => Done in 578.922 ms\n",
      "[2023-08-09 00:18:20,145][root][INFO] - \n",
      "[2023-08-09 00:18:20,145][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:18:20,145][root][INFO] - => Done in 107.050 us\n",
      "[2023-08-09 00:18:20,145][root][INFO] - \n",
      "[2023-08-09 00:18:20,145][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:18:20,145][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:18:20,905][root][INFO] - => Done in 760.349 ms\n",
      "[2023-08-09 00:18:20,905][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01523\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01549\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.9925\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s3a2_s2a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/7m2a5a23\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_001815-7m2a5a23/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:18:56,208][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s3a2_s3a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_001857-4nxj3sxv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s3a2_s3a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/4nxj3sxv\u001b[0m\n",
      "[2023-08-09 00:19:01,351][root][INFO] - => Done in 5.143 s\n",
      "[2023-08-09 00:19:01,352][root][INFO] - \n",
      "[2023-08-09 00:19:01,352][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:19:01,355][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:19:01,355][root][INFO] - => Done in 3.064 ms\n",
      "[2023-08-09 00:19:01,355][root][INFO] - \n",
      "[2023-08-09 00:19:01,355][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:19:01,913][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:19:01,913][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:19:01,913][root][INFO] - => Done in 558.420 ms\n",
      "[2023-08-09 00:19:01,913][root][INFO] - \n",
      "[2023-08-09 00:19:01,914][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:19:01,914][root][INFO] - => Done in 261.784 us\n",
      "[2023-08-09 00:19:01,914][root][INFO] - \n",
      "[2023-08-09 00:19:01,914][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:19:01,914][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:19:02,674][root][INFO] - => Done in 759.766 ms\n",
      "[2023-08-09 00:19:02,674][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–ˆâ–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–†â–†â–‡â–‡â–†â–†â–‡â–‡â–…â–‡â–‡â–†â–†â–†â–†â–†â–…â–†â–…â–‡â–†â–‡â–†â–‡â–†â–†â–†â–‡â–†â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–†â–‡â–‡â–†â–‡â–‡â–†â–‡â–‡â–†â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–â–â–â–â–â–‚â–â–â–â–‚â–â–‚â–â–â–â–‚â–â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–â–â–â–â–â–‚â–â–â–â–‚â–â–‚â–â–â–â–‚â–â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–ˆâ–‚â–â–â–â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–‡â–ˆâ–†â–†â–†â–„â–„â–ƒâ–„â–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–„â–„â–â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–â–ƒâ–â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–„â–‚â–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–ˆâ–‚â–â–â–â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–‡â–ˆâ–†â–†â–†â–„â–„â–ƒâ–„â–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–„â–„â–â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–â–ƒâ–â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–„â–‚â–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–ˆâ–ƒâ–‚â–â–â–ƒâ–â–‚â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–‡â–ˆâ–†â–†â–†â–„â–„â–ƒâ–„â–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–„â–„â–â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–â–ƒâ–â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–„â–‚â–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–ˆâ–ƒâ–‚â–â–â–ƒâ–â–‚â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–‡â–ˆâ–†â–†â–†â–„â–„â–ƒâ–„â–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–„â–„â–â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–â–ƒâ–â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–„â–‚â–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.10683\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 3.20699\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 2.84118\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.27069\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 3.214\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 2.8735\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.233\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.04375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.233\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.113\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.8715\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0055\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 226.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1743.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 11.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.113\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.871\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0055\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 226\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1742\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s3a2_s3a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/4nxj3sxv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_001857-4nxj3sxv/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:19:38,226][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s3a2_s4a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_001939-9pa9nxnj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s3a2_s4a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/9pa9nxnj\u001b[0m\n",
      "[2023-08-09 00:19:42,765][root][INFO] - => Done in 4.539 s\n",
      "[2023-08-09 00:19:42,765][root][INFO] - \n",
      "[2023-08-09 00:19:42,766][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:19:42,770][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:19:42,770][root][INFO] - => Done in 4.652 ms\n",
      "[2023-08-09 00:19:42,770][root][INFO] - \n",
      "[2023-08-09 00:19:42,771][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:19:43,382][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:19:43,382][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:19:43,382][root][INFO] - => Done in 611.583 ms\n",
      "[2023-08-09 00:19:43,382][root][INFO] - \n",
      "[2023-08-09 00:19:43,382][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:19:43,382][root][INFO] - => Done in 100.136 us\n",
      "[2023-08-09 00:19:43,382][root][INFO] - \n",
      "[2023-08-09 00:19:43,382][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:19:43,383][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:19:44,164][root][INFO] - => Done in 781.481 ms\n",
      "[2023-08-09 00:19:44,164][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01526\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01549\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99252\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s3a2_s4a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/9pa9nxnj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_001939-9pa9nxnj/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:20:20,295][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s3a2_s5a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_002021-em1mu1oq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s3a2_s5a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/em1mu1oq\u001b[0m\n",
      "[2023-08-09 00:20:26,255][root][INFO] - => Done in 5.959 s\n",
      "[2023-08-09 00:20:26,255][root][INFO] - \n",
      "[2023-08-09 00:20:26,255][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:20:26,262][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:20:26,263][root][INFO] - => Done in 7.478 ms\n",
      "[2023-08-09 00:20:26,263][root][INFO] - \n",
      "[2023-08-09 00:20:26,263][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:20:26,830][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:20:26,831][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:20:26,831][root][INFO] - => Done in 567.658 ms\n",
      "[2023-08-09 00:20:26,831][root][INFO] - \n",
      "[2023-08-09 00:20:26,831][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:20:26,831][root][INFO] - => Done in 113.726 us\n",
      "[2023-08-09 00:20:26,831][root][INFO] - \n",
      "[2023-08-09 00:20:26,831][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:20:26,831][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:20:27,590][root][INFO] - => Done in 759.146 ms\n",
      "[2023-08-09 00:20:27,590][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–ˆâ–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–ˆâ–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–â–‚â–â–â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–ˆâ–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–â–‚â–â–â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–ˆâ–‚â–â–â–â–ƒâ–â–‚â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–ƒâ–â–â–â–â–â–â–â–â–â–â–ƒâ–‚â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–…â–ˆâ–„â–…â–…â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–…â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–ˆâ–ƒâ–â–â–â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–ƒâ–â–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–…â–ˆâ–„â–…â–…â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–…â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–ˆâ–ƒâ–â–â–â–„â–â–‚â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–ƒâ–â–â–â–â–â–â–â–â–â–â–„â–‚â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–…â–ˆâ–„â–…â–…â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–…â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–ˆâ–ƒâ–â–â–â–„â–â–‚â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–ƒâ–â–â–â–â–â–â–â–â–â–â–„â–‚â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–…â–ˆâ–„â–…â–…â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–…â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.09833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 3.20445\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 2.84108\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.2673\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 3.197\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 2.879\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.219\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.038\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.219\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.1055\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.878\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0065\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 211.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1756.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 13.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.1055\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.8775\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0065\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 211\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1755\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s3a2_s5a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/em1mu1oq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_002021-em1mu1oq/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:21:03,354][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s4a1_s1a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_002104-l3zzoz81\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s4a1_s1a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/l3zzoz81\u001b[0m\n",
      "[2023-08-09 00:21:08,545][root][INFO] - => Done in 5.191 s\n",
      "[2023-08-09 00:21:08,546][root][INFO] - \n",
      "[2023-08-09 00:21:08,546][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:21:08,549][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:21:08,549][root][INFO] - => Done in 3.230 ms\n",
      "[2023-08-09 00:21:08,549][root][INFO] - \n",
      "[2023-08-09 00:21:08,549][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:21:09,122][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:21:09,122][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:21:09,123][root][INFO] - => Done in 573.468 ms\n",
      "[2023-08-09 00:21:09,123][root][INFO] - \n",
      "[2023-08-09 00:21:09,123][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:21:09,123][root][INFO] - => Done in 169.277 us\n",
      "[2023-08-09 00:21:09,123][root][INFO] - \n",
      "[2023-08-09 00:21:09,123][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:21:09,123][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:21:09,885][root][INFO] - => Done in 762.475 ms\n",
      "[2023-08-09 00:21:09,886][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–†â–†â–…â–†â–…â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–†â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–…â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–†â–†â–…â–†â–†â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–†â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–ˆâ–…â–„â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–ˆâ–…â–„â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–‚â–‡â–„â–â–ƒâ–â–ƒâ–ƒâ–„â–„â–‚â–„â–„â–„â–„â–…â–†â–†â–†â–†â–†â–ˆâ–†â–…â–…â–…â–‡â–…â–…â–„â–†â–…â–ˆâ–†â–„â–†â–‡â–„â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–ˆâ–„â–„â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–„â–…â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–†â–†â–‡â–‡â–†â–‡â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–‚â–‡â–„â–â–ƒâ–â–ƒâ–ƒâ–„â–„â–‚â–„â–„â–„â–„â–…â–†â–†â–†â–†â–†â–ˆâ–†â–…â–…â–…â–‡â–…â–…â–„â–†â–…â–ˆâ–†â–„â–†â–‡â–„â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–ˆâ–„â–„â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–„â–…â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–†â–†â–‡â–‡â–†â–‡â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–‚â–‡â–„â–â–ƒâ–â–ƒâ–ƒâ–„â–„â–‚â–„â–„â–„â–„â–…â–†â–†â–†â–†â–†â–ˆâ–†â–…â–…â–…â–‡â–…â–…â–„â–†â–…â–ˆâ–†â–„â–†â–‡â–„â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–ˆâ–„â–„â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–„â–…â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–†â–†â–‡â–‡â–†â–‡â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–‚â–‡â–„â–â–ƒâ–â–ƒâ–ƒâ–„â–„â–‚â–„â–„â–„â–„â–…â–†â–†â–†â–†â–†â–ˆâ–†â–…â–…â–…â–‡â–…â–…â–„â–†â–…â–ˆâ–†â–„â–†â–‡â–„â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–ˆâ–„â–„â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–„â–…â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–†â–†â–‡â–‡â–†â–‡â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.10717\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 2.61622\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 3.21327\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.49055\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 2.642\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 3.215\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.4645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 2.9285\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.4645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.188\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0025\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.72\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0795\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 376.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 5.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1440.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 159.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.188\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0025\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.72\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0795\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 376\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1440\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 159\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s4a1_s1a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/l3zzoz81\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_002104-l3zzoz81/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:21:44,574][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s4a1_s2a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_002145-lqqboywl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s4a1_s2a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/lqqboywl\u001b[0m\n",
      "[2023-08-09 00:21:49,378][root][INFO] - => Done in 4.804 s\n",
      "[2023-08-09 00:21:49,378][root][INFO] - \n",
      "[2023-08-09 00:21:49,378][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:21:49,381][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:21:49,381][root][INFO] - => Done in 3.214 ms\n",
      "[2023-08-09 00:21:49,381][root][INFO] - \n",
      "[2023-08-09 00:21:49,381][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:21:49,986][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:21:49,986][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:21:49,986][root][INFO] - => Done in 605.057 ms\n",
      "[2023-08-09 00:21:49,986][root][INFO] - \n",
      "[2023-08-09 00:21:49,986][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:21:49,986][root][INFO] - => Done in 105.143 us\n",
      "[2023-08-09 00:21:49,986][root][INFO] - \n",
      "[2023-08-09 00:21:49,987][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:21:49,987][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:21:50,759][root][INFO] - => Done in 772.733 ms\n",
      "[2023-08-09 00:21:50,760][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–†â–„â–…â–„â–…â–†â–†â–†â–†â–‡â–†â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–†â–ˆâ–†â–‡â–‡â–†â–‡â–ˆâ–‡â–†â–‡â–‡â–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–…â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–‡â–†â–…â–†â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–ˆâ–…â–„â–‚â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–ˆâ–…â–„â–‚â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–‡â–…â–‚â–ƒâ–‚â–â–â–â–â–â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–ƒâ–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–ƒâ–ˆâ–…â–â–„â–â–‚â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–„â–„â–†â–…â–…â–…â–†â–…â–…â–…â–…â–‡â–…â–…â–…â–…â–…â–ˆâ–…â–„â–†â–†â–…â–†â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–ˆâ–„â–„â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–ˆâ–†â–„â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–„â–…â–‡â–†â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–‚â–â–â–‚â–‚â–â–â–‚â–‚â–â–â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–‡â–…â–â–ƒâ–â–â–â–â–â–â–â–‚â–â–â–‚â–‚â–â–ƒâ–ƒâ–â–ƒâ–‚â–â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–ƒâ–â–â–ƒâ–‚â–‚â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–ƒâ–ˆâ–…â–â–„â–â–‚â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–„â–„â–†â–…â–…â–…â–†â–…â–…â–…â–…â–‡â–…â–…â–…â–…â–…â–ˆâ–…â–„â–†â–†â–…â–†â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–ˆâ–„â–„â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–ˆâ–†â–„â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–„â–…â–‡â–†â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–‚â–â–â–‚â–‚â–â–â–‚â–‚â–â–â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–‡â–…â–‚â–ƒâ–‚â–â–â–â–â–â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–ƒâ–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–ƒâ–ˆâ–…â–â–„â–â–‚â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–„â–„â–‡â–…â–…â–…â–†â–†â–…â–…â–…â–‡â–…â–…â–…â–…â–…â–ˆâ–…â–„â–†â–†â–…â–†â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–ˆâ–„â–„â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–ˆâ–†â–„â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–„â–…â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–‚â–â–â–‚â–‚â–â–â–‚â–‚â–â–â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–‡â–…â–â–ƒâ–â–â–â–â–â–â–â–‚â–â–â–‚â–‚â–â–ƒâ–ƒâ–â–ƒâ–‚â–â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–ƒâ–â–â–ƒâ–‚â–‚â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–ƒâ–ˆâ–…â–â–„â–â–‚â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–„â–„â–‡â–…â–…â–…â–†â–†â–…â–…â–…â–‡â–…â–…â–…â–…â–…â–ˆâ–…â–„â–†â–†â–…â–†â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–ˆâ–„â–„â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–ˆâ–†â–„â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–„â–…â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–‚â–â–â–‚â–‚â–â–â–‚â–‚â–â–â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.13617\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 2.67113\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 3.23468\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.46924\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 2.7305\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 3.266\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.412\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 2.99825\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.412\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.177\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.765\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.044\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 354.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 4.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1530.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 88.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.177\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.765\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.044\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 354\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1530\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 88\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s4a1_s2a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/lqqboywl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_002145-lqqboywl/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:22:25,549][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s4a1_s3a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_002226-mj9mie4u\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s4a1_s3a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/mj9mie4u\u001b[0m\n",
      "[2023-08-09 00:22:30,585][root][INFO] - => Done in 5.036 s\n",
      "[2023-08-09 00:22:30,585][root][INFO] - \n",
      "[2023-08-09 00:22:30,586][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:22:30,589][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:22:30,589][root][INFO] - => Done in 3.760 ms\n",
      "[2023-08-09 00:22:30,589][root][INFO] - \n",
      "[2023-08-09 00:22:30,589][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:22:31,164][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:22:31,164][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:22:31,164][root][INFO] - => Done in 574.460 ms\n",
      "[2023-08-09 00:22:31,164][root][INFO] - \n",
      "[2023-08-09 00:22:31,164][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:22:31,164][root][INFO] - => Done in 108.957 us\n",
      "[2023-08-09 00:22:31,164][root][INFO] - \n",
      "[2023-08-09 00:22:31,164][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:22:31,164][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:22:31,930][root][INFO] - => Done in 765.814 ms\n",
      "[2023-08-09 00:22:31,930][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–…â–…â–†â–…â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–ˆâ–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–…â–…â–†â–†â–†â–‡â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–…â–„â–…â–†â–„â–…â–†â–‡â–…â–…â–‡â–…â–†â–„â–†â–„â–‡â–…â–†â–…â–‡â–…â–…â–‡â–†â–†â–‡â–…â–ƒâ–…â–…â–‡â–ˆâ–†â–ˆâ–…â–…â–†â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–ˆâ–„â–…â–…â–…â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–‚â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–„â–„â–„â–„â–…â–ƒâ–…â–†â–†â–†â–„â–‡â–…â–‡â–„â–†â–„â–†â–…â–„â–…â–…â–ƒâ–ˆâ–…â–„â–„â–…â–‡â–‡â–„â–„â–†â–†â–„â–‡â–…â–„â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–„â–„â–„â–ƒâ–ƒâ–‚â–‚â–â–‚â–‚â–â–â–â–‚â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–â–‚â–â–â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–…â–…â–†â–†â–†â–‡â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–…â–„â–…â–†â–„â–…â–†â–‡â–…â–…â–‡â–…â–†â–„â–†â–„â–‡â–…â–†â–…â–‡â–…â–…â–‡â–†â–†â–‡â–…â–ƒâ–…â–…â–‡â–ˆâ–†â–ˆâ–…â–…â–†â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–ˆâ–„â–…â–…â–…â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–‚â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–„â–„â–„â–„â–…â–ƒâ–…â–†â–†â–†â–„â–‡â–…â–‡â–„â–†â–„â–†â–…â–„â–…â–…â–ƒâ–ˆâ–…â–„â–„â–…â–‡â–‡â–„â–„â–†â–†â–„â–‡â–…â–„â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–„â–„â–„â–ƒâ–ƒâ–‚â–‚â–â–‚â–‚â–â–â–â–‚â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–â–‚â–â–â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–…â–…â–†â–†â–†â–‡â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–ˆâ–†â–…â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–„â–„â–„â–†â–…â–…â–†â–‡â–†â–†â–‡â–†â–‡â–…â–‡â–†â–‡â–†â–‡â–†â–ˆâ–†â–†â–‡â–‡â–‡â–ˆâ–†â–…â–†â–†â–‡â–ˆâ–‡â–ˆâ–†â–†â–‡â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–ˆâ–„â–…â–…â–…â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–‚â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–„â–„â–„â–„â–…â–ƒâ–…â–†â–†â–†â–„â–‡â–…â–‡â–„â–†â–„â–†â–…â–„â–…â–…â–ƒâ–ˆâ–…â–„â–„â–…â–‡â–‡â–„â–„â–†â–†â–„â–‡â–…â–„â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–â–â–â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–â–‚â–â–â–â–â–â–‚â–‚â–â–‚â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–„â–„â–„â–ƒâ–ƒâ–‚â–‚â–â–‚â–‚â–â–â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–…â–…â–†â–†â–†â–‡â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–ˆâ–†â–…â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–„â–„â–„â–†â–…â–…â–†â–‡â–†â–†â–‡â–†â–‡â–…â–‡â–†â–‡â–†â–‡â–†â–ˆâ–†â–†â–‡â–‡â–‡â–ˆâ–†â–…â–†â–†â–‡â–ˆâ–‡â–ˆâ–†â–†â–‡â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–ˆâ–„â–…â–…â–…â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–‚â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–„â–„â–„â–„â–…â–ƒâ–…â–†â–†â–†â–„â–‡â–…â–‡â–„â–†â–„â–†â–…â–„â–…â–…â–ƒâ–ˆâ–…â–„â–„â–…â–‡â–‡â–„â–„â–†â–†â–„â–‡â–…â–„â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–â–â–â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–â–‚â–â–â–â–â–â–‚â–‚â–â–‚â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–„â–„â–„â–ƒâ–ƒâ–‚â–‚â–â–‚â–‚â–â–â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 3.322\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 3.29211\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 3.81302\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 2.74241\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 3.388\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 3.826\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 2.752\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.607\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 2.752\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.4595\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.2755\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0105\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.1235\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.1145\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0065\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 919.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 551.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 21.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 247.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 229.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 13.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.4595\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.018\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.2575\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0105\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.1235\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.1125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0065\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 919\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 36\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 21\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 247\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 225\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s4a1_s3a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/mj9mie4u\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_002226-mj9mie4u/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:23:07,541][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s4a1_s4a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_002308-y4xuxkbt\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s4a1_s4a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/y4xuxkbt\u001b[0m\n",
      "[2023-08-09 00:23:12,367][root][INFO] - => Done in 4.826 s\n",
      "[2023-08-09 00:23:12,367][root][INFO] - \n",
      "[2023-08-09 00:23:12,367][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:23:12,370][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:23:12,370][root][INFO] - => Done in 3.065 ms\n",
      "[2023-08-09 00:23:12,371][root][INFO] - \n",
      "[2023-08-09 00:23:12,371][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:23:12,952][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:23:12,952][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:23:12,952][root][INFO] - => Done in 581.300 ms\n",
      "[2023-08-09 00:23:12,952][root][INFO] - \n",
      "[2023-08-09 00:23:12,952][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:23:12,952][root][INFO] - => Done in 110.865 us\n",
      "[2023-08-09 00:23:12,952][root][INFO] - \n",
      "[2023-08-09 00:23:12,952][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:23:12,952][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:23:13,709][root][INFO] - => Done in 756.571 ms\n",
      "[2023-08-09 00:23:13,709][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–†â–†â–†â–†â–†â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–ˆâ–†â–‡â–‡â–‡â–†â–†â–‡â–…â–†â–…â–„â–ƒâ–ƒâ–…â–†â–†â–ƒâ–„â–†â–„â–„â–…â–…â–‡â–„â–†â–…â–„â–„â–…â–„â–…â–…â–…â–„â–„â–…â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–ˆâ–ƒâ–„â–ƒâ–„â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–â–â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–†â–‡â–†â–‡â–‡â–†â–†â–…â–†â–‡â–†â–†â–†â–‡â–‡â–ˆâ–†â–†â–‡â–‡â–†â–ˆâ–ˆâ–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–â–â–‚â–â–â–‚â–â–‚â–â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–ˆâ–†â–‡â–‡â–‡â–†â–†â–‡â–…â–†â–…â–„â–ƒâ–ƒâ–…â–†â–†â–ƒâ–„â–†â–„â–„â–…â–…â–‡â–„â–†â–…â–„â–„â–…â–„â–…â–…â–…â–„â–„â–…â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–ˆâ–ƒâ–„â–ƒâ–„â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–â–â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–†â–‡â–†â–‡â–‡â–†â–†â–…â–†â–‡â–†â–†â–†â–‡â–‡â–ˆâ–†â–†â–‡â–‡â–†â–ˆâ–ˆâ–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–â–â–‚â–â–â–‚â–â–‚â–â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–…â–„â–…â–…â–ƒâ–ƒâ–‚â–†â–…â–„â–„â–ƒâ–ƒâ–„â–ƒâ–‚â–„â–…â–„â–„â–ƒâ–‚â–ƒâ–…â–„â–ƒâ–„â–„â–‚â–ƒâ–„â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–ˆâ–…â–…â–…â–…â–„â–…â–ˆâ–‡â–…â–„â–†â–„â–„â–ƒâ–†â–ˆâ–‚â–…â–‡â–„â–„â–†â–„â–ˆâ–ƒâ–‡â–…â–…â–…â–…â–„â–‡â–†â–…â–…â–…â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–ˆâ–ƒâ–„â–ƒâ–„â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–â–â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–†â–‡â–†â–‡â–‡â–†â–†â–…â–†â–‡â–†â–†â–†â–‡â–‡â–ˆâ–†â–†â–‡â–‡â–†â–ˆâ–ˆâ–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ƒâ–ˆâ–ˆâ–†â–…â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–ƒâ–†â–‚â–ƒâ–ƒâ–‚â–ƒâ–â–‚â–‚â–ƒâ–ƒâ–‚â–â–ƒâ–„â–‚â–‚â–„â–ƒâ–‚â–‚â–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–ƒâ–ƒâ–ƒâ–â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–â–â–‚â–â–â–‚â–â–â–â–â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–…â–„â–…â–…â–ƒâ–ƒâ–‚â–†â–…â–„â–„â–ƒâ–ƒâ–„â–ƒâ–‚â–„â–…â–„â–„â–ƒâ–‚â–ƒâ–…â–„â–ƒâ–„â–„â–‚â–ƒâ–„â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–ˆâ–…â–…â–…â–…â–„â–…â–ˆâ–‡â–…â–„â–†â–„â–„â–ƒâ–†â–ˆâ–‚â–…â–‡â–„â–„â–†â–„â–ˆâ–ƒâ–‡â–…â–…â–…â–…â–„â–‡â–†â–…â–…â–…â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–ˆâ–ƒâ–„â–ƒâ–„â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–â–â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–†â–‡â–†â–‡â–‡â–†â–†â–…â–†â–‡â–†â–†â–†â–‡â–‡â–ˆâ–†â–†â–‡â–‡â–†â–ˆâ–ˆâ–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ƒâ–ˆâ–ˆâ–†â–…â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–ƒâ–†â–‚â–ƒâ–ƒâ–‚â–ƒâ–â–‚â–‚â–ƒâ–ƒâ–‚â–â–ƒâ–„â–‚â–‚â–„â–ƒâ–‚â–‚â–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–ƒâ–ƒâ–ƒâ–â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–â–â–‚â–â–â–‚â–â–â–â–â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 3.38533\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 3.471\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 3.5526\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 2.99487\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 3.533\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 3.6485\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 2.9745\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.59075\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 2.9745\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.5075\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.215\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0165\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.1465\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 1015.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 430.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 33.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 293.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 199.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 10.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.5075\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.034\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0165\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.1465\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.013\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0865\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 1015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 68\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 362\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 33\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 293\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 26\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 173\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s4a1_s4a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/y4xuxkbt\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_002308-y4xuxkbt/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:23:47,689][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s4a1_s5a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_002348-ltpchnm1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s4a1_s5a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/ltpchnm1\u001b[0m\n",
      "[2023-08-09 00:23:52,641][root][INFO] - => Done in 4.952 s\n",
      "[2023-08-09 00:23:52,641][root][INFO] - \n",
      "[2023-08-09 00:23:52,641][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:23:52,644][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:23:52,644][root][INFO] - => Done in 3.251 ms\n",
      "[2023-08-09 00:23:52,644][root][INFO] - \n",
      "[2023-08-09 00:23:52,644][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:23:53,225][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:23:53,225][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:23:53,225][root][INFO] - => Done in 580.597 ms\n",
      "[2023-08-09 00:23:53,225][root][INFO] - \n",
      "[2023-08-09 00:23:53,225][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:23:53,225][root][INFO] - => Done in 102.758 us\n",
      "[2023-08-09 00:23:53,225][root][INFO] - \n",
      "[2023-08-09 00:23:53,225][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:23:53,225][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:23:53,987][root][INFO] - => Done in 761.376 ms\n",
      "[2023-08-09 00:23:53,987][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 1.014 MB of 1.014 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–…â–†â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–„â–„â–†â–…â–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–†â–†â–†â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–†â–‡â–‡â–ˆâ–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–„â–…â–†â–†â–†â–‡â–‡â–†â–†â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–†â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–…â–†â–†â–†â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–„â–…â–†â–†â–†â–‡â–‡â–†â–†â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–†â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–‚â–„â–…â–…â–ˆâ–…â–ƒâ–„â–ƒâ–‚â–ƒâ–‚â–„â–â–ƒâ–‚â–„â–‚â–„â–„â–ƒâ–†â–‚â–â–ƒâ–ƒâ–„â–â–ƒâ–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–„â–„â–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–†â–†â–‡â–†â–‡â–‡â–†â–‡â–†â–†â–†â–†â–ˆâ–ˆâ–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–†â–†â–‡â–‡â–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–ˆâ–„â–…â–„â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–‚â–â–â–â–‚â–â–â–‚â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–ƒâ–ƒâ–…â–„â–…â–†â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–ˆâ–†â–‡â–‡â–‡â–‡â–†â–†â–†â–‡â–ˆâ–‡â–‡â–†â–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–†â–…â–…â–…â–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–ƒâ–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–‚â–„â–…â–…â–ˆâ–…â–ƒâ–„â–ƒâ–‚â–ƒâ–‚â–„â–â–ƒâ–‚â–„â–‚â–„â–„â–ƒâ–†â–‚â–â–ƒâ–ƒâ–„â–â–ƒâ–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–„â–„â–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–†â–†â–‡â–†â–‡â–‡â–†â–‡â–†â–†â–†â–†â–ˆâ–ˆâ–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–†â–†â–‡â–‡â–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–ˆâ–…â–…â–„â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–‚â–â–â–â–‚â–â–â–‚â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–ƒâ–ƒâ–…â–„â–…â–†â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–ˆâ–†â–‡â–‡â–‡â–‡â–†â–†â–†â–‡â–ˆâ–‡â–‡â–†â–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–†â–…â–…â–…â–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–ƒâ–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–‚â–„â–…â–…â–ˆâ–…â–ƒâ–„â–ƒâ–‚â–ƒâ–‚â–„â–â–ƒâ–‚â–„â–‚â–„â–„â–ƒâ–†â–‚â–â–ƒâ–ƒâ–„â–â–ƒâ–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–„â–„â–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–†â–ˆâ–ˆâ–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–†â–‡â–‡â–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–ˆâ–„â–…â–„â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–‚â–â–â–â–‚â–â–â–‚â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–ƒâ–ƒâ–…â–„â–…â–†â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–ˆâ–†â–‡â–‡â–‡â–‡â–†â–†â–†â–‡â–ˆâ–‡â–‡â–†â–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–‡â–ˆâ–…â–ˆâ–†â–†â–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–â–‚â–â–â–‚â–â–â–â–‚â–‚â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–†â–…â–…â–„â–„â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–‚â–„â–…â–…â–ˆâ–…â–ƒâ–„â–ƒâ–‚â–ƒâ–‚â–„â–â–ƒâ–‚â–„â–‚â–„â–„â–ƒâ–†â–‚â–â–ƒâ–ƒâ–„â–â–ƒâ–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–„â–„â–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–†â–ˆâ–ˆâ–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–†â–‡â–‡â–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–ˆâ–…â–…â–„â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–‚â–â–â–â–‚â–â–â–‚â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–ƒâ–ƒâ–…â–„â–…â–†â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–ˆâ–†â–‡â–‡â–‡â–‡â–†â–†â–†â–‡â–ˆâ–‡â–‡â–†â–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–‡â–ˆâ–…â–ˆâ–†â–†â–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–â–‚â–â–â–‚â–â–â–â–‚â–‚â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–†â–…â–…â–„â–„â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.91767\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 3.21883\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 3.56906\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 1.88075\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 3.2895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 3.5835\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.88\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.4365\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.88\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.084\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.417\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.009\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.3285\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.148\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0035\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 168.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 834.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 18.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 657.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 296.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 7.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.084\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.416\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.009\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.3285\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.1465\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0035\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 168\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 832\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 657\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 293\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s4a1_s5a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/ltpchnm1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_002348-ltpchnm1/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:24:28,828][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s5a2_s1a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_002429-pzh9task\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s5a2_s1a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/pzh9task\u001b[0m\n",
      "[2023-08-09 00:24:34,194][root][INFO] - => Done in 5.366 s\n",
      "[2023-08-09 00:24:34,194][root][INFO] - \n",
      "[2023-08-09 00:24:34,194][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:24:34,198][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:24:34,199][root][INFO] - => Done in 4.320 ms\n",
      "[2023-08-09 00:24:34,199][root][INFO] - \n",
      "[2023-08-09 00:24:34,199][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:24:34,757][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:24:34,758][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:24:34,758][root][INFO] - => Done in 559.114 ms\n",
      "[2023-08-09 00:24:34,758][root][INFO] - \n",
      "[2023-08-09 00:24:34,758][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:24:34,758][root][INFO] - => Done in 110.149 us\n",
      "[2023-08-09 00:24:34,758][root][INFO] - \n",
      "[2023-08-09 00:24:34,758][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:24:34,758][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:24:35,518][root][INFO] - => Done in 760.151 ms\n",
      "[2023-08-09 00:24:35,518][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01511\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01588\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99292\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s5a2_s1a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/pzh9task\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_002429-pzh9task/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:25:10,727][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s5a2_s2a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_002511-r2zruk4x\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s5a2_s2a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/r2zruk4x\u001b[0m\n",
      "[2023-08-09 00:25:15,488][root][INFO] - => Done in 4.761 s\n",
      "[2023-08-09 00:25:15,488][root][INFO] - \n",
      "[2023-08-09 00:25:15,488][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:25:15,491][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:25:15,491][root][INFO] - => Done in 3.087 ms\n",
      "[2023-08-09 00:25:15,491][root][INFO] - \n",
      "[2023-08-09 00:25:15,491][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:25:16,070][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:25:16,070][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:25:16,070][root][INFO] - => Done in 578.707 ms\n",
      "[2023-08-09 00:25:16,070][root][INFO] - \n",
      "[2023-08-09 00:25:16,070][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:25:16,070][root][INFO] - => Done in 123.978 us\n",
      "[2023-08-09 00:25:16,070][root][INFO] - \n",
      "[2023-08-09 00:25:16,070][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:25:16,071][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:25:16,826][root][INFO] - => Done in 756.025 ms\n",
      "[2023-08-09 00:25:16,827][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 1.016 MB of 1.016 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01501\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01584\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.9929\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1979.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s5a2_s2a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/r2zruk4x\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_002511-r2zruk4x/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:25:51,907][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s5a2_s3a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_002553-bbqbkc1j\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s5a2_s3a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/bbqbkc1j\u001b[0m\n",
      "[2023-08-09 00:25:56,781][root][INFO] - => Done in 4.875 s\n",
      "[2023-08-09 00:25:56,782][root][INFO] - \n",
      "[2023-08-09 00:25:56,782][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:25:56,785][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:25:56,785][root][INFO] - => Done in 3.243 ms\n",
      "[2023-08-09 00:25:56,785][root][INFO] - \n",
      "[2023-08-09 00:25:56,785][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:25:57,366][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:25:57,366][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:25:57,366][root][INFO] - => Done in 580.778 ms\n",
      "[2023-08-09 00:25:57,366][root][INFO] - \n",
      "[2023-08-09 00:25:57,366][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:25:57,366][root][INFO] - => Done in 124.931 us\n",
      "[2023-08-09 00:25:57,366][root][INFO] - \n",
      "[2023-08-09 00:25:57,366][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:25:57,366][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:25:58,123][root][INFO] - => Done in 757.229 ms\n",
      "[2023-08-09 00:25:58,124][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: | 1.014 MB of 1.017 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–ˆâ–‡â–†â–ˆâ–†â–…â–†â–†â–…â–†â–‡â–†â–…â–…â–†â–†â–„â–†â–†â–…â–†â–…â–…â–…â–„â–†â–„â–…â–…â–†â–…â–…â–…â–†â–…â–†â–…â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–ˆâ–„â–„â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–‚â–â–â–â–â–‚â–â–â–â–‚â–â–â–â–‚â–â–‚â–â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–ˆâ–„â–„â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–‚â–â–â–â–â–‚â–â–â–â–‚â–â–â–â–‚â–â–‚â–â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–„â–„â–‚â–‚â–â–â–ƒâ–â–â–â–â–â–â–‚â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–‚â–â–â–„â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–ˆâ–„â–„â–‚â–„â–‚â–‚â–ƒâ–‚â–ƒâ–â–ƒâ–‚â–â–â–â–ƒâ–â–‚â–â–â–â–â–‚â–â–â–ƒâ–‚â–‚â–â–â–â–â–â–ƒâ–ƒâ–â–‚â–ƒâ–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–‡â–ˆâ–‡â–†â–†â–„â–„â–ƒâ–„â–‚â–„â–…â–„â–ƒâ–ƒâ–…â–„â–‚â–„â–„â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–â–‚â–ƒâ–„â–‚â–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–„â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–„â–„â–‚â–‚â–â–â–ƒâ–â–â–â–â–â–â–‚â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–‚â–â–â–„â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–ˆâ–„â–„â–‚â–„â–‚â–‚â–ƒâ–‚â–ƒâ–â–ƒâ–‚â–â–â–â–ƒâ–â–‚â–â–â–â–â–‚â–â–â–ƒâ–‚â–‚â–â–â–â–â–â–ƒâ–ƒâ–â–‚â–ƒâ–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–‡â–ˆâ–‡â–†â–†â–„â–„â–ƒâ–„â–‚â–„â–…â–„â–ƒâ–ƒâ–…â–„â–‚â–„â–„â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–â–‚â–ƒâ–„â–‚â–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–„â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–„â–„â–‚â–‚â–â–â–ƒâ–â–â–â–â–â–â–‚â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–‚â–â–â–„â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–ˆâ–‡â–†â–ƒâ–‡â–ƒâ–‚â–„â–ƒâ–„â–â–…â–ƒâ–â–â–â–…â–â–ƒâ–â–â–‚â–â–‚â–â–â–…â–ƒâ–‚â–â–â–â–‚â–â–„â–„â–â–‚â–„â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–‡â–ˆâ–‡â–†â–†â–„â–„â–ƒâ–„â–‚â–„â–…â–„â–ƒâ–ƒâ–…â–„â–‚â–„â–„â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–â–‚â–ƒâ–„â–‚â–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–ƒâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–…â–…â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–„â–„â–‚â–‚â–â–â–ƒâ–â–â–â–â–â–â–‚â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–‚â–â–â–„â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–ˆâ–‡â–†â–ƒâ–‡â–ƒâ–‚â–„â–ƒâ–„â–â–…â–ƒâ–â–â–â–…â–â–ƒâ–â–â–‚â–â–‚â–â–â–…â–ƒâ–‚â–â–â–â–‚â–â–„â–„â–â–‚â–„â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–‡â–ˆâ–‡â–†â–†â–„â–„â–ƒâ–„â–‚â–„â–…â–„â–ƒâ–ƒâ–…â–„â–‚â–„â–„â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–â–‚â–ƒâ–„â–‚â–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–ƒâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–…â–…â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.10933\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 3.20222\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 2.85273\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.2872\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 3.189\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 2.8965\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.2425\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.04275\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.2425\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0055\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.1025\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.8715\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 8.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 11.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 205.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1743.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 12.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0055\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.1025\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.8705\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 205\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1741\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s5a2_s3a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/bbqbkc1j\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_002553-bbqbkc1j/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:26:34,939][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s5a2_s4a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_002635-x52xta13\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s5a2_s4a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/x52xta13\u001b[0m\n",
      "[2023-08-09 00:26:39,806][root][INFO] - => Done in 4.867 s\n",
      "[2023-08-09 00:26:39,806][root][INFO] - \n",
      "[2023-08-09 00:26:39,806][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:26:39,809][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:26:39,809][root][INFO] - => Done in 3.363 ms\n",
      "[2023-08-09 00:26:39,809][root][INFO] - \n",
      "[2023-08-09 00:26:39,810][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:26:40,362][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:26:40,363][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:26:40,363][root][INFO] - => Done in 553.079 ms\n",
      "[2023-08-09 00:26:40,363][root][INFO] - \n",
      "[2023-08-09 00:26:40,363][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:26:40,363][root][INFO] - => Done in 144.958 us\n",
      "[2023-08-09 00:26:40,363][root][INFO] - \n",
      "[2023-08-09 00:26:40,363][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:26:40,363][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:26:41,123][root][INFO] - => Done in 760.341 ms\n",
      "[2023-08-09 00:26:41,124][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01505\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01586\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99291\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1979.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s5a2_s4a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/x52xta13\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_002635-x52xta13/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:27:15,881][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s5a2_s5a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_002716-kxxgvce0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s5a2_s5a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/kxxgvce0\u001b[0m\n",
      "[2023-08-09 00:27:20,747][root][INFO] - => Done in 4.866 s\n",
      "[2023-08-09 00:27:20,747][root][INFO] - \n",
      "[2023-08-09 00:27:20,747][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:27:20,750][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:27:20,750][root][INFO] - => Done in 3.190 ms\n",
      "[2023-08-09 00:27:20,751][root][INFO] - \n",
      "[2023-08-09 00:27:20,751][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:27:21,332][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:27:21,332][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:27:21,332][root][INFO] - => Done in 581.353 ms\n",
      "[2023-08-09 00:27:21,332][root][INFO] - \n",
      "[2023-08-09 00:27:21,332][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:27:21,332][root][INFO] - => Done in 112.057 us\n",
      "[2023-08-09 00:27:21,332][root][INFO] - \n",
      "[2023-08-09 00:27:21,332][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:27:21,332][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:27:22,104][root][INFO] - => Done in 771.384 ms\n",
      "[2023-08-09 00:27:22,104][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 1.007 MB of 1.020 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–ˆâ–‡â–‡â–ˆâ–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–†â–‡â–‡â–†â–‡â–‡â–‡â–‡â–†â–‡â–†â–‡â–‡â–†â–†â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–…â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–ˆâ–…â–ƒâ–‚â–‚â–â–‚â–â–‚â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–ˆâ–…â–ƒâ–‚â–‚â–â–‚â–â–‚â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–†â–ƒâ–‚â–‚â–â–â–„â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–„â–‚â–â–â–‚â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–ˆâ–†â–„â–‚â–„â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–â–‚â–‚â–â–â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–â–‚â–â–â–„â–‚â–ƒâ–â–‚â–‚â–ƒâ–â–ƒâ–‚â–‚â–‚â–ƒâ–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–„â–ˆâ–…â–„â–„â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–‚â–ƒâ–‚â–â–‚â–ƒâ–â–‚â–ƒâ–‚â–‚â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–„â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–†â–ƒâ–‚â–‚â–â–â–„â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–„â–‚â–â–â–‚â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–ˆâ–†â–„â–‚â–„â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–â–‚â–‚â–â–â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–â–‚â–â–â–„â–‚â–ƒâ–â–‚â–‚â–ƒâ–â–ƒâ–‚â–‚â–‚â–ƒâ–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–„â–ˆâ–…â–„â–„â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–‚â–ƒâ–‚â–â–‚â–ƒâ–â–‚â–ƒâ–‚â–‚â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–„â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–†â–ƒâ–‚â–‚â–â–â–„â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–„â–‚â–â–â–‚â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–‡â–ˆâ–†â–‚â–‡â–ƒâ–…â–„â–„â–…â–â–ƒâ–„â–â–‚â–ƒâ–…â–‚â–ƒâ–‚â–‚â–‚â–â–ƒâ–â–‚â–‡â–ƒâ–„â–â–ƒâ–‚â–…â–â–…â–ƒâ–‚â–‚â–…â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–„â–ˆâ–…â–„â–„â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–‚â–ƒâ–‚â–â–‚â–ƒâ–â–‚â–ƒâ–‚â–‚â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–„â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–†â–ƒâ–‚â–‚â–â–â–„â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–„â–‚â–â–â–‚â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–‡â–ˆâ–†â–‚â–‡â–ƒâ–…â–„â–„â–…â–â–ƒâ–„â–â–‚â–ƒâ–…â–‚â–ƒâ–‚â–‚â–‚â–â–ƒâ–â–‚â–‡â–ƒâ–„â–â–ƒâ–‚â–…â–â–…â–ƒâ–‚â–‚â–…â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–„â–ˆâ–…â–„â–„â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–‚â–ƒâ–‚â–â–‚â–ƒâ–â–‚â–ƒâ–‚â–‚â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–„â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.13233\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 3.2006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 2.85144\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.29003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 3.229\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 2.8855\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.2825\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.05725\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.2825\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.007\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.1205\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.853\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 10.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 14.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 241.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1706.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 9.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.007\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.1205\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.852\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 241\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1704\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s5a2_s5a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/kxxgvce0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_002716-kxxgvce0/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:27:57,001][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s1a2_s1a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_002757-f1y0uvud\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s1a2_s1a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/f1y0uvud\u001b[0m\n",
      "[2023-08-09 00:28:01,962][root][INFO] - => Done in 4.961 s\n",
      "[2023-08-09 00:28:01,962][root][INFO] - \n",
      "[2023-08-09 00:28:01,962][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:28:01,965][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:28:01,966][root][INFO] - => Done in 3.017 ms\n",
      "[2023-08-09 00:28:01,966][root][INFO] - \n",
      "[2023-08-09 00:28:01,966][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:28:02,537][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:28:02,537][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:28:02,538][root][INFO] - => Done in 571.922 ms\n",
      "[2023-08-09 00:28:02,538][root][INFO] - \n",
      "[2023-08-09 00:28:02,538][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:28:02,538][root][INFO] - => Done in 111.103 us\n",
      "[2023-08-09 00:28:02,538][root][INFO] - \n",
      "[2023-08-09 00:28:02,538][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:28:02,538][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:28:03,306][root][INFO] - => Done in 767.871 ms\n",
      "[2023-08-09 00:28:03,306][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01525\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.0152\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99244\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1979.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s1a2_s1a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/f1y0uvud\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_002757-f1y0uvud/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:28:37,888][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s1a2_s2a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_002838-y8xvgniu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s1a2_s2a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/y8xvgniu\u001b[0m\n",
      "[2023-08-09 00:28:42,240][root][INFO] - => Done in 4.352 s\n",
      "[2023-08-09 00:28:42,240][root][INFO] - \n",
      "[2023-08-09 00:28:42,240][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:28:42,247][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:28:42,248][root][INFO] - => Done in 7.170 ms\n",
      "[2023-08-09 00:28:42,248][root][INFO] - \n",
      "[2023-08-09 00:28:42,248][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:28:42,854][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:28:42,854][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:28:42,854][root][INFO] - => Done in 606.561 ms\n",
      "[2023-08-09 00:28:42,854][root][INFO] - \n",
      "[2023-08-09 00:28:42,855][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:28:42,855][root][INFO] - => Done in 105.143 us\n",
      "[2023-08-09 00:28:42,855][root][INFO] - \n",
      "[2023-08-09 00:28:42,855][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:28:42,855][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:28:43,644][root][INFO] - => Done in 788.945 ms\n",
      "[2023-08-09 00:28:43,644][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01524\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01525\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99238\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1979.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s1a2_s2a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/y8xvgniu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_002838-y8xvgniu/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:29:19,692][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s1a2_s3a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_002920-42d0b8a4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s1a2_s3a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/42d0b8a4\u001b[0m\n",
      "[2023-08-09 00:29:25,198][root][INFO] - => Done in 5.505 s\n",
      "[2023-08-09 00:29:25,198][root][INFO] - \n",
      "[2023-08-09 00:29:25,198][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:29:25,201][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:29:25,201][root][INFO] - => Done in 3.087 ms\n",
      "[2023-08-09 00:29:25,201][root][INFO] - \n",
      "[2023-08-09 00:29:25,201][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:29:25,778][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:29:25,779][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:29:25,779][root][INFO] - => Done in 577.706 ms\n",
      "[2023-08-09 00:29:25,779][root][INFO] - \n",
      "[2023-08-09 00:29:25,779][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:29:25,779][root][INFO] - => Done in 138.044 us\n",
      "[2023-08-09 00:29:25,779][root][INFO] - \n",
      "[2023-08-09 00:29:25,779][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:29:25,779][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:29:26,554][root][INFO] - => Done in 775.052 ms\n",
      "[2023-08-09 00:29:26,554][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–†â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–‡â–ˆâ–‡â–‡â–†â–ˆâ–‡â–†â–‡â–‡â–†â–‡â–†â–‡â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–†â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–†â–‡â–‡â–†â–‡â–‡â–†â–‡â–†â–†â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–†â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–â–â–â–‚â–â–â–â–‚â–â–â–â–â–â–‚â–â–â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–â–â–â–‚â–â–â–â–‚â–â–â–â–â–â–‚â–â–â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–ˆâ–ˆâ–…â–†â–†â–„â–„â–„â–„â–‚â–ƒâ–…â–ƒâ–ƒâ–‚â–…â–„â–â–„â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–„â–‚â–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–ˆâ–ˆâ–…â–†â–†â–„â–„â–„â–„â–‚â–ƒâ–…â–ƒâ–ƒâ–‚â–…â–„â–â–„â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–„â–‚â–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–ˆâ–ˆâ–…â–†â–†â–„â–„â–„â–„â–‚â–ƒâ–…â–ƒâ–ƒâ–‚â–…â–„â–â–„â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–„â–‚â–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–ˆâ–ˆâ–…â–†â–†â–„â–„â–„â–„â–‚â–ƒâ–…â–ƒâ–ƒâ–‚â–…â–„â–â–„â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–„â–‚â–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.09633\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 3.20727\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 2.83881\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.26487\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 3.193\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 2.881\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.215\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.037\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.215\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.1035\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.88\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0065\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 207.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1760.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 13.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.1035\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.8795\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0065\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 207\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1759\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 13\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s1a2_s3a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/42d0b8a4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_002920-42d0b8a4/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:30:00,895][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s1a2_s4a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_003001-bp8syd4n\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s1a2_s4a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/bp8syd4n\u001b[0m\n",
      "[2023-08-09 00:30:06,011][root][INFO] - => Done in 5.117 s\n",
      "[2023-08-09 00:30:06,011][root][INFO] - \n",
      "[2023-08-09 00:30:06,012][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:30:06,015][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:30:06,015][root][INFO] - => Done in 3.226 ms\n",
      "[2023-08-09 00:30:06,015][root][INFO] - \n",
      "[2023-08-09 00:30:06,015][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:30:06,571][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:30:06,572][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:30:06,572][root][INFO] - => Done in 556.809 ms\n",
      "[2023-08-09 00:30:06,572][root][INFO] - \n",
      "[2023-08-09 00:30:06,572][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:30:06,572][root][INFO] - => Done in 106.812 us\n",
      "[2023-08-09 00:30:06,572][root][INFO] - \n",
      "[2023-08-09 00:30:06,572][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:30:06,572][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:30:07,347][root][INFO] - => Done in 774.862 ms\n",
      "[2023-08-09 00:30:07,347][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 1.012 MB of 1.024 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01523\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01521\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99241\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s1a2_s4a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/bp8syd4n\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_003001-bp8syd4n/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:30:42,795][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s1a2_s5a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_003043-8vm54tgg\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s1a2_s5a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/8vm54tgg\u001b[0m\n",
      "[2023-08-09 00:30:48,564][root][INFO] - => Done in 5.769 s\n",
      "[2023-08-09 00:30:48,566][root][INFO] - \n",
      "[2023-08-09 00:30:48,566][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:30:48,573][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:30:48,573][root][INFO] - => Done in 7.521 ms\n",
      "[2023-08-09 00:30:48,573][root][INFO] - \n",
      "[2023-08-09 00:30:48,573][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:30:49,144][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:30:49,144][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:30:49,144][root][INFO] - => Done in 570.450 ms\n",
      "[2023-08-09 00:30:49,144][root][INFO] - \n",
      "[2023-08-09 00:30:49,144][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:30:49,144][root][INFO] - => Done in 154.972 us\n",
      "[2023-08-09 00:30:49,144][root][INFO] - \n",
      "[2023-08-09 00:30:49,144][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:30:49,144][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:30:49,919][root][INFO] - => Done in 774.251 ms\n",
      "[2023-08-09 00:30:49,919][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 1.025 MB of 1.025 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–ˆâ–„â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–ˆâ–„â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–†â–ˆâ–ƒâ–„â–…â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–â–ƒâ–‚â–â–ƒâ–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–â–ƒâ–ƒâ–â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–…â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–†â–ˆâ–ƒâ–„â–…â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–â–ƒâ–‚â–â–ƒâ–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–â–ƒâ–ƒâ–â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–…â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–†â–ˆâ–ƒâ–„â–…â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–â–ƒâ–‚â–â–ƒâ–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–â–ƒâ–ƒâ–â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–…â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–†â–ˆâ–ƒâ–„â–…â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–â–ƒâ–‚â–â–ƒâ–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–â–ƒâ–ƒâ–â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–…â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.10083\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 3.20591\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 2.83994\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.26306\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 3.202\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 2.875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.2255\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.0385\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.2255\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.1085\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.8745\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.007\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 217.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1749.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 14.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.1085\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.874\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.007\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 217\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1748\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s1a2_s5a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/8vm54tgg\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_003043-8vm54tgg/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:31:25,494][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s2a2_s1a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_003126-0oqyir1a\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s2a2_s1a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/0oqyir1a\u001b[0m\n",
      "[2023-08-09 00:31:30,073][root][INFO] - => Done in 4.580 s\n",
      "[2023-08-09 00:31:30,074][root][INFO] - \n",
      "[2023-08-09 00:31:30,074][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:31:30,079][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:31:30,079][root][INFO] - => Done in 4.942 ms\n",
      "[2023-08-09 00:31:30,079][root][INFO] - \n",
      "[2023-08-09 00:31:30,079][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:31:30,680][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:31:30,680][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:31:30,681][root][INFO] - => Done in 601.603 ms\n",
      "[2023-08-09 00:31:30,681][root][INFO] - \n",
      "[2023-08-09 00:31:30,681][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:31:30,681][root][INFO] - => Done in 123.024 us\n",
      "[2023-08-09 00:31:30,681][root][INFO] - \n",
      "[2023-08-09 00:31:30,681][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:31:30,681][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:31:31,461][root][INFO] - => Done in 780.138 ms\n",
      "[2023-08-09 00:31:31,461][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01525\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.0152\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99244\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1979.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s2a2_s1a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/0oqyir1a\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_003126-0oqyir1a/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:32:06,490][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s2a2_s2a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_003207-muj0e56t\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s2a2_s2a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/muj0e56t\u001b[0m\n",
      "[2023-08-09 00:32:11,289][root][INFO] - => Done in 4.799 s\n",
      "[2023-08-09 00:32:11,289][root][INFO] - \n",
      "[2023-08-09 00:32:11,289][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:32:11,293][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:32:11,293][root][INFO] - => Done in 3.815 ms\n",
      "[2023-08-09 00:32:11,293][root][INFO] - \n",
      "[2023-08-09 00:32:11,293][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:32:11,880][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:32:11,881][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:32:11,881][root][INFO] - => Done in 587.784 ms\n",
      "[2023-08-09 00:32:11,881][root][INFO] - \n",
      "[2023-08-09 00:32:11,881][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:32:11,881][root][INFO] - => Done in 114.918 us\n",
      "[2023-08-09 00:32:11,881][root][INFO] - \n",
      "[2023-08-09 00:32:11,881][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:32:11,881][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:32:12,650][root][INFO] - => Done in 769.231 ms\n",
      "[2023-08-09 00:32:12,651][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 1.027 MB of 1.027 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01524\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01526\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99238\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1979.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s2a2_s2a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/muj0e56t\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_003207-muj0e56t/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:32:47,940][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s2a2_s3a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_003248-1farvais\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s2a2_s3a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/1farvais\u001b[0m\n",
      "[2023-08-09 00:32:52,322][root][INFO] - => Done in 4.382 s\n",
      "[2023-08-09 00:32:52,323][root][INFO] - \n",
      "[2023-08-09 00:32:52,323][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:32:52,327][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:32:52,327][root][INFO] - => Done in 4.495 ms\n",
      "[2023-08-09 00:32:52,327][root][INFO] - \n",
      "[2023-08-09 00:32:52,327][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:32:52,940][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:32:52,940][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:32:52,940][root][INFO] - => Done in 612.443 ms\n",
      "[2023-08-09 00:32:52,940][root][INFO] - \n",
      "[2023-08-09 00:32:52,940][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:32:52,940][root][INFO] - => Done in 122.786 us\n",
      "[2023-08-09 00:32:52,940][root][INFO] - \n",
      "[2023-08-09 00:32:52,940][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:32:52,940][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:32:53,723][root][INFO] - => Done in 782.734 ms\n",
      "[2023-08-09 00:32:53,723][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 1.028 MB of 1.028 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–†â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–†â–‡â–‡â–†â–‡â–†â–‡â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–†â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–†â–‡â–‡â–†â–‡â–‡â–†â–‡â–†â–‡â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–†â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–‚â–â–â–â–â–‚â–â–‚â–â–‚â–â–â–â–â–â–‚â–â–â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–‚â–â–â–â–â–‚â–â–‚â–â–‚â–â–â–â–â–â–‚â–â–â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–‡â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–ˆâ–ˆâ–…â–†â–†â–„â–„â–„â–„â–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–„â–„â–‚â–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–‡â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–ˆâ–ˆâ–…â–†â–†â–„â–„â–„â–„â–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–„â–„â–‚â–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–‡â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–ˆâ–ˆâ–…â–†â–†â–„â–„â–„â–„â–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–„â–„â–‚â–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–‡â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–ˆâ–ˆâ–…â–†â–†â–„â–„â–„â–„â–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–„â–„â–‚â–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.12033\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 3.20709\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 2.83952\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.26501\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 3.241\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 2.8645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.2555\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.05275\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.2555\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.1255\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.86\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 251.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1720.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 9.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.1255\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.86\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 251\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1720\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s2a2_s3a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/1farvais\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_003248-1farvais/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:33:29,054][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s2a2_s4a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_003330-ai4uv5hn\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s2a2_s4a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/ai4uv5hn\u001b[0m\n",
      "[2023-08-09 00:33:33,584][root][INFO] - => Done in 4.530 s\n",
      "[2023-08-09 00:33:33,584][root][INFO] - \n",
      "[2023-08-09 00:33:33,584][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:33:33,588][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:33:33,588][root][INFO] - => Done in 4.019 ms\n",
      "[2023-08-09 00:33:33,588][root][INFO] - \n",
      "[2023-08-09 00:33:33,589][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:33:34,185][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:33:34,185][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:33:34,185][root][INFO] - => Done in 596.667 ms\n",
      "[2023-08-09 00:33:34,185][root][INFO] - \n",
      "[2023-08-09 00:33:34,185][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:33:34,185][root][INFO] - => Done in 102.997 us\n",
      "[2023-08-09 00:33:34,185][root][INFO] - \n",
      "[2023-08-09 00:33:34,185][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:33:34,186][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:33:34,965][root][INFO] - => Done in 780.003 ms\n",
      "[2023-08-09 00:33:34,966][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01523\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01522\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99241\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s2a2_s4a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/ai4uv5hn\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_003330-ai4uv5hn/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:34:09,624][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s2a2_s5a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_003410-huw1t7am\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s2a2_s5a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/huw1t7am\u001b[0m\n",
      "[2023-08-09 00:34:14,454][root][INFO] - => Done in 4.830 s\n",
      "[2023-08-09 00:34:14,454][root][INFO] - \n",
      "[2023-08-09 00:34:14,454][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:34:14,457][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:34:14,457][root][INFO] - => Done in 3.109 ms\n",
      "[2023-08-09 00:34:14,457][root][INFO] - \n",
      "[2023-08-09 00:34:14,457][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:34:15,024][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:34:15,024][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:34:15,024][root][INFO] - => Done in 566.730 ms\n",
      "[2023-08-09 00:34:15,024][root][INFO] - \n",
      "[2023-08-09 00:34:15,024][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:34:15,024][root][INFO] - => Done in 111.818 us\n",
      "[2023-08-09 00:34:15,024][root][INFO] - \n",
      "[2023-08-09 00:34:15,024][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:34:15,025][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:34:15,789][root][INFO] - => Done in 764.386 ms\n",
      "[2023-08-09 00:34:15,789][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 1.030 MB of 1.030 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–ˆâ–„â–‚â–‚â–‚â–â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–ˆâ–„â–‚â–‚â–‚â–â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–†â–ˆâ–ƒâ–„â–…â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–â–‚â–â–‚â–‚â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–†â–ˆâ–ƒâ–„â–…â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–â–‚â–â–‚â–‚â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–†â–ˆâ–ƒâ–„â–…â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–â–‚â–â–‚â–‚â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–…â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–†â–ˆâ–ƒâ–„â–…â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–â–‚â–â–‚â–‚â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–…â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.09883\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 3.20601\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 2.84017\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.26381\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 3.198\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 2.889\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.2095\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.0435\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.2095\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.8855\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0025\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 204.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1771.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 5.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.8845\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0025\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 204\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1769\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s2a2_s5a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/huw1t7am\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_003410-huw1t7am/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:34:50,821][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s3a1_s1a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_003451-b23jxb3t\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s3a1_s1a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/b23jxb3t\u001b[0m\n",
      "[2023-08-09 00:34:55,861][root][INFO] - => Done in 5.040 s\n",
      "[2023-08-09 00:34:55,862][root][INFO] - \n",
      "[2023-08-09 00:34:55,862][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:34:55,865][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:34:55,865][root][INFO] - => Done in 3.014 ms\n",
      "[2023-08-09 00:34:55,865][root][INFO] - \n",
      "[2023-08-09 00:34:55,865][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:34:56,425][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:34:56,426][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:34:56,426][root][INFO] - => Done in 560.875 ms\n",
      "[2023-08-09 00:34:56,426][root][INFO] - \n",
      "[2023-08-09 00:34:56,426][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:34:56,426][root][INFO] - => Done in 111.103 us\n",
      "[2023-08-09 00:34:56,426][root][INFO] - \n",
      "[2023-08-09 00:34:56,426][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:34:56,426][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:34:57,196][root][INFO] - => Done in 770.397 ms\n",
      "[2023-08-09 00:34:57,197][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01533\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01544\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99248\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.989\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1978.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.989\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1978\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s3a1_s1a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/b23jxb3t\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_003451-b23jxb3t/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:35:32,214][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s3a1_s2a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_003533-pp0i4rvt\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s3a1_s2a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/pp0i4rvt\u001b[0m\n",
      "[2023-08-09 00:35:38,652][root][INFO] - => Done in 6.438 s\n",
      "[2023-08-09 00:35:38,652][root][INFO] - \n",
      "[2023-08-09 00:35:38,652][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:35:38,655][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:35:38,655][root][INFO] - => Done in 2.936 ms\n",
      "[2023-08-09 00:35:38,655][root][INFO] - \n",
      "[2023-08-09 00:35:38,655][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:35:39,243][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:35:39,243][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:35:39,243][root][INFO] - => Done in 588.690 ms\n",
      "[2023-08-09 00:35:39,243][root][INFO] - \n",
      "[2023-08-09 00:35:39,244][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:35:39,244][root][INFO] - => Done in 103.951 us\n",
      "[2023-08-09 00:35:39,244][root][INFO] - \n",
      "[2023-08-09 00:35:39,244][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:35:39,244][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:35:40,013][root][INFO] - => Done in 769.273 ms\n",
      "[2023-08-09 00:35:40,013][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 1.033 MB of 1.033 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01524\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01542\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99246\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1979.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s3a1_s2a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/pp0i4rvt\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_003533-pp0i4rvt/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:36:14,283][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s3a1_s3a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_003615-d2929tqq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s3a1_s3a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/d2929tqq\u001b[0m\n",
      "[2023-08-09 00:36:19,117][root][INFO] - => Done in 4.834 s\n",
      "[2023-08-09 00:36:19,118][root][INFO] - \n",
      "[2023-08-09 00:36:19,118][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:36:19,122][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:36:19,122][root][INFO] - => Done in 4.011 ms\n",
      "[2023-08-09 00:36:19,122][root][INFO] - \n",
      "[2023-08-09 00:36:19,122][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:36:19,706][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:36:19,706][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:36:19,706][root][INFO] - => Done in 584.186 ms\n",
      "[2023-08-09 00:36:19,706][root][INFO] - \n",
      "[2023-08-09 00:36:19,706][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:36:19,706][root][INFO] - => Done in 144.005 us\n",
      "[2023-08-09 00:36:19,706][root][INFO] - \n",
      "[2023-08-09 00:36:19,707][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:36:19,707][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:36:20,483][root][INFO] - => Done in 776.065 ms\n",
      "[2023-08-09 00:36:20,483][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 1.034 MB of 1.034 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–†â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–†â–‡â–‡â–†â–‡â–‡â–†â–†â–†â–‡â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–ˆâ–†â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–†â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–†â–‡â–‡â–†â–‡â–‡â–†â–†â–†â–†â–‡â–†â–‡â–†â–‡â–‡â–‡â–†â–‡â–‡â–‡â–†â–ˆâ–†â–†â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–‚â–â–â–‚â–‚â–â–â–â–‚â–â–‚â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–‚â–â–â–‚â–‚â–â–â–â–‚â–â–‚â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–ƒâ–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–ƒâ–â–â–â–†â–â–ˆâ–â–â–â–â–†â–â–â–â–â–â–†â–â–â–‚â–â–…â–â–â–â–†â–„â–â–â–‚â–â–â–†â–…â–â–â–†â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–ˆâ–ˆâ–†â–‡â–†â–„â–„â–ƒâ–„â–ƒâ–„â–…â–ƒâ–ƒâ–ƒâ–„â–„â–‚â–„â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–†â–‚â–‚â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–ƒâ–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–ƒâ–â–â–â–†â–â–ˆâ–â–â–â–â–†â–â–â–â–â–â–†â–â–â–‚â–â–…â–â–â–â–†â–„â–â–â–‚â–â–â–†â–…â–â–â–†â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–ˆâ–ˆâ–†â–‡â–†â–„â–„â–ƒâ–„â–ƒâ–„â–…â–ƒâ–ƒâ–ƒâ–„â–„â–‚â–„â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–†â–‚â–‚â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–ƒâ–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–ƒâ–â–â–â–†â–â–ˆâ–â–â–â–â–†â–â–â–â–â–â–†â–â–â–‚â–â–…â–â–â–â–†â–„â–â–â–‚â–â–â–†â–…â–â–â–†â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–ˆâ–ˆâ–†â–‡â–†â–„â–„â–ƒâ–„â–ƒâ–„â–…â–ƒâ–ƒâ–ƒâ–„â–„â–‚â–„â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–†â–‚â–‚â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–ƒâ–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–ƒâ–â–â–â–†â–â–ˆâ–â–â–â–â–†â–â–â–â–â–â–†â–â–â–‚â–â–…â–â–â–â–†â–„â–â–â–‚â–â–â–†â–…â–â–â–†â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–ˆâ–ˆâ–†â–‡â–†â–„â–„â–ƒâ–„â–ƒâ–„â–…â–ƒâ–ƒâ–ƒâ–„â–„â–‚â–„â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–†â–‚â–‚â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.10333\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 3.20455\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 2.84083\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.26982\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 3.192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 2.8935\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.2245\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.04275\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.2245\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.8805\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 9.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 199.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1761.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 10.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.88\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 199\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1760\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s3a1_s3a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/d2929tqq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_003615-d2929tqq/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:36:56,652][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s3a1_s4a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_003657-avjp4r66\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s3a1_s4a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/avjp4r66\u001b[0m\n",
      "[2023-08-09 00:37:01,594][root][INFO] - => Done in 4.942 s\n",
      "[2023-08-09 00:37:01,594][root][INFO] - \n",
      "[2023-08-09 00:37:01,594][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:37:01,598][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:37:01,598][root][INFO] - => Done in 3.370 ms\n",
      "[2023-08-09 00:37:01,598][root][INFO] - \n",
      "[2023-08-09 00:37:01,598][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:37:02,179][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:37:02,180][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:37:02,180][root][INFO] - => Done in 581.876 ms\n",
      "[2023-08-09 00:37:02,180][root][INFO] - \n",
      "[2023-08-09 00:37:02,180][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:37:02,180][root][INFO] - => Done in 112.057 us\n",
      "[2023-08-09 00:37:02,180][root][INFO] - \n",
      "[2023-08-09 00:37:02,180][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:37:02,180][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:37:02,956][root][INFO] - => Done in 776.055 ms\n",
      "[2023-08-09 00:37:02,956][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01526\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01541\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99248\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s3a1_s4a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/avjp4r66\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_003657-avjp4r66/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:37:39,426][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s3a1_s5a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_003740-p70v62kt\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s3a1_s5a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/p70v62kt\u001b[0m\n",
      "[2023-08-09 00:37:44,660][root][INFO] - => Done in 5.234 s\n",
      "[2023-08-09 00:37:44,660][root][INFO] - \n",
      "[2023-08-09 00:37:44,660][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:37:44,663][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:37:44,664][root][INFO] - => Done in 3.169 ms\n",
      "[2023-08-09 00:37:44,664][root][INFO] - \n",
      "[2023-08-09 00:37:44,664][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:37:45,234][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:37:45,234][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:37:45,234][root][INFO] - => Done in 570.180 ms\n",
      "[2023-08-09 00:37:45,234][root][INFO] - \n",
      "[2023-08-09 00:37:45,234][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:37:45,234][root][INFO] - => Done in 107.050 us\n",
      "[2023-08-09 00:37:45,234][root][INFO] - \n",
      "[2023-08-09 00:37:45,234][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:37:45,234][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:37:46,017][root][INFO] - => Done in 782.837 ms\n",
      "[2023-08-09 00:37:46,017][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–ˆâ–„â–‚â–‚â–‚â–â–â–â–‚â–‚â–â–â–â–â–â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–ˆâ–„â–‚â–‚â–‚â–â–â–â–‚â–‚â–â–â–â–â–â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–‚â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–‡â–â–â–â–…â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–ƒâ–â–â–â–†â–â–‡â–â–â–â–â–†â–â–â–â–â–â–†â–â–â–‚â–â–…â–â–â–â–†â–†â–â–â–ˆâ–â–â–‡â–„â–â–â–†â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–‡â–ˆâ–„â–…â–…â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–â–ƒâ–ƒâ–‚â–‚â–„â–ƒâ–‚â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–…â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–‚â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–‡â–â–â–â–…â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–ƒâ–â–â–â–†â–â–‡â–â–â–â–â–†â–â–â–â–â–â–†â–â–â–‚â–â–…â–â–â–â–†â–†â–â–â–ˆâ–â–â–‡â–„â–â–â–†â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–‡â–ˆâ–„â–…â–…â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–â–ƒâ–ƒâ–‚â–‚â–„â–ƒâ–‚â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–…â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–‚â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–‡â–â–â–â–…â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–ƒâ–â–â–â–†â–â–‡â–â–â–â–â–†â–â–â–â–â–â–†â–â–â–‚â–â–…â–â–â–â–†â–†â–â–â–ˆâ–â–â–‡â–„â–â–â–†â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–‡â–ˆâ–„â–…â–…â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–â–ƒâ–ƒâ–‚â–‚â–„â–ƒâ–‚â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–…â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–‚â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–‡â–â–â–â–…â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–ƒâ–â–â–â–†â–â–‡â–â–â–â–â–†â–â–â–â–â–â–†â–â–â–‚â–â–…â–â–â–â–†â–†â–â–â–ˆâ–â–â–‡â–„â–â–â–†â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–‡â–ˆâ–„â–…â–…â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–â–ƒâ–ƒâ–‚â–‚â–„â–ƒâ–‚â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–…â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.10883\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 3.20417\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 2.84464\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.26571\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 3.203\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 2.8895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.234\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.04625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.234\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.1045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.876\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 9.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 209.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1752.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 9.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.1045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.8755\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 209\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1751\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s3a1_s5a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/p70v62kt\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_003740-p70v62kt/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:38:20,948][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s4a2_s1a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_003822-krkvqdkc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s4a2_s1a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/krkvqdkc\u001b[0m\n",
      "[2023-08-09 00:38:26,860][root][INFO] - => Done in 5.912 s\n",
      "[2023-08-09 00:38:26,860][root][INFO] - \n",
      "[2023-08-09 00:38:26,860][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:38:26,866][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:38:26,866][root][INFO] - => Done in 5.627 ms\n",
      "[2023-08-09 00:38:26,866][root][INFO] - \n",
      "[2023-08-09 00:38:26,866][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:38:27,436][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:38:27,436][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:38:27,436][root][INFO] - => Done in 569.879 ms\n",
      "[2023-08-09 00:38:27,436][root][INFO] - \n",
      "[2023-08-09 00:38:27,436][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:38:27,436][root][INFO] - => Done in 120.878 us\n",
      "[2023-08-09 00:38:27,436][root][INFO] - \n",
      "[2023-08-09 00:38:27,436][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:38:27,436][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:38:28,220][root][INFO] - => Done in 783.803 ms\n",
      "[2023-08-09 00:38:28,220][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01524\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01554\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99262\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1979.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s4a2_s1a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/krkvqdkc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_003822-krkvqdkc/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:39:02,671][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s4a2_s2a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_003903-272b1p4e\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s4a2_s2a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/272b1p4e\u001b[0m\n",
      "[2023-08-09 00:39:07,758][root][INFO] - => Done in 5.086 s\n",
      "[2023-08-09 00:39:07,758][root][INFO] - \n",
      "[2023-08-09 00:39:07,758][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:39:07,761][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:39:07,761][root][INFO] - => Done in 3.519 ms\n",
      "[2023-08-09 00:39:07,762][root][INFO] - \n",
      "[2023-08-09 00:39:07,762][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:39:08,331][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:39:08,331][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:39:08,331][root][INFO] - => Done in 569.375 ms\n",
      "[2023-08-09 00:39:08,331][root][INFO] - \n",
      "[2023-08-09 00:39:08,331][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:39:08,331][root][INFO] - => Done in 109.911 us\n",
      "[2023-08-09 00:39:08,331][root][INFO] - \n",
      "[2023-08-09 00:39:08,331][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:39:08,331][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:39:09,106][root][INFO] - => Done in 774.787 ms\n",
      "[2023-08-09 00:39:09,106][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01516\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01553\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99259\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s4a2_s2a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/272b1p4e\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_003903-272b1p4e/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:39:45,023][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s4a2_s3a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_003945-39mcfvbf\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s4a2_s3a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/39mcfvbf\u001b[0m\n",
      "[2023-08-09 00:39:49,947][root][INFO] - => Done in 4.924 s\n",
      "[2023-08-09 00:39:49,948][root][INFO] - \n",
      "[2023-08-09 00:39:49,948][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:39:49,951][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:39:49,951][root][INFO] - => Done in 3.284 ms\n",
      "[2023-08-09 00:39:49,951][root][INFO] - \n",
      "[2023-08-09 00:39:49,951][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:39:50,515][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:39:50,515][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:39:50,515][root][INFO] - => Done in 563.823 ms\n",
      "[2023-08-09 00:39:50,515][root][INFO] - \n",
      "[2023-08-09 00:39:50,515][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:39:50,515][root][INFO] - => Done in 110.865 us\n",
      "[2023-08-09 00:39:50,515][root][INFO] - \n",
      "[2023-08-09 00:39:50,515][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:39:50,515][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:39:51,283][root][INFO] - => Done in 768.211 ms\n",
      "[2023-08-09 00:39:51,284][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–†â–‡â–‡â–†â–‡â–‡â–†â–‡â–†â–†â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–†â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–†â–‡â–‡â–†â–‡â–‡â–†â–‡â–†â–‡â–‡â–†â–‡â–†â–‡â–‡â–‡â–†â–‡â–‡â–‡â–†â–‡â–†â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–ˆâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–â–â–â–‚â–â–‚â–‚â–‚â–â–â–â–â–â–‚â–â–â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–ˆâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–â–â–â–‚â–â–‚â–‚â–‚â–â–â–â–â–â–‚â–â–â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–…â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–‡â–„â–â–â–â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–ˆâ–ˆâ–…â–†â–‡â–„â–„â–„â–„â–ƒâ–ƒâ–…â–„â–ƒâ–ƒâ–…â–„â–â–…â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–…â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–‡â–„â–â–â–â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–ˆâ–ˆâ–…â–†â–‡â–„â–„â–„â–„â–ƒâ–ƒâ–…â–„â–ƒâ–ƒâ–…â–„â–â–…â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–…â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–…â–„â–â–â–â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–ˆâ–ˆâ–…â–†â–‡â–„â–„â–„â–„â–ƒâ–ƒâ–…â–„â–ƒâ–ƒâ–…â–„â–â–…â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–…â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–…â–„â–â–â–â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–ˆâ–ˆâ–…â–†â–‡â–„â–„â–„â–„â–ƒâ–ƒâ–…â–„â–ƒâ–ƒâ–…â–„â–â–…â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.13217\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 3.20834\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 2.83838\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.2688\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 3.2565\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 2.8575\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.2825\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.057\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.2825\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.134\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.8485\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 3.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 268.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1697.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 10.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.134\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.848\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 268\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1696\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s4a2_s3a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/39mcfvbf\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_003945-39mcfvbf/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:40:25,206][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s4a2_s4a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_004026-4orynohh\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s4a2_s4a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/4orynohh\u001b[0m\n",
      "[2023-08-09 00:40:30,404][root][INFO] - => Done in 5.198 s\n",
      "[2023-08-09 00:40:30,405][root][INFO] - \n",
      "[2023-08-09 00:40:30,405][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:40:30,408][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:40:30,408][root][INFO] - => Done in 3.582 ms\n",
      "[2023-08-09 00:40:30,408][root][INFO] - \n",
      "[2023-08-09 00:40:30,408][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:40:30,967][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:40:30,967][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:40:30,967][root][INFO] - => Done in 558.952 ms\n",
      "[2023-08-09 00:40:30,967][root][INFO] - \n",
      "[2023-08-09 00:40:30,967][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:40:30,968][root][INFO] - => Done in 142.097 us\n",
      "[2023-08-09 00:40:30,968][root][INFO] - \n",
      "[2023-08-09 00:40:30,968][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:40:30,968][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:40:31,755][root][INFO] - => Done in 786.980 ms\n",
      "[2023-08-09 00:40:31,755][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01517\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.0155\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99262\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s4a2_s4a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/4orynohh\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_004026-4orynohh/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:41:08,143][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s4a2_s5a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_004109-430qswlp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s4a2_s5a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/430qswlp\u001b[0m\n",
      "[2023-08-09 00:41:14,311][root][INFO] - => Done in 6.167 s\n",
      "[2023-08-09 00:41:14,311][root][INFO] - \n",
      "[2023-08-09 00:41:14,311][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:41:14,318][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:41:14,319][root][INFO] - => Done in 7.323 ms\n",
      "[2023-08-09 00:41:14,319][root][INFO] - \n",
      "[2023-08-09 00:41:14,319][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:41:14,893][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:41:14,893][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:41:14,893][root][INFO] - => Done in 574.459 ms\n",
      "[2023-08-09 00:41:14,893][root][INFO] - \n",
      "[2023-08-09 00:41:14,893][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:41:14,893][root][INFO] - => Done in 124.216 us\n",
      "[2023-08-09 00:41:14,893][root][INFO] - \n",
      "[2023-08-09 00:41:14,893][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:41:14,894][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:41:15,690][root][INFO] - => Done in 796.586 ms\n",
      "[2023-08-09 00:41:15,690][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–ˆâ–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–ˆâ–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–â–â–â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–ˆâ–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–â–â–â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‡â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–…â–„â–â–â–â–ˆâ–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–†â–ˆâ–ƒâ–„â–…â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–„â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚ï¿½ï¿½ï¿½\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‡â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–…â–„â–â–â–â–ˆâ–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–†â–ˆâ–ƒâ–„â–…â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–„â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‡â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–ƒâ–„â–â–â–â–ˆâ–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–†â–ˆâ–ƒâ–„â–…â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–„â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–…â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‡â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–ƒâ–„â–â–â–â–ˆâ–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–†â–ˆâ–ƒâ–„â–…â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–„â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–…â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.09833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 3.20502\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 2.84078\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.26445\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 3.197\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 2.885\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.213\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.041\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.213\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.1035\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.882\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 207.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1764.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 9.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.1035\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.8815\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 207\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1763\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s4a2_s5a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/430qswlp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_004109-430qswlp/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:41:50,165][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s5a1_s1a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_004151-6mmy6dc1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s5a1_s1a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/6mmy6dc1\u001b[0m\n",
      "[2023-08-09 00:41:55,584][root][INFO] - => Done in 5.419 s\n",
      "[2023-08-09 00:41:55,584][root][INFO] - \n",
      "[2023-08-09 00:41:55,584][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:41:55,590][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:41:55,590][root][INFO] - => Done in 6.195 ms\n",
      "[2023-08-09 00:41:55,591][root][INFO] - \n",
      "[2023-08-09 00:41:55,591][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:41:56,169][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:41:56,170][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:41:56,170][root][INFO] - => Done in 579.094 ms\n",
      "[2023-08-09 00:41:56,170][root][INFO] - \n",
      "[2023-08-09 00:41:56,170][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:41:56,170][root][INFO] - => Done in 146.866 us\n",
      "[2023-08-09 00:41:56,170][root][INFO] - \n",
      "[2023-08-09 00:41:56,170][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:41:56,170][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:41:56,957][root][INFO] - => Done in 787.147 ms\n",
      "[2023-08-09 00:41:56,957][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01525\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01556\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99261\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s5a1_s1a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/6mmy6dc1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_004151-6mmy6dc1/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:42:31,020][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s5a1_s2a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_004232-7axafrtx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s5a1_s2a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/7axafrtx\u001b[0m\n",
      "[2023-08-09 00:42:35,849][root][INFO] - => Done in 4.829 s\n",
      "[2023-08-09 00:42:35,850][root][INFO] - \n",
      "[2023-08-09 00:42:35,850][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:42:35,854][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:42:35,854][root][INFO] - => Done in 4.193 ms\n",
      "[2023-08-09 00:42:35,854][root][INFO] - \n",
      "[2023-08-09 00:42:35,854][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:42:36,458][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:42:36,458][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:42:36,458][root][INFO] - => Done in 604.052 ms\n",
      "[2023-08-09 00:42:36,458][root][INFO] - \n",
      "[2023-08-09 00:42:36,458][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:42:36,458][root][INFO] - => Done in 117.064 us\n",
      "[2023-08-09 00:42:36,459][root][INFO] - \n",
      "[2023-08-09 00:42:36,459][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:42:36,459][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:42:37,248][root][INFO] - => Done in 789.069 ms\n",
      "[2023-08-09 00:42:37,248][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 1.043 MB of 1.043 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.0152\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01557\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99258\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s5a1_s2a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/7axafrtx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_004232-7axafrtx/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:43:13,228][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s5a1_s3a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_004314-clh32tuk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s5a1_s3a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/clh32tuk\u001b[0m\n",
      "[2023-08-09 00:43:17,940][root][INFO] - => Done in 4.713 s\n",
      "[2023-08-09 00:43:17,941][root][INFO] - \n",
      "[2023-08-09 00:43:17,941][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:43:17,944][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:43:17,944][root][INFO] - => Done in 3.443 ms\n",
      "[2023-08-09 00:43:17,944][root][INFO] - \n",
      "[2023-08-09 00:43:17,944][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:43:18,536][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:43:18,536][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:43:18,536][root][INFO] - => Done in 591.567 ms\n",
      "[2023-08-09 00:43:18,536][root][INFO] - \n",
      "[2023-08-09 00:43:18,536][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:43:18,536][root][INFO] - => Done in 142.097 us\n",
      "[2023-08-09 00:43:18,536][root][INFO] - \n",
      "[2023-08-09 00:43:18,536][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:43:18,536][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:43:19,320][root][INFO] - => Done in 783.646 ms\n",
      "[2023-08-09 00:43:19,320][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–†â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–†â–‡â–†â–‡â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–†â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–†â–†â–‡â–†â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–â–â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–â–â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–„â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–„â–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–‚â–‚â–â–â–‚â–†â–â–ˆâ–â–„â–â–â–†â–â–â–â–â–â–†â–â–â–‚â–â–†â–â–â–â–†â–‡â–â–â–‚â–â–â–†â–‚â–â–â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–ˆâ–ˆâ–…â–†â–†â–„â–„â–ƒâ–„â–ƒâ–ƒâ–…â–„â–ƒâ–ƒâ–„â–„â–‚â–„â–„â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–„â–‚â–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–„â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–„â–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–‚â–‚â–â–â–‚â–†â–â–ˆâ–â–„â–â–â–†â–â–â–â–â–â–†â–â–â–‚â–â–†â–â–â–â–†â–‡â–â–â–‚â–â–â–†â–‚â–â–â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–ˆâ–ˆâ–…â–†â–†â–„â–„â–ƒâ–„â–ƒâ–ƒâ–…â–„â–ƒâ–ƒâ–„â–„â–‚â–„â–„â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–„â–‚â–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–„â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–„â–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–‚â–‚â–â–â–‚â–†â–â–ˆâ–â–„â–â–â–†â–â–â–â–â–â–†â–â–â–‚â–â–†â–â–â–â–†â–‡â–â–â–‚â–â–â–†â–‚â–â–â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–ˆâ–ˆâ–…â–†â–†â–„â–„â–ƒâ–„â–ƒâ–ƒâ–…â–„â–ƒâ–ƒâ–„â–„â–‚â–„â–„â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–„â–‚â–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–„â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–„â–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–‚â–‚â–â–â–‚â–†â–â–ˆâ–â–„â–â–â–†â–â–â–â–â–â–†â–â–â–‚â–â–†â–â–â–â–†â–‡â–â–â–‚â–â–â–†â–‚â–â–â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–ˆâ–ˆâ–…â–†â–†â–„â–„â–ƒâ–„â–ƒâ–ƒâ–…â–„â–ƒâ–ƒâ–„â–„â–‚â–„â–„â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–„â–‚â–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.10833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 3.2053\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 2.84372\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.26953\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 3.202\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 2.8885\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.2345\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.04525\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.2345\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.1045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.8755\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 9.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 209.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1751.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 10.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.1045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 209\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1750\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s5a1_s3a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/clh32tuk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_004314-clh32tuk/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:43:54,865][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s5a1_s4a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_004355-4t90cbqj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s5a1_s4a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/4t90cbqj\u001b[0m\n",
      "[2023-08-09 00:44:00,465][root][INFO] - => Done in 5.600 s\n",
      "[2023-08-09 00:44:00,465][root][INFO] - \n",
      "[2023-08-09 00:44:00,465][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:44:00,472][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:44:00,472][root][INFO] - => Done in 7.451 ms\n",
      "[2023-08-09 00:44:00,473][root][INFO] - \n",
      "[2023-08-09 00:44:00,473][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:44:01,052][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:44:01,052][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:44:01,052][root][INFO] - => Done in 579.439 ms\n",
      "[2023-08-09 00:44:01,052][root][INFO] - \n",
      "[2023-08-09 00:44:01,052][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:44:01,052][root][INFO] - => Done in 132.084 us\n",
      "[2023-08-09 00:44:01,052][root][INFO] - \n",
      "[2023-08-09 00:44:01,053][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:44:01,053][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:44:01,831][root][INFO] - => Done in 778.640 ms\n",
      "[2023-08-09 00:44:01,831][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–‚â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01522\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01556\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.9926\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1979.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s5a1_s4a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/4t90cbqj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_004355-4t90cbqj/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 00:44:37,109][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s5a1_s5a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_004438-5icts9ha\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s5a1_s5a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/5icts9ha\u001b[0m\n",
      "[2023-08-09 00:44:41,778][root][INFO] - => Done in 4.669 s\n",
      "[2023-08-09 00:44:41,779][root][INFO] - \n",
      "[2023-08-09 00:44:41,779][root][INFO] - => Env setup ...\n",
      "[2023-08-09 00:44:41,782][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 00:44:41,782][root][INFO] - => Done in 3.261 ms\n",
      "[2023-08-09 00:44:41,782][root][INFO] - \n",
      "[2023-08-09 00:44:41,782][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 00:44:42,376][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 00:44:42,376][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 00:44:42,376][root][INFO] - => Done in 594.320 ms\n",
      "[2023-08-09 00:44:42,376][root][INFO] - \n",
      "[2023-08-09 00:44:42,376][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 00:44:42,377][root][INFO] - => Done in 113.010 us\n",
      "[2023-08-09 00:44:42,377][root][INFO] - \n",
      "[2023-08-09 00:44:42,377][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 00:44:42,377][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 00:44:43,148][root][INFO] - => Done in 771.246 ms\n",
      "[2023-08-09 00:44:43,148][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–ˆâ–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–ˆâ–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–ˆâ–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–ˆâ–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–‚â–â–â–â–†â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–‡â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–‚â–â–â–â–…â–â–…â–â–ƒâ–â–â–…â–â–â–â–â–â–…â–â–â–‚â–â–…â–â–â–â–…â–ˆâ–â–â–‡â–â–â–…â–â–â–â–…â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–†â–ˆâ–ƒâ–…â–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–â–ƒâ–ƒâ–‚â–ƒâ–„â–ƒâ–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–‚â–â–â–â–†â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–‡â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–‚â–â–â–â–…â–â–…â–â–ƒâ–â–â–…â–â–â–â–â–â–…â–â–â–‚â–â–…â–â–â–â–…â–ˆâ–â–â–‡â–â–â–…â–â–â–â–…â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–†â–ˆâ–ƒâ–…â–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–â–ƒâ–ƒâ–‚â–ƒâ–„â–ƒâ–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–‚â–â–â–â–†â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–‡â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–‚â–â–â–â–…â–â–…â–â–ƒâ–â–â–…â–â–â–â–â–â–…â–â–â–‚â–â–…â–â–â–â–…â–ˆâ–â–â–‡â–â–â–…â–â–â–â–…â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–†â–ˆâ–ƒâ–…â–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–â–ƒâ–ƒâ–‚â–ƒâ–„â–ƒâ–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–…â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–‚â–â–â–â–†â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–‡â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–‚â–â–â–â–…â–â–…â–â–ƒâ–â–â–…â–â–â–â–â–â–…â–â–â–‚â–â–…â–â–â–â–…â–ˆâ–â–â–‡â–â–â–…â–â–â–â–…â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–†â–ˆâ–ƒâ–…â–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–â–ƒâ–ƒâ–‚â–ƒâ–„â–ƒâ–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–…â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.11283\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 3.20516\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 2.8431\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.2701\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 3.2125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 2.884\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.242\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.04825\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.242\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.1095\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.871\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 9.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 219.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1742.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 10.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.1095\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.871\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 219\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1742\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s5a1_s5a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/5icts9ha\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_004438-5icts9ha/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# they all did ddc so I expect the shapers to be compatible to each other\n",
    "\n",
    "import yaml\n",
    "game= \"ipd\"\n",
    "num_pl = 3\n",
    "num_shap = 2\n",
    "mean = [(1,2), (2,2), (3,1), (4,2), (5,1)]\n",
    "nice = [(1,1), (2,1), (3,2), (4,1), (5,2)]\n",
    "\n",
    "# mean v mean\n",
    "for seed1,agent1 in mean:\n",
    "    for seed2,agent2 in mean:\n",
    "        ########## shaper1\n",
    "        yaml_f = f\"/Users/alexandrasouly/code/pax/pax/conf/experiment/multi-shapers/eval/n{num_pl}pl_{num_shap}shap_{game}_eval{seed1}.yaml\"\n",
    "        with open(yaml_f) as f:\n",
    "            config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        run_path1 = config[f'run_path{agent1}']\n",
    "        agent_path1 =   config[f'model_path{agent1}']\n",
    "        ########## shaper 2\n",
    "        yaml_f = f\"/Users/alexandrasouly/code/pax/pax/conf/experiment/multi-shapers/eval/n{num_pl}pl_{num_shap}shap_{game}_eval{seed2}.yaml\"\n",
    "        with open(yaml_f) as f:\n",
    "            config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        run_path2 = config[f'run_path{agent2}']\n",
    "        agent_path2 =   config[f'model_path{agent2}']\n",
    "        ############# run experiment\n",
    "        name = f\"{num_pl}pl_{num_shap}shap_{game}_s{seed1}a{agent1}_s{seed2}a{agent2}_eval\"\n",
    "        group = f'{num_pl}pl_{num_shap}shap_{game}-comp-mean_v_mean'\n",
    "        !/Users/alexandrasouly/miniconda3/envs/pax/bin/python3 -m pax.experiment +experiment=multi-shapers/comp/n{num_pl}pl_{num_shap}shap_{game}_comp_eval ++run_path1={run_path1} ++run_path2={run_path2} ++model_path1={agent_path1} ++model_path2={agent_path2} ++wandb.name={name} ++wandb.group={group}\n",
    "\n",
    "\n",
    "# nice v nice\n",
    "for seed1,agent1 in nice:\n",
    "    for seed2,agent2 in nice:\n",
    "        ########## shaper1\n",
    "        yaml_f = f\"/Users/alexandrasouly/code/pax/pax/conf/experiment/multi-shapers/eval/n{num_pl}pl_{num_shap}shap_{game}_eval{seed1}.yaml\"\n",
    "        with open(yaml_f) as f:\n",
    "            config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        run_path1 = config[f'run_path{agent1}']\n",
    "        agent_path1 =   config[f'model_path{agent1}']\n",
    "        ########## shaper 2\n",
    "        yaml_f = f\"/Users/alexandrasouly/code/pax/pax/conf/experiment/multi-shapers/eval/n{num_pl}pl_{num_shap}shap_{game}_eval{seed2}.yaml\"\n",
    "        with open(yaml_f) as f:\n",
    "            config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        run_path2 = config[f'run_path{agent2}']\n",
    "        agent_path2 =   config[f'model_path{agent2}']\n",
    "        ############# run experiment\n",
    "        name = f\"{num_pl}pl_{num_shap}shap_{game}_s{seed1}a{agent1}_s{seed2}a{agent2}_eval\"\n",
    "        group = f'{num_pl}pl_{num_shap}shap_{game}-comp-nice_v_nice'\n",
    "        !/Users/alexandrasouly/miniconda3/envs/pax/bin/python3 -m pax.experiment +experiment=multi-shapers/comp/n{num_pl}pl_{num_shap}shap_{game}_comp_eval ++run_path1={run_path1} ++run_path2={run_path2} ++model_path1={agent_path1} ++model_path2={agent_path2} ++wandb.name={name} ++wandb.group={group}\n",
    "\n",
    "\n",
    "# mean v nice\n",
    "for seed1,agent1 in mean:\n",
    "    for seed2,agent2 in nice:\n",
    "        ########## shaper1\n",
    "        yaml_f = f\"/Users/alexandrasouly/code/pax/pax/conf/experiment/multi-shapers/eval/n{num_pl}pl_{num_shap}shap_{game}_eval{seed1}.yaml\"\n",
    "        with open(yaml_f) as f:\n",
    "            config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        run_path1 = config[f'run_path{agent1}']\n",
    "        agent_path1 =   config[f'model_path{agent1}']\n",
    "        ########## shaper 2\n",
    "        yaml_f = f\"/Users/alexandrasouly/code/pax/pax/conf/experiment/multi-shapers/eval/n{num_pl}pl_{num_shap}shap_{game}_eval{seed2}.yaml\"\n",
    "        with open(yaml_f) as f:\n",
    "            config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        run_path2 = config[f'run_path{agent2}']\n",
    "        agent_path2 =   config[f'model_path{agent2}']\n",
    "        ############# run experiment\n",
    "        name = f\"{num_pl}pl_{num_shap}shap_{game}_s{seed1}a{agent1}_s{seed2}a{agent2}_eval\"\n",
    "        group = f'{num_pl}pl_{num_shap}shap_{game}-comp-mean_v_nice'\n",
    "        !/Users/alexandrasouly/miniconda3/envs/pax/bin/python3 -m pax.experiment +experiment=multi-shapers/comp/n{num_pl}pl_{num_shap}shap_{game}_comp_eval ++run_path1={run_path1} ++run_path2={run_path2} ++model_path1={agent_path1} ++model_path2={agent_path2} ++wandb.name={name} ++wandb.group={group}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 18:15:31,890][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s1a1_s1a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_181533-ziwcp9yp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s1a1_s1a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/ziwcp9yp\u001b[0m\n",
      "[2023-08-08 18:15:36,714][root][INFO] - => Done in 4.825 s\n",
      "[2023-08-08 18:15:36,715][root][INFO] - \n",
      "[2023-08-08 18:15:36,715][root][INFO] - => Env setup ...\n",
      "[2023-08-08 18:15:36,718][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 18:15:36,719][root][INFO] - => Done in 3.866 ms\n",
      "[2023-08-08 18:15:36,719][root][INFO] - \n",
      "[2023-08-08 18:15:36,719][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 18:15:37,337][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 18:15:37,337][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 18:15:37,337][root][INFO] - => Done in 618.588 ms\n",
      "[2023-08-08 18:15:37,337][root][INFO] - \n",
      "[2023-08-08 18:15:37,338][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 18:15:37,338][root][INFO] - => Done in 275.373 us\n",
      "[2023-08-08 18:15:37,338][root][INFO] - \n",
      "[2023-08-08 18:15:37,338][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 18:15:37,338][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 18:15:38,147][root][INFO] - => Done in 808.660 ms\n",
      "[2023-08-08 18:15:38,147][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 0.906 MB of 0.906 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–…â–…â–„â–…â–…â–…â–†â–†â–…â–‡â–‡â–†â–†â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–†â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–‡â–‡â–…â–…â–„â–ƒâ–‡â–†â–â–ƒâ–„â–„â–â–‡â–„â–ˆâ–…â–‚â–‡â–„â–‡â–‡â–‡â–…â–„â–†â–‡â–ƒâ–…â–â–„â–†â–‡â–†â–‡â–†â–†â–‡â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‡â–‡â–„â–…â–„â–ƒâ–‡â–†â–â–…â–‡â–„â–‚â–‡â–„â–ˆâ–…â–„â–‡â–„â–‡â–‡â–‡â–…â–„â–†â–‡â–…â–…â–â–†â–†â–‡â–†â–‡â–†â–†â–‡â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–…â–…â–…â–…â–†â–†â–‡â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‡â–‡â–„â–…â–„â–ƒâ–‡â–†â–â–…â–†â–„â–‚â–‡â–„â–ˆâ–…â–„â–‡â–„â–‡â–‡â–‡â–…â–„â–†â–‡â–…â–…â–â–†â–†â–‡â–†â–‡â–†â–†â–‡â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–…â–…â–…â–…â–†â–†â–‡â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–ˆâ–‡â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–ƒâ–„â–‚â–ˆâ–ƒâ–„â–„â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–‚â–‚â–…â–„â–…â–†â–‚â–ƒâ–ˆâ–ƒâ–‚â–…â–‡â–‚â–…â–â–„â–„â–‚â–…â–‚â–‚â–‚â–„â–…â–ƒâ–‚â–ƒâ–„â–†â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–ˆâ–‡â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–ƒâ–„â–‚â–ˆâ–ƒâ–„â–„â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–‚â–‚â–…â–„â–…â–†â–‚â–ƒâ–ˆâ–ƒâ–‚â–…â–‡â–‚â–…â–â–„â–„â–‚â–…â–‚â–‚â–‚â–„â–…â–ƒâ–‚â–ƒâ–„â–†â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–ˆâ–‡â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–ƒâ–„â–‚â–ˆâ–ƒâ–„â–„â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–‚â–‚â–…â–„â–…â–†â–‚â–ƒâ–ˆâ–ƒâ–‚â–…â–‡â–‚â–…â–â–„â–„â–‚â–…â–‚â–‚â–‚â–„â–…â–ƒâ–‚â–ƒâ–„â–†â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–ˆâ–‡â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–ƒâ–„â–‚â–ˆâ–ƒâ–„â–„â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–‚â–‚â–…â–„â–…â–†â–‚â–ƒâ–ˆâ–ƒâ–‚â–…â–‡â–‚â–…â–â–„â–„â–‚â–…â–‚â–‚â–‚â–„â–…â–ƒâ–‚â–ƒâ–„â–†â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.919\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.97726\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.946\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 4.84131\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 4.897\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 4.897\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.969\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 1938.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 40.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.969\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 1938\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 40\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s1a1_s1a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/ziwcp9yp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_181533-ziwcp9yp/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 18:16:14,088][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s1a1_s2a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_181615-f26h3k9q\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s1a1_s2a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/f26h3k9q\u001b[0m\n",
      "[2023-08-08 18:16:18,921][root][INFO] - => Done in 4.833 s\n",
      "[2023-08-08 18:16:18,921][root][INFO] - \n",
      "[2023-08-08 18:16:18,921][root][INFO] - => Env setup ...\n",
      "[2023-08-08 18:16:18,929][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 18:16:18,929][root][INFO] - => Done in 7.942 ms\n",
      "[2023-08-08 18:16:18,929][root][INFO] - \n",
      "[2023-08-08 18:16:18,929][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 18:16:19,520][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 18:16:19,520][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 18:16:19,520][root][INFO] - => Done in 590.735 ms\n",
      "[2023-08-08 18:16:19,520][root][INFO] - \n",
      "[2023-08-08 18:16:19,520][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 18:16:19,521][root][INFO] - => Done in 198.841 us\n",
      "[2023-08-08 18:16:19,521][root][INFO] - \n",
      "[2023-08-08 18:16:19,521][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 18:16:19,521][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 18:16:20,289][root][INFO] - => Done in 768.173 ms\n",
      "[2023-08-08 18:16:20,289][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.895 MB of 0.907 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–†â–†â–…â–†â–†â–†â–‡â–†â–…â–‡â–…â–‡â–…â–ˆâ–…â–ˆâ–…â–†â–†â–„â–…â–…â–†â–„â–„â–‡â–„â–…â–†â–…â–†â–…â–…â–„â–„â–‡â–…â–„â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–ƒâ–†â–„â–†â–„â–…â–ƒâ–„â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–…â–â–‚â–„â–„â–ƒâ–‚â–‚â–‚â–â–„â–‚â–â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‡â–‡â–…â–†â–…â–„â–‡â–…â–‚â–…â–„â–„â–â–†â–ƒâ–†â–ƒâ–„â–„â–‚â–ƒâ–„â–„â–â–â–…â–ƒâ–ƒâ–ƒâ–â–…â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–†â–†â–†â–†â–†â–‡â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‡â–‡â–†â–†â–†â–…â–†â–…â–„â–…â–ƒâ–…â–‚â–†â–ƒâ–…â–‚â–„â–ƒâ–â–‚â–ƒâ–ƒâ–â–â–„â–â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–â–„â–‚â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–†â–†â–†â–†â–†â–‡â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–…â–†â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–‚â–â–‚â–‚â–‚â–ƒâ–„â–ƒâ–„â–†â–ƒâ–„â–ƒâ–„â–„â–†â–„â–†â–†â–‡â–†â–†â–‡â–†â–„â–ˆâ–‡â–…â–„â–†â–†â–‡â–‡â–ˆâ–…â–†â–ˆâ–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–ƒâ–ƒâ–‚â–ˆâ–ƒâ–ƒâ–…â–‚â–‚â–…â–â–â–„â–â–â–‚â–â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–‚â–‚â–†â–„â–…â–†â–‚â–‚â–ˆâ–ƒâ–‚â–…â–ˆâ–‚â–…â–â–„â–„â–‚â–†â–‚â–‚â–‚â–…â–†â–ƒâ–‚â–ƒâ–…â–‡â–â–ƒâ–‚â–„â–‚â–ƒâ–ƒâ–ƒâ–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–ƒâ–ƒâ–â–ˆâ–â–â–â–â–â–â–†â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–‡â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–…â–†â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–‚â–â–‚â–‚â–‚â–ƒâ–„â–ƒâ–ƒâ–†â–ƒâ–„â–ƒâ–„â–„â–†â–„â–†â–†â–‡â–†â–†â–‡â–†â–„â–ˆâ–‡â–…â–„â–†â–†â–‡â–‡â–ˆâ–…â–†â–ˆâ–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–ƒâ–ƒâ–‚â–ˆâ–ƒâ–ƒâ–…â–‚â–‚â–…â–â–â–„â–â–â–‚â–â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–‚â–‚â–†â–„â–…â–†â–‚â–‚â–ˆâ–ƒâ–‚â–…â–ˆâ–‚â–…â–â–„â–„â–‚â–†â–‚â–‚â–‚â–…â–†â–ƒâ–‚â–ƒâ–…â–‡â–â–ƒâ–‚â–„â–‚â–ƒâ–ƒâ–ƒâ–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–ƒâ–ƒâ–â–ˆâ–â–â–â–â–â–â–†â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–‡â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–…â–†â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–ƒâ–ƒâ–‚â–‚â–‚â–…â–ˆâ–…â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–ƒâ–â–‚â–‚â–‚â–â–â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–â–â–‚â–â–‚â–â–ƒâ–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–‚â–â–‚â–‚â–‚â–ƒâ–„â–ƒâ–„â–†â–ƒâ–„â–ƒâ–„â–„â–†â–„â–†â–†â–‡â–†â–†â–‡â–†â–„â–ˆâ–‡â–…â–„â–†â–†â–‡â–‡â–ˆâ–…â–†â–ˆâ–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–ƒâ–ƒâ–‚â–ˆâ–ƒâ–ƒâ–…â–‚â–‚â–…â–â–â–„â–â–â–‚â–â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–‚â–‚â–†â–„â–…â–†â–‚â–‚â–ˆâ–ƒâ–‚â–…â–ˆâ–‚â–…â–â–„â–„â–‚â–†â–‚â–‚â–‚â–…â–†â–ƒâ–‚â–ƒâ–…â–‡â–â–ƒâ–‚â–„â–‚â–ƒâ–ƒâ–ƒâ–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–ƒâ–ƒâ–â–ˆâ–â–â–â–â–â–â–†â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–‡â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–…â–†â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–ƒâ–ƒâ–‚â–‚â–‚â–…â–ˆâ–…â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–ƒâ–â–‚â–‚â–‚â–â–â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–â–â–‚â–â–‚â–â–ƒâ–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–‚â–â–‚â–‚â–‚â–ƒâ–„â–ƒâ–ƒâ–†â–ƒâ–„â–ƒâ–„â–„â–†â–„â–†â–†â–‡â–†â–†â–‡â–†â–„â–ˆâ–‡â–…â–„â–†â–†â–‡â–‡â–ˆâ–…â–†â–ˆâ–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–ƒâ–ƒâ–‚â–ˆâ–ƒâ–ƒâ–…â–‚â–‚â–…â–â–â–„â–â–â–‚â–â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–‚â–‚â–†â–„â–…â–†â–‚â–‚â–ˆâ–ƒâ–‚â–…â–ˆâ–‚â–…â–â–„â–„â–‚â–†â–‚â–‚â–‚â–…â–†â–ƒâ–‚â–ƒâ–…â–‡â–â–ƒâ–‚â–„â–‚â–ƒâ–ƒâ–ƒâ–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–ƒâ–ƒâ–â–ˆâ–â–â–â–â–â–â–†â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–‡â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.706\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.78554\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.87383\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 4.59969\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.6975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.819\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 4.6015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.75825\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 4.6015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.012\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.9055\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0525\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.012\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.008\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 24.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 1811.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 105.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 24.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.012\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.9055\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0525\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.012\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.008\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 1811\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 105\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s1a1_s2a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/f26h3k9q\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_181615-f26h3k9q/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 18:16:54,953][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s1a1_s3a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_181656-fw63yyq6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s1a1_s3a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/fw63yyq6\u001b[0m\n",
      "[2023-08-08 18:16:59,869][root][INFO] - => Done in 4.916 s\n",
      "[2023-08-08 18:16:59,869][root][INFO] - \n",
      "[2023-08-08 18:16:59,869][root][INFO] - => Env setup ...\n",
      "[2023-08-08 18:16:59,872][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 18:16:59,872][root][INFO] - => Done in 3.090 ms\n",
      "[2023-08-08 18:16:59,872][root][INFO] - \n",
      "[2023-08-08 18:16:59,872][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 18:17:00,448][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 18:17:00,448][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 18:17:00,448][root][INFO] - => Done in 575.681 ms\n",
      "[2023-08-08 18:17:00,448][root][INFO] - \n",
      "[2023-08-08 18:17:00,448][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 18:17:00,448][root][INFO] - => Done in 193.834 us\n",
      "[2023-08-08 18:17:00,449][root][INFO] - \n",
      "[2023-08-08 18:17:00,449][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 18:17:00,449][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 18:17:01,175][root][INFO] - => Done in 726.458 ms\n",
      "[2023-08-08 18:17:01,175][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–…â–…â–„â–…â–…â–…â–†â–†â–…â–‡â–‡â–†â–†â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–†â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–‡â–‡â–…â–…â–„â–ƒâ–‡â–†â–â–†â–‡â–„â–â–‡â–„â–ˆâ–…â–‚â–‡â–„â–‡â–‡â–‡â–…â–„â–†â–‡â–†â–…â–â–‡â–†â–‡â–†â–‡â–†â–†â–‡â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‡â–‡â–„â–…â–„â–ƒâ–‡â–†â–â–†â–‡â–„â–â–‡â–„â–ˆâ–…â–„â–‡â–„â–‡â–‡â–‡â–…â–„â–†â–‡â–†â–…â–â–‡â–†â–‡â–†â–‡â–†â–†â–‡â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–…â–…â–…â–…â–†â–†â–‡â–‡â–†â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‡â–‡â–„â–…â–„â–ƒâ–‡â–†â–â–†â–‡â–„â–â–‡â–„â–ˆâ–…â–„â–‡â–„â–‡â–‡â–‡â–…â–„â–†â–‡â–†â–…â–â–‡â–†â–‡â–†â–‡â–†â–†â–‡â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–…â–…â–…â–…â–†â–†â–‡â–‡â–†â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–ƒâ–ƒâ–‚â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–‚â–‚â–…â–„â–…â–†â–‚â–ƒâ–ˆâ–ƒâ–‚â–…â–ˆâ–‚â–…â–â–„â–„â–‚â–…â–‚â–‚â–‚â–„â–…â–ƒâ–‚â–ƒâ–„â–†â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–ƒâ–ƒâ–‚â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–‚â–‚â–…â–„â–…â–†â–‚â–ƒâ–ˆâ–ƒâ–‚â–…â–ˆâ–‚â–…â–â–„â–„â–‚â–…â–‚â–‚â–‚â–„â–…â–ƒâ–‚â–ƒâ–„â–†â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–ƒâ–ƒâ–‚â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–‚â–‚â–…â–„â–…â–†â–‚â–ƒâ–ˆâ–ƒâ–‚â–…â–ˆâ–‚â–…â–â–„â–„â–‚â–…â–‚â–‚â–‚â–„â–…â–ƒâ–‚â–ƒâ–„â–†â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–ƒâ–ƒâ–‚â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–‚â–‚â–…â–„â–…â–†â–‚â–ƒâ–ˆâ–ƒâ–‚â–…â–ˆâ–‚â–…â–â–„â–„â–‚â–…â–‚â–‚â–‚â–„â–…â–ƒâ–‚â–ƒâ–„â–†â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.9195\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.97968\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.94685\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 4.84377\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 4.8985\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.93\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 4.8985\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.9695\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 1939.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 40.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.9695\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.02\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 1939\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 40\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s1a1_s3a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/fw63yyq6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_181656-fw63yyq6/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 18:17:34,900][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s1a1_s4a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_181736-l4hsvtm1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s1a1_s4a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/l4hsvtm1\u001b[0m\n",
      "[2023-08-08 18:17:40,195][root][INFO] - => Done in 5.296 s\n",
      "[2023-08-08 18:17:40,195][root][INFO] - \n",
      "[2023-08-08 18:17:40,195][root][INFO] - => Env setup ...\n",
      "[2023-08-08 18:17:40,199][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 18:17:40,199][root][INFO] - => Done in 3.792 ms\n",
      "[2023-08-08 18:17:40,199][root][INFO] - \n",
      "[2023-08-08 18:17:40,199][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 18:17:40,789][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 18:17:40,790][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 18:17:40,790][root][INFO] - => Done in 590.378 ms\n",
      "[2023-08-08 18:17:40,790][root][INFO] - \n",
      "[2023-08-08 18:17:40,790][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 18:17:40,790][root][INFO] - => Done in 127.077 us\n",
      "[2023-08-08 18:17:40,790][root][INFO] - \n",
      "[2023-08-08 18:17:40,790][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 18:17:40,790][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 18:17:41,586][root][INFO] - => Done in 795.634 ms\n",
      "[2023-08-08 18:17:41,586][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.897 MB of 0.910 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–…â–†â–„â–†â–†â–„â–‡â–„â–„â–‡â–†â–‡â–„â–ˆâ–…â–‡â–ƒâ–‡â–†â–†â–ƒâ–…â–†â–„â–…â–‡â–„â–†â–†â–†â–†â–…â–†â–‚â–…â–‡â–†â–„â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–‡â–‡â–†â–‡â–‡â–†â–†â–„â–…â–†â–„â–†â–„â–†â–„â–„â–‚â–…â–„â–…â–‚â–ƒâ–„â–ƒâ–„â–…â–‚â–„â–„â–…â–„â–ƒâ–„â–â–ƒâ–…â–„â–‚â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‡â–‡â–…â–†â–…â–„â–†â–„â–‚â–…â–…â–„â–â–†â–ƒâ–…â–‚â–ƒâ–„â–ƒâ–ƒâ–„â–„â–‚â–‚â–„â–ƒâ–ƒâ–ƒâ–‚â–„â–ƒâ–„â–â–ƒâ–„â–„â–ƒâ–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–…â–…â–…â–†â–†â–†â–‡â–†â–†â–‡â–‡â–‡â–†â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–†â–‡â–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‡â–‡â–†â–‡â–†â–…â–†â–„â–„â–†â–„â–…â–ƒâ–†â–„â–…â–‚â–„â–„â–„â–‚â–ƒâ–„â–ƒâ–ƒâ–…â–‚â–„â–„â–„â–„â–ƒâ–„â–â–ƒâ–…â–„â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–…â–…â–…â–†â–†â–†â–‡â–†â–†â–‡â–‡â–‡â–†â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–†â–‡â–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–…â–…â–…â–†â–†â–†â–‡â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–…â–„â–ƒâ–…â–ƒâ–…â–ƒâ–„â–…â–†â–„â–…â–„â–‡â–†â–…â–…â–…â–„â–‡â–…â–„â–ƒâ–…â–†â–…â–ˆâ–†â–„â–…â–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–ƒâ–ƒâ–‚â–ˆâ–„â–„â–†â–‚â–‚â–…â–â–â–ƒâ–â–â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–‚â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–‚â–‚â–…â–„â–…â–…â–‚â–‚â–ˆâ–ƒâ–‚â–…â–ˆâ–‚â–…â–â–„â–…â–‚â–†â–‚â–‚â–‚â–†â–†â–ƒâ–‚â–ƒâ–…â–†â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–…â–‡â–â–ˆâ–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‡â–â–â–â–â–â–â–â–‡â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–…â–…â–…â–†â–†â–†â–‡â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–…â–„â–ƒâ–…â–ƒâ–…â–ƒâ–„â–…â–†â–„â–…â–„â–‡â–†â–…â–…â–…â–„â–‡â–…â–„â–ƒâ–…â–†â–…â–ˆâ–†â–„â–…â–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–ƒâ–ƒâ–‚â–ˆâ–„â–„â–†â–‚â–‚â–…â–â–â–ƒâ–â–â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–‚â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–‚â–‚â–…â–„â–…â–…â–‚â–‚â–ˆâ–ƒâ–‚â–…â–ˆâ–‚â–…â–â–„â–…â–‚â–†â–‚â–‚â–‚â–†â–†â–ƒâ–‚â–ƒâ–…â–†â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–…â–‡â–â–ˆâ–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‡â–â–â–â–â–â–â–â–‡â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–…â–‡â–…â–†â–†â–ƒâ–…â–†â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–â–â–â–ƒâ–â–‚â–‚â–â–‚â–ƒâ–‚â–â–‚â–‚â–â–â–â–â–â–â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–…â–„â–ƒâ–…â–ƒâ–…â–ƒâ–„â–…â–†â–„â–…â–„â–‡â–†â–…â–…â–…â–„â–‡â–…â–„â–ƒâ–…â–†â–…â–ˆâ–†â–„â–…â–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–ƒâ–ƒâ–‚â–ˆâ–„â–„â–†â–‚â–‚â–…â–â–â–ƒâ–â–â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–‚â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–‚â–‚â–…â–„â–…â–…â–‚â–‚â–ˆâ–ƒâ–‚â–…â–ˆâ–‚â–…â–â–„â–…â–‚â–†â–‚â–‚â–‚â–†â–†â–ƒâ–‚â–ƒâ–…â–†â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–…â–‡â–â–ˆâ–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‡â–â–â–â–â–â–â–â–‡â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–…â–‡â–…â–†â–†â–ƒâ–…â–†â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–â–â–â–ƒâ–â–‚â–‚â–â–‚â–ƒâ–‚â–â–‚â–‚â–â–â–â–â–â–â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–…â–„â–ƒâ–…â–ƒâ–…â–ƒâ–„â–…â–†â–„â–…â–„â–‡â–†â–…â–…â–…â–„â–‡â–…â–„â–ƒâ–…â–†â–…â–ˆâ–†â–„â–…â–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–ƒâ–ƒâ–‚â–ˆâ–„â–„â–†â–‚â–‚â–…â–â–â–ƒâ–â–â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–‚â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–‚â–‚â–…â–„â–…â–…â–‚â–‚â–ˆâ–ƒâ–‚â–…â–ˆâ–‚â–…â–â–„â–…â–‚â–†â–‚â–‚â–‚â–†â–†â–ƒâ–‚â–ƒâ–…â–†â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–…â–‡â–â–ˆâ–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‡â–â–â–â–â–â–â–â–‡â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.681\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.7482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.85993\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 4.56976\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.665\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.797\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 4.581\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.731\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 4.581\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.008\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.903\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.059\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 1806.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 118.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 30.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 10.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.008\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.903\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.059\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 1806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 118\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s1a1_s4a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/l4hsvtm1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_181736-l4hsvtm1/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 18:18:15,742][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s1a1_s5a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_181816-8t8up1qg\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s1a1_s5a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/8t8up1qg\u001b[0m\n",
      "[2023-08-08 18:18:20,794][root][INFO] - => Done in 5.052 s\n",
      "[2023-08-08 18:18:20,795][root][INFO] - \n",
      "[2023-08-08 18:18:20,795][root][INFO] - => Env setup ...\n",
      "[2023-08-08 18:18:20,799][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 18:18:20,799][root][INFO] - => Done in 3.945 ms\n",
      "[2023-08-08 18:18:20,799][root][INFO] - \n",
      "[2023-08-08 18:18:20,799][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 18:18:21,386][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 18:18:21,387][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 18:18:21,387][root][INFO] - => Done in 587.796 ms\n",
      "[2023-08-08 18:18:21,387][root][INFO] - \n",
      "[2023-08-08 18:18:21,387][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 18:18:21,387][root][INFO] - => Done in 134.945 us\n",
      "[2023-08-08 18:18:21,387][root][INFO] - \n",
      "[2023-08-08 18:18:21,387][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 18:18:21,387][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 18:18:22,126][root][INFO] - => Done in 739.310 ms\n",
      "[2023-08-08 18:18:22,127][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–…â–‚â–ƒâ–…â–‚â–†â–ƒâ–‚â–ƒâ–†â–ƒâ–‚â–„â–‡â–ƒâ–…â–â–†â–‡â–‚â–…â–ƒâ–„â–ƒâ–ƒâ–‡â–‚â–ƒâ–†â–…â–„â–ƒâ–ƒâ–†â–…â–ˆâ–„â–…â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–…â–‚â–„â–†â–„â–†â–„â–ƒâ–„â–…â–ƒâ–ƒâ–…â–‡â–„â–…â–‚â–…â–†â–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–†â–â–‚â–…â–„â–ƒâ–ƒâ–‚â–„â–ƒâ–†â–ƒâ–„â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ˆâ–ƒâ–‚â–ƒâ–â–ƒâ–„â–…â–‚â–…â–…â–â–ƒâ–†â–„â–…â–ƒâ–„â–‡â–ƒâ–†â–…â–†â–…â–„â–…â–†â–„â–…â–„â–‡â–„â–‡â–ˆâ–ˆâ–‡â–…â–ˆâ–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–„â–„â–‚â–„â–„â–ƒâ–…â–ƒâ–â–‚â–…â–‚â–ƒâ–ƒâ–…â–ƒâ–…â–‚â–‡â–‡â–ƒâ–…â–„â–„â–„â–„â–†â–ƒâ–„â–†â–†â–„â–„â–„â–†â–…â–ˆâ–…â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–…â–‚â–ƒâ–„â–‚â–…â–ƒâ–ƒâ–ƒâ–…â–‚â–‚â–„â–‡â–ƒâ–„â–â–„â–†â–‚â–„â–ƒâ–ƒâ–ƒâ–‚â–…â–â–‚â–…â–ƒâ–ƒâ–‚â–‚â–„â–„â–†â–ƒâ–„â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–„â–„â–‚â–„â–„â–ƒâ–…â–ƒâ–â–‚â–…â–‚â–ƒâ–ƒâ–…â–ƒâ–…â–‚â–‡â–‡â–ƒâ–…â–„â–„â–„â–„â–†â–ƒâ–„â–†â–†â–„â–„â–„â–†â–…â–ˆâ–…â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–…â–„â–„â–…â–…â–…â–…â–…â–…â–…â–„â–…â–…â–ˆâ–„â–…â–ƒâ–„â–…â–‚â–…â–ƒâ–ƒâ–ƒâ–ƒâ–„â–â–‚â–„â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–„â–‚â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–„â–ƒâ–„â–ƒâ–‚â–„â–‚â–‚â–‚â–„â–„â–‚â–ƒâ–â–„â–ƒâ–„â–†â–…â–…â–„â–…â–…â–…â–…â–…â–‡â–‡â–…â–ˆâ–†â–…â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–„â–‡â–…â–„â–„â–ƒâ–…â–†â–…â–„â–†â–†â–„â–‚â–†â–„â–‡â–„â–ƒâ–†â–…â–†â–†â–†â–†â–ƒâ–ˆâ–‡â–„â–…â–†â–†â–‡â–…â–†â–ƒâ–†â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–‚â–‚â–ƒâ–‡â–†â–ƒâ–‡â–ƒâ–„â–‡â–ƒâ–â–ƒâ–‡â–â–ˆâ–â–ƒâ–‚â–‚â–†â–‚â–‚â–‚â–†â–„â–†â–â–„â–„â–‡â–â–‚â–‚â–…â–ƒâ–‚â–â–‚â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ƒâ–‚â–‚â–ˆâ–†â–‡â–ˆâ–‚â–ƒâ–†â–ƒâ–„â–„â–‡â–‚â–„â–â–…â–„â–‚â–‡â–â–‚â–â–„â–†â–„â–ƒâ–†â–†â–†â–â–‚â–‚â–‚â–‚â–ƒâ–…â–â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–‚â–â–â–‚â–‚â–ˆâ–…â–â–„â–‚â–â–â–‡â–‚â–â–„â–‚â–…â–â–â–„â–â–‚â–‚â–‚â–ƒâ–â–‚â–â–‚â–ƒâ–â–â–‚â–‚â–â–‚â–â–„â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–…â–„â–„â–…â–…â–…â–…â–…â–…â–…â–„â–…â–…â–ˆâ–„â–…â–ƒâ–„â–…â–‚â–…â–ƒâ–ƒâ–ƒâ–ƒâ–„â–â–‚â–„â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–„â–‚â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–„â–ƒâ–„â–ƒâ–‚â–„â–‚â–‚â–‚â–„â–„â–‚â–ƒâ–â–„â–ƒâ–„â–†â–…â–…â–„â–…â–…â–…â–…â–…â–‡â–‡â–…â–ˆâ–†â–…â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–„â–‡â–…â–„â–„â–ƒâ–…â–†â–…â–„â–†â–†â–„â–‚â–†â–„â–‡â–„â–ƒâ–†â–…â–†â–†â–†â–†â–ƒâ–ˆâ–‡â–„â–…â–†â–†â–‡â–…â–†â–ƒâ–†â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–‚â–‚â–ƒâ–‡â–†â–ƒâ–‡â–ƒâ–„â–‡â–ƒâ–â–ƒâ–‡â–â–ˆâ–â–ƒâ–‚â–‚â–†â–‚â–‚â–‚â–†â–„â–†â–â–„â–„â–‡â–â–‚â–‚â–…â–ƒâ–‚â–â–‚â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ƒâ–‚â–‚â–ˆâ–†â–‡â–ˆâ–‚â–ƒâ–†â–ƒâ–„â–„â–‡â–‚â–„â–â–…â–„â–‚â–‡â–â–‚â–â–„â–†â–„â–ƒâ–†â–†â–†â–â–‚â–‚â–‚â–‚â–ƒâ–…â–â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–‚â–â–â–‚â–‚â–ˆâ–…â–â–„â–‚â–â–â–‡â–‚â–â–„â–‚â–…â–â–â–„â–â–‚â–‚â–‚â–ƒâ–â–‚â–â–‚â–ƒâ–â–â–‚â–‚â–â–‚â–â–„â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–…â–„â–„â–…â–…â–…â–…â–…â–…â–…â–„â–…â–…â–ˆâ–„â–…â–ƒâ–„â–…â–‚â–…â–ƒâ–ƒâ–ƒâ–ƒâ–„â–â–‚â–„â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–„â–‚â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–ƒâ–ƒâ–„â–„â–ƒâ–…â–ƒâ–â–‚â–„â–ƒâ–ƒâ–ƒâ–‚â–„â–„â–ƒâ–‡â–†â–„â–„â–„â–„â–„â–…â–†â–…â–†â–†â–ˆâ–…â–…â–†â–‡â–†â–ˆâ–†â–†â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–‚â–…â–„â–„â–‚â–‚â–‚â–ƒâ–…â–‚â–ƒâ–…â–‚â–ƒâ–â–„â–‚â–…â–ƒâ–ƒâ–†â–„â–…â–†â–…â–…â–ƒâ–ˆâ–†â–ƒâ–…â–†â–„â–‡â–‡â–‡â–„â–†â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–„â–‡â–…â–„â–„â–ƒâ–…â–†â–…â–„â–†â–†â–„â–‚â–†â–„â–‡â–„â–ƒâ–†â–…â–†â–†â–†â–†â–ƒâ–ˆâ–‡â–„â–…â–†â–†â–‡â–…â–†â–ƒâ–†â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–‚â–‚â–ƒâ–‡â–†â–ƒâ–‡â–ƒâ–„â–‡â–ƒâ–â–ƒâ–‡â–â–ˆâ–â–ƒâ–‚â–‚â–†â–‚â–‚â–‚â–†â–„â–†â–â–„â–„â–‡â–â–‚â–‚â–…â–ƒâ–‚â–â–‚â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–‚â–‚â–‚â–ˆâ–‡â–‡â–†â–‚â–ƒâ–†â–ƒâ–ƒâ–ƒâ–ˆâ–â–ƒâ–â–…â–…â–‚â–‡â–â–‚â–â–„â–†â–…â–â–†â–„â–†â–â–‚â–‚â–‚â–‚â–‚â–†â–â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–„â–â–‚â–…â–‚â–„â–ˆâ–â–ƒâ–…â–â–ƒâ–„â–‚â–‚â–ƒâ–â–ƒâ–â–‚â–„â–â–â–â–‚â–„â–â–…â–‚â–†â–…â–‚â–â–â–â–ƒâ–…â–â–‚â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–‚â–â–â–‚â–‚â–ˆâ–…â–â–„â–‚â–â–â–‡â–‚â–â–„â–‚â–…â–â–â–„â–â–‚â–‚â–‚â–ƒâ–â–‚â–â–‚â–ƒâ–â–â–‚â–‚â–â–‚â–â–„â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–…â–„â–„â–…â–…â–…â–…â–…â–…â–…â–„â–…â–…â–ˆâ–„â–…â–ƒâ–„â–…â–‚â–…â–ƒâ–ƒâ–ƒâ–ƒâ–„â–â–‚â–„â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–„â–‚â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–ƒâ–ƒâ–„â–„â–ƒâ–…â–ƒâ–â–‚â–„â–ƒâ–ƒâ–ƒâ–‚â–„â–„â–ƒâ–‡â–†â–„â–„â–„â–…â–„â–…â–†â–…â–†â–†â–ˆâ–…â–…â–†â–‡â–†â–ˆâ–†â–†â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–‚â–…â–„â–ƒâ–‚â–‚â–‚â–ƒâ–…â–‚â–ƒâ–…â–‚â–ƒâ–â–„â–‚â–…â–ƒâ–ƒâ–†â–„â–…â–†â–…â–…â–ƒâ–ˆâ–†â–ƒâ–…â–†â–„â–‡â–‡â–‡â–„â–†â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–„â–‡â–…â–„â–„â–ƒâ–…â–†â–…â–„â–†â–†â–„â–‚â–†â–„â–‡â–„â–ƒâ–†â–…â–†â–†â–†â–†â–ƒâ–ˆâ–‡â–„â–…â–†â–†â–‡â–…â–†â–ƒâ–†â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–‚â–‚â–ƒâ–‡â–†â–ƒâ–‡â–ƒâ–„â–‡â–ƒâ–â–ƒâ–‡â–â–ˆâ–â–ƒâ–‚â–‚â–†â–‚â–‚â–‚â–†â–„â–†â–â–„â–„â–‡â–â–‚â–‚â–…â–ƒâ–‚â–â–‚â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–‚â–‚â–‚â–ˆâ–‡â–‡â–†â–‚â–ƒâ–†â–ƒâ–ƒâ–ƒâ–ˆâ–â–ƒâ–â–…â–…â–‚â–‡â–â–‚â–â–„â–†â–…â–â–†â–„â–†â–â–‚â–‚â–‚â–‚â–‚â–†â–â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–„â–â–‚â–…â–‚â–„â–ˆâ–â–ƒâ–…â–â–ƒâ–„â–‚â–‚â–ƒâ–â–ƒâ–â–‚â–„â–â–â–â–‚â–„â–â–…â–‚â–†â–…â–‚â–â–â–â–ƒâ–…â–â–‚â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–‚â–â–â–‚â–‚â–ˆâ–…â–â–„â–‚â–â–â–‡â–‚â–â–„â–‚â–…â–â–â–„â–â–‚â–‚â–‚â–ƒâ–â–‚â–â–‚â–ƒâ–â–â–‚â–‚â–â–‚â–â–„â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.28633\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.49244\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.97844\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 3.31927\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.5195\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 2.004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 3.3355\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.76175\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 3.3355\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.301\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.5845\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.093\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0025\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0055\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0035\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 602.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 1169.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 186.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 5.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 11.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 7.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.301\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.5135\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.093\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0025\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0035\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 602\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 1027\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 142\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 186\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s1a1_s5a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/8t8up1qg\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_181816-8t8up1qg/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 18:18:55,135][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s2a2_s1a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_181856-dvjclvd9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s2a2_s1a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/dvjclvd9\u001b[0m\n",
      "[2023-08-08 18:18:59,945][root][INFO] - => Done in 4.810 s\n",
      "[2023-08-08 18:18:59,945][root][INFO] - \n",
      "[2023-08-08 18:18:59,945][root][INFO] - => Env setup ...\n",
      "[2023-08-08 18:18:59,951][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 18:18:59,951][root][INFO] - => Done in 5.830 ms\n",
      "[2023-08-08 18:18:59,951][root][INFO] - \n",
      "[2023-08-08 18:18:59,951][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 18:19:00,533][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 18:19:00,533][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 18:19:00,533][root][INFO] - => Done in 581.588 ms\n",
      "[2023-08-08 18:19:00,533][root][INFO] - \n",
      "[2023-08-08 18:19:00,533][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 18:19:00,533][root][INFO] - => Done in 104.904 us\n",
      "[2023-08-08 18:19:00,533][root][INFO] - \n",
      "[2023-08-08 18:19:00,533][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 18:19:00,533][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 18:19:01,297][root][INFO] - => Done in 763.422 ms\n",
      "[2023-08-08 18:19:01,297][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: | 0.900 MB of 0.903 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–ˆâ–‡â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–ˆâ–‡â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–ˆâ–‡â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–ˆâ–‡â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.9976\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.9991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 4.89867\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 4.997\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 4.997\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.989\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 1978.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.989\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 1978\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s2a2_s1a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/dvjclvd9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_181856-dvjclvd9/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 18:19:35,835][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s2a2_s2a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_181937-czbf2r3g\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s2a2_s2a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/czbf2r3g\u001b[0m\n",
      "[2023-08-08 18:19:40,980][root][INFO] - => Done in 5.145 s\n",
      "[2023-08-08 18:19:40,980][root][INFO] - \n",
      "[2023-08-08 18:19:40,980][root][INFO] - => Env setup ...\n",
      "[2023-08-08 18:19:40,983][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 18:19:40,983][root][INFO] - => Done in 2.915 ms\n",
      "[2023-08-08 18:19:40,983][root][INFO] - \n",
      "[2023-08-08 18:19:40,983][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 18:19:41,578][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 18:19:41,578][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 18:19:41,578][root][INFO] - => Done in 595.257 ms\n",
      "[2023-08-08 18:19:41,578][root][INFO] - \n",
      "[2023-08-08 18:19:41,578][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 18:19:41,578][root][INFO] - => Done in 107.050 us\n",
      "[2023-08-08 18:19:41,579][root][INFO] - \n",
      "[2023-08-08 18:19:41,579][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 18:19:41,579][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 18:19:42,370][root][INFO] - => Done in 791.864 ms\n",
      "[2023-08-08 18:19:42,371][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: | 0.910 MB of 0.913 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–†â–†â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–…â–ˆâ–‡â–ˆâ–†â–‡â–†â–‡â–†â–†â–…â–…â–…â–…â–…â–‡â–„â–…â–‡â–‡â–†â–…â–…â–…â–„â–‡â–†â–„â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–„â–†â–…â–ƒâ–†â–…â–†â–„â–…â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–„â–â–‚â–„â–„â–ƒâ–‚â–‚â–‚â–‚â–„â–ƒâ–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–…â–†â–†â–„â–†â–…â–†â–„â–…â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–„â–â–‚â–„â–…â–„â–‚â–‚â–‚â–‚â–„â–ƒâ–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–…â–†â–†â–„â–†â–…â–†â–„â–…â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–„â–â–‚â–„â–„â–ƒâ–‚â–‚â–‚â–‚â–„â–ƒâ–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–…â–ƒâ–„â–†â–ƒâ–„â–ƒâ–…â–„â–†â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–…â–ˆâ–‡â–…â–…â–†â–‡â–‡â–‡â–‡â–…â–†â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–…â–ƒâ–„â–†â–ƒâ–„â–ƒâ–…â–„â–†â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–…â–ˆâ–‡â–…â–…â–†â–‡â–‡â–‡â–‡â–…â–†â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–„â–‚â–ƒâ–ƒâ–‚â–…â–ˆâ–…â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–ƒâ–â–â–‚â–‚â–â–â–‚â–â–‚â–â–â–â–‚â–‚â–â–â–‚â–â–‚â–â–ƒâ–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–…â–ƒâ–„â–†â–ƒâ–„â–ƒâ–…â–„â–†â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–…â–ˆâ–‡â–…â–…â–†â–‡â–‡â–‡â–‡â–…â–†â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–„â–‚â–ƒâ–ƒâ–‚â–…â–ˆâ–…â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–ƒâ–â–â–‚â–‚â–â–â–‚â–â–‚â–â–â–â–‚â–‚â–â–â–‚â–â–‚â–â–ƒâ–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–…â–ƒâ–„â–†â–ƒâ–„â–ƒâ–…â–„â–†â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–…â–ˆâ–‡â–…â–…â–†â–‡â–‡â–‡â–‡â–…â–†â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.737\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.78774\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.91836\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 4.64276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.6825\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.873\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 4.6555\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.77775\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 4.6555\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.009\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.9175\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0635\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 18.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 1835.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 127.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.009\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.9175\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0635\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 1835\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 127\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s2a2_s2a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/czbf2r3g\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_181937-czbf2r3g/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 18:20:28,946][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s2a2_s3a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_182030-cg2f73mv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s2a2_s3a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/cg2f73mv\u001b[0m\n",
      "[2023-08-08 18:20:38,513][root][INFO] - => Done in 9.567 s\n",
      "[2023-08-08 18:20:38,513][root][INFO] - \n",
      "[2023-08-08 18:20:38,513][root][INFO] - => Env setup ...\n",
      "[2023-08-08 18:20:38,516][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 18:20:38,516][root][INFO] - => Done in 2.880 ms\n",
      "[2023-08-08 18:20:38,516][root][INFO] - \n",
      "[2023-08-08 18:20:38,516][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 18:20:39,230][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 18:20:39,231][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 18:20:39,231][root][INFO] - => Done in 714.893 ms\n",
      "[2023-08-08 18:20:39,231][root][INFO] - \n",
      "[2023-08-08 18:20:39,231][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 18:20:39,231][root][INFO] - => Done in 106.812 us\n",
      "[2023-08-08 18:20:39,231][root][INFO] - \n",
      "[2023-08-08 18:20:39,231][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 18:20:39,231][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 18:20:40,080][root][INFO] - => Done in 849.332 ms\n",
      "[2023-08-08 18:20:40,080][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 3.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.99995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.99996\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 4.90091\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 5.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 5.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s2a2_s3a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/cg2f73mv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 77 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_182030-cg2f73mv/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 18:21:13,707][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s2a2_s4a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_182114-9zltb9m0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s2a2_s4a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/9zltb9m0\u001b[0m\n",
      "[2023-08-08 18:21:18,432][root][INFO] - => Done in 4.725 s\n",
      "[2023-08-08 18:21:18,432][root][INFO] - \n",
      "[2023-08-08 18:21:18,433][root][INFO] - => Env setup ...\n",
      "[2023-08-08 18:21:18,436][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 18:21:18,436][root][INFO] - => Done in 3.624 ms\n",
      "[2023-08-08 18:21:18,436][root][INFO] - \n",
      "[2023-08-08 18:21:18,436][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 18:21:19,030][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 18:21:19,030][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 18:21:19,030][root][INFO] - => Done in 594.064 ms\n",
      "[2023-08-08 18:21:19,030][root][INFO] - \n",
      "[2023-08-08 18:21:19,031][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 18:21:19,031][root][INFO] - => Done in 106.812 us\n",
      "[2023-08-08 18:21:19,031][root][INFO] - \n",
      "[2023-08-08 18:21:19,031][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 18:21:19,031][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 18:21:19,881][root][INFO] - => Done in 850.337 ms\n",
      "[2023-08-08 18:21:19,881][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.915 MB of 0.915 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–…â–†â–†â–†â–‡â–†â–‡â–„â–†â–‡â–†â–ˆâ–†â–ˆâ–†â–†â–„â–‡â–†â–ˆâ–ƒâ–…â–†â–†â–‡â–ˆâ–„â–†â–‡â–ˆâ–‡â–†â–†â–ƒâ–…â–‡â–‡â–„â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–„â–…â–†â–„â–†â–„â–†â–„â–„â–‚â–…â–„â–…â–‚â–ƒâ–„â–„â–„â–…â–‚â–„â–…â–†â–„â–ƒâ–„â–â–ƒâ–…â–…â–‚â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–„â–…â–†â–„â–†â–„â–†â–„â–„â–‚â–…â–„â–…â–‚â–ƒâ–„â–ƒâ–„â–…â–‚â–„â–„â–…â–„â–ƒâ–„â–â–ƒâ–…â–„â–‚â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–ˆâ–†â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–‡â–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–„â–…â–†â–„â–†â–„â–†â–„â–„â–‚â–…â–„â–…â–‚â–ƒâ–„â–„â–„â–…â–‚â–„â–…â–…â–„â–ƒâ–„â–â–ƒâ–…â–…â–‚â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–ˆâ–†â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–‡â–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–…â–„â–ƒâ–…â–ƒâ–…â–ƒâ–…â–…â–‡â–„â–…â–„â–‡â–†â–…â–…â–…â–„â–‡â–…â–„â–ƒâ–…â–†â–…â–ˆâ–†â–„â–„â–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–…â–„â–ƒâ–…â–ƒâ–…â–ƒâ–…â–…â–‡â–„â–…â–„â–‡â–†â–…â–…â–…â–„â–‡â–…â–„â–ƒâ–…â–†â–…â–ˆâ–†â–„â–„â–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–„â–‡â–…â–…â–…â–ƒâ–…â–…â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–…â–„â–ƒâ–…â–ƒâ–…â–ƒâ–…â–…â–‡â–„â–…â–„â–‡â–†â–…â–…â–…â–„â–‡â–…â–„â–ƒâ–…â–†â–…â–ˆâ–†â–„â–„â–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–„â–‡â–…â–…â–…â–ƒâ–…â–…â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–…â–„â–ƒâ–…â–ƒâ–…â–ƒâ–…â–…â–‡â–„â–…â–„â–‡â–†â–…â–…â–…â–„â–‡â–…â–„â–ƒâ–…â–†â–…â–ˆâ–†â–„â–„â–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.758\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.76535\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.91044\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 4.63069\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.7025\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.881\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 4.6905\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.79175\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 4.6905\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.9265\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0595\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 8.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 1853.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 119.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.9265\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0595\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 1853\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s2a2_s4a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/9zltb9m0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_182114-9zltb9m0/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 18:21:54,051][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s2a2_s5a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_182155-cktuqb3o\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s2a2_s5a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/cktuqb3o\u001b[0m\n",
      "[2023-08-08 18:21:58,670][root][INFO] - => Done in 4.619 s\n",
      "[2023-08-08 18:21:58,670][root][INFO] - \n",
      "[2023-08-08 18:21:58,670][root][INFO] - => Env setup ...\n",
      "[2023-08-08 18:21:58,674][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 18:21:58,674][root][INFO] - => Done in 3.697 ms\n",
      "[2023-08-08 18:21:58,674][root][INFO] - \n",
      "[2023-08-08 18:21:58,674][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 18:21:59,292][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 18:21:59,292][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 18:21:59,292][root][INFO] - => Done in 617.910 ms\n",
      "[2023-08-08 18:21:59,292][root][INFO] - \n",
      "[2023-08-08 18:21:59,292][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 18:21:59,292][root][INFO] - => Done in 108.957 us\n",
      "[2023-08-08 18:21:59,292][root][INFO] - \n",
      "[2023-08-08 18:21:59,292][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 18:21:59,293][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 18:22:00,100][root][INFO] - => Done in 807.792 ms\n",
      "[2023-08-08 18:22:00,100][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–‡â–„â–â–„â–„â–ƒâ–†â–‚â–â–ƒâ–…â–‚â–‚â–‚â–…â–ƒâ–ƒâ–â–…â–†â–â–ƒâ–‚â–‚â–‚â–ƒâ–†â–‚â–ƒâ–…â–„â–ƒâ–‚â–ƒâ–…â–„â–ˆâ–„â–„â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–„â–‚â–„â–…â–„â–†â–ƒâ–‚â–„â–…â–‚â–ƒâ–ƒâ–‡â–ƒâ–„â–‚â–„â–†â–â–ƒâ–‚â–‚â–‚â–‚â–…â–â–‚â–…â–ƒâ–ƒâ–‚â–â–ƒâ–ƒâ–†â–ƒâ–ƒâ–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‡â–ƒâ–…â–„â–‚â–†â–ƒâ–…â–ƒâ–…â–„â–â–ƒâ–…â–„â–ƒâ–ƒâ–„â–†â–…â–„â–„â–…â–„â–…â–†â–‡â–†â–†â–…â–†â–ƒâ–‡â–ˆâ–‡â–ˆâ–†â–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–„â–ƒâ–‚â–„â–„â–ƒâ–…â–‚â–â–ƒâ–…â–‚â–ƒâ–‚â–„â–ƒâ–ƒâ–‚â–†â–†â–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–†â–ƒâ–„â–†â–†â–„â–„â–„â–†â–„â–ˆâ–…â–…â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–„â–â–ƒâ–„â–‚â–…â–ƒâ–‚â–ƒâ–„â–‚â–â–‚â–†â–ƒâ–ƒâ–â–„â–†â–â–ƒâ–‚â–‚â–â–‚â–…â–‚â–‚â–„â–ƒâ–ƒâ–â–‚â–„â–ƒâ–†â–ƒâ–„â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–„â–ƒâ–‚â–„â–„â–ƒâ–…â–‚â–â–ƒâ–…â–‚â–ƒâ–‚â–„â–ƒâ–ƒâ–‚â–†â–†â–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–†â–ƒâ–„â–†â–†â–„â–„â–„â–†â–„â–ˆâ–…â–…â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–…â–…â–…â–…â–…â–…â–†â–…â–…â–…â–„â–…â–…â–ˆâ–„â–…â–ƒâ–„â–…â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–‚â–‚â–„â–‚â–ƒâ–ƒâ–â–‚â–ƒâ–„â–‚â–ƒâ–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–„â–ƒâ–„â–ƒâ–ƒâ–„â–‚â–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–â–„â–ƒâ–„â–…â–„â–…â–„â–…â–…â–…â–…â–…â–‡â–‡â–…â–‡â–†â–…â–‡â–‡â–†â–‡â–†â–†â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–…â–‡â–…â–„â–…â–ƒâ–†â–‡â–…â–„â–‡â–†â–†â–‚â–†â–…â–ˆâ–…â–ƒâ–ˆâ–†â–‡â–‡â–ˆâ–‡â–„â–ˆâ–‡â–…â–†â–†â–‡â–ˆâ–†â–†â–ƒâ–‡â–†â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–…â–…â–…â–…â–…â–…â–†â–…â–…â–…â–„â–…â–…â–ˆâ–„â–…â–ƒâ–„â–…â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–‚â–‚â–„â–‚â–ƒâ–ƒâ–â–‚â–ƒâ–„â–‚â–ƒâ–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–„â–ƒâ–„â–ƒâ–ƒâ–„â–‚â–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–â–„â–ƒâ–„â–…â–„â–…â–„â–…â–…â–…â–…â–…â–‡â–‡â–…â–‡â–†â–…â–‡â–‡â–†â–‡â–†â–†â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–…â–‡â–…â–„â–…â–ƒâ–†â–‡â–…â–„â–‡â–†â–†â–‚â–†â–…â–ˆâ–…â–ƒâ–ˆâ–†â–‡â–‡â–ˆâ–‡â–„â–ˆâ–‡â–…â–†â–†â–‡â–ˆâ–†â–†â–ƒâ–‡â–†â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–…â–…â–…â–…â–…â–…â–†â–…â–…â–…â–„â–…â–…â–ˆâ–„â–…â–ƒâ–„â–…â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–‚â–‚â–„â–‚â–ƒâ–ƒâ–â–‚â–ƒâ–„â–‚â–ƒâ–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–ƒâ–‚â–„â–„â–ƒâ–…â–‚â–â–ƒâ–„â–ƒâ–„â–‚â–‚â–„â–ƒâ–„â–‡â–…â–„â–„â–„â–„â–„â–…â–†â–…â–†â–†â–‡â–…â–…â–†â–‡â–…â–ˆâ–†â–…â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–‚â–…â–„â–„â–‚â–‚â–ƒâ–ƒâ–…â–ƒâ–ƒâ–…â–‚â–ƒâ–â–„â–‚â–…â–ƒâ–ƒâ–†â–„â–…â–†â–…â–…â–ƒâ–ˆâ–†â–„â–…â–†â–„â–ˆâ–‡â–‡â–„â–†â–†â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–…â–‡â–…â–„â–…â–ƒâ–†â–‡â–…â–„â–‡â–†â–†â–‚â–†â–…â–ˆâ–…â–ƒâ–ˆâ–†â–‡â–‡â–ˆâ–‡â–„â–ˆâ–‡â–…â–†â–†â–‡â–ˆâ–†â–†â–ƒâ–‡â–†â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–…â–…â–…â–…â–…â–…â–†â–…â–…â–…â–„â–…â–…â–ˆâ–„â–…â–ƒâ–„â–…â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–‚â–‚â–„â–‚â–ƒâ–ƒâ–â–‚â–ƒâ–„â–‚â–ƒâ–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–ƒâ–‚â–„â–„â–ƒâ–…â–‚â–â–ƒâ–„â–ƒâ–„â–‚â–‚â–„â–ƒâ–„â–‡â–…â–„â–„â–„â–„â–„â–…â–†â–…â–†â–†â–‡â–…â–…â–†â–‡â–…â–ˆâ–†â–…â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–‚â–…â–„â–„â–‚â–‚â–ƒâ–ƒâ–…â–ƒâ–ƒâ–…â–‚â–ƒâ–â–„â–‚â–…â–ƒâ–ƒâ–†â–„â–…â–†â–…â–…â–ƒâ–ˆâ–†â–„â–…â–†â–„â–ˆâ–‡â–‡â–„â–†â–†â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–…â–‡â–…â–„â–…â–ƒâ–†â–‡â–…â–„â–‡â–†â–†â–‚â–†â–…â–ˆâ–…â–ƒâ–ˆâ–†â–‡â–‡â–ˆâ–‡â–„â–ˆâ–‡â–…â–†â–†â–‡â–ˆâ–†â–†â–ƒâ–‡â–†â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.30583\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.48257\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.99637\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 3.33645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 2.0415\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 3.361\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.77825\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 3.361\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.302\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.592\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.096\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 604.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 1184.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 192.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.302\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.514\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.078\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.096\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 604\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 1028\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 156\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s2a2_s5a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/cktuqb3o\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_182155-cktuqb3o/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 18:22:33,946][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s3a1_s1a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_182235-fgxu2kh4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s3a1_s1a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/fgxu2kh4\u001b[0m\n",
      "[2023-08-08 18:22:38,971][root][INFO] - => Done in 5.025 s\n",
      "[2023-08-08 18:22:38,971][root][INFO] - \n",
      "[2023-08-08 18:22:38,971][root][INFO] - => Env setup ...\n",
      "[2023-08-08 18:22:38,975][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 18:22:38,975][root][INFO] - => Done in 4.124 ms\n",
      "[2023-08-08 18:22:38,975][root][INFO] - \n",
      "[2023-08-08 18:22:38,975][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 18:22:39,537][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 18:22:39,537][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 18:22:39,537][root][INFO] - => Done in 561.917 ms\n",
      "[2023-08-08 18:22:39,537][root][INFO] - \n",
      "[2023-08-08 18:22:39,537][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 18:22:39,537][root][INFO] - => Done in 108.004 us\n",
      "[2023-08-08 18:22:39,538][root][INFO] - \n",
      "[2023-08-08 18:22:39,538][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 18:22:39,538][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 18:22:40,260][root][INFO] - => Done in 721.985 ms\n",
      "[2023-08-08 18:22:40,260][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 0.905 MB of 0.905 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–…â–†â–†â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ˆâ–ˆâ–ˆâ–…â–†â–†â–ˆâ–†â–ˆâ–ƒâ–ƒâ–ˆâ–„â–ˆâ–„â–ˆâ–†â–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–†â–†â–ˆâ–â–ˆâ–†â–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ˆâ–ˆâ–ˆâ–‚â–„â–ƒâ–ˆâ–„â–‡â–‡â–‡â–ˆâ–â–ˆâ–â–ˆâ–„â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–„â–„â–ˆâ–ƒâ–ˆâ–„â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–…â–†â–†â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–„â–ƒâ–ˆâ–…â–‡â–…â–…â–ˆâ–â–ˆâ–‚â–ˆâ–…â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–…â–…â–ˆâ–â–ˆâ–…â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–…â–†â–†â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–…â–†â–…â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–ˆâ–‡â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–…â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–â–â–â–‡â–…â–†â–â–…â–‚â–â–â–â–ˆâ–â–ˆâ–â–…â–â–â–â–â–â–â–ˆâ–…â–…â–â–…â–â–…â–â–â–â–â–â–â–…â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–…â–†â–…â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–ˆâ–‡â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–…â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–â–â–â–‡â–…â–†â–â–…â–‚â–â–â–â–ˆâ–â–ˆâ–â–…â–â–â–â–â–â–â–ˆâ–…â–…â–â–…â–â–…â–â–â–â–â–â–â–…â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–…â–†â–…â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–ˆâ–‡â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–…â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–‡â–…â–†â–â–…â–‚â–â–â–â–ˆâ–â–ˆâ–â–…â–â–â–â–â–â–â–ˆâ–…â–…â–â–…â–â–…â–â–â–â–â–â–â–…â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–…â–†â–…â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–ˆâ–‡â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–…â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–‡â–…â–†â–â–…â–‚â–â–â–â–ˆâ–â–ˆâ–â–…â–â–â–â–â–â–â–ˆâ–…â–…â–â–…â–â–…â–â–â–â–â–â–â–…â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.9815\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.99497\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.99235\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 4.8908\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.9775\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 4.976\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.98425\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 4.976\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.985\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 1970.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 9.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.985\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 1970\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s3a1_s1a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/fgxu2kh4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_182235-fgxu2kh4/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 18:25:35,117][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s3a1_s2a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ConnectionError), entering retry loop.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ConnectionError), entering retry loop.\n",
      "Problem at: /Users/alexandrasouly/code/pax/pax/experiment.py 110 global_setup\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 1108, in init\n",
      "    run = wi.init()\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 742, in init\n",
      "    raise error\n",
      "wandb.errors.CommError: Error communicating with wandb process, exiting...\n",
      "For more info see: https://docs.wandb.ai/library/init#init-start-error\n",
      "[2023-08-08 18:59:09,643][urllib3.connectionpool][WARNING] - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x16ae25310>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /api/5288891/store/\n",
      "[2023-08-08 18:59:09,645][urllib3.connectionpool][WARNING] - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1798371c0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /api/5288891/store/\n",
      "[2023-08-08 18:59:09,646][urllib3.connectionpool][WARNING] - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x179837190>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /api/5288891/store/\n",
      "[2023-08-08 18:59:09,649][urllib3.connectionpool][WARNING] - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x179837b80>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /api/5288891/store/\n",
      "[2023-08-08 18:59:09,650][urllib3.connectionpool][WARNING] - Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x178e9f820>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /api/5288891/store/\n",
      "[2023-08-08 18:59:09,650][urllib3.connectionpool][WARNING] - Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x178e9f6d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /api/5288891/store/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Abnormal program exit\n",
      "[2023-08-08 18:59:11,654][root][INFO] - => Done in 33.609 m\n",
      "[2023-08-08 18:59:11,655][root][INFO] - \n",
      "Error executing job with overrides: ['+experiment=multi-shapers/comp/n3pl_2shap_tc_comp_eval', '++run_path1=ucl-dark/tensor-tc/8v8vokho', '++run_path2=ucl-dark/tensor-tc/0lg7du3n', '++model_path1=exp/3pl-2shap-tc/3pl_2shap_tc_3/2023-08-02_14.38.10.878306/generation_299_agent_0', '++model_path2=exp/3pl-2shap-tc/3pl_2shap_tc_2/2023-08-02_05.06.31.755800/generation_299_agent_1', '++wandb.name=3pl_2shap_tc_s3a1_s2a2_eval', '++wandb.group=3pl_2shap_tc-comp-nice_v_nice']\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 1108, in init\n",
      "    run = wi.init()\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 742, in init\n",
      "    raise error\n",
      "wandb.errors.CommError: Error communicating with wandb process, exiting...\n",
      "For more info see: https://docs.wandb.ai/library/init#init-start-error\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alexandrasouly/code/pax/pax/experiment.py\", line 780, in main\n",
      "    save_dir = global_setup(args)\n",
      "  File \"/Users/alexandrasouly/code/pax/pax/experiment.py\", line 110, in global_setup\n",
      "    wandb.init(\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 1145, in init\n",
      "    raise Exception(\"problem\") from error_seen\n",
      "Exception: problem\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 18:59:15,831][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s3a1_s3a1_eval\n",
      "[2023-08-08 19:15:53,229][wandb.sdk.lib.retry][INFO] - Retry attempt failed:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/urllib3/connection.py\", line 174, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/urllib3/util/connection.py\", line 72, in create_connection\n",
      "    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/socket.py\", line 954, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "socket.gaierror: [Errno 8] nodename nor servname provided, or not known\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 386, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 1042, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/urllib3/connection.py\", line 358, in connect\n",
      "    self.sock = conn = self._new_conn()\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/urllib3/connection.py\", line 186, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x1628c5850>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/requests/adapters.py\", line 489, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/urllib3/util/retry.py\", line 592, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /graphql (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1628c5850>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/sdk/lib/retry.py\", line 128, in __call__\n",
      "    result = self._call_fn(*args, **kwargs)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/sdk/internal/internal_api.py\", line 241, in execute\n",
      "    return self.client.execute(*args, **kwargs)  # type: ignore\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py\", line 52, in execute\n",
      "    result = self._get_result(document, *args, **kwargs)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py\", line 60, in _get_result\n",
      "    return self.transport.execute(document, *args, **kwargs)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/transport/requests.py\", line 38, in execute\n",
      "    request = requests.post(self.url, **post_args)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/requests/api.py\", line 115, in post\n",
      "    return request(\"post\", url, data=data, json=json, **kwargs)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/requests/api.py\", line 59, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/requests/sessions.py\", line 587, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/requests/sessions.py\", line 701, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/requests/adapters.py\", line 565, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /graphql (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x1628c5850>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ConnectionError), entering retry loop.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ConnectionError), entering retry loop.\n",
      "Problem at: /Users/alexandrasouly/code/pax/pax/experiment.py 110 global_setup\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 1108, in init\n",
      "    run = wi.init()\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 742, in init\n",
      "    raise error\n",
      "wandb.errors.CommError: Error communicating with wandb process, exiting...\n",
      "For more info see: https://docs.wandb.ai/library/init#init-start-error\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Abnormal program exit\n",
      "[2023-08-08 19:43:10,597][root][INFO] - => Done in 43.913 m\n",
      "[2023-08-08 19:43:10,597][root][INFO] - \n",
      "Error executing job with overrides: ['+experiment=multi-shapers/comp/n3pl_2shap_tc_comp_eval', '++run_path1=ucl-dark/tensor-tc/8v8vokho', '++run_path2=ucl-dark/tensor-tc/8v8vokho', '++model_path1=exp/3pl-2shap-tc/3pl_2shap_tc_3/2023-08-02_14.38.10.878306/generation_299_agent_0', '++model_path2=exp/3pl-2shap-tc/3pl_2shap_tc_3/2023-08-02_14.38.10.878306/generation_299_agent_0', '++wandb.name=3pl_2shap_tc_s3a1_s3a1_eval', '++wandb.group=3pl_2shap_tc-comp-nice_v_nice']\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 1108, in init\n",
      "    run = wi.init()\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 742, in init\n",
      "    raise error\n",
      "wandb.errors.CommError: Error communicating with wandb process, exiting...\n",
      "For more info see: https://docs.wandb.ai/library/init#init-start-error\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alexandrasouly/code/pax/pax/experiment.py\", line 780, in main\n",
      "    save_dir = global_setup(args)\n",
      "  File \"/Users/alexandrasouly/code/pax/pax/experiment.py\", line 110, in global_setup\n",
      "    wandb.init(\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 1145, in init\n",
      "    raise Exception(\"problem\") from error_seen\n",
      "Exception: problem\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 19:43:15,369][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s3a1_s4a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_194317-swn50fjp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s3a1_s4a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/swn50fjp\u001b[0m\n",
      "[2023-08-08 19:43:24,079][root][INFO] - => Done in 8.710 s\n",
      "[2023-08-08 19:43:24,080][root][INFO] - \n",
      "[2023-08-08 19:43:24,080][root][INFO] - => Env setup ...\n",
      "[2023-08-08 19:43:24,089][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 19:43:24,089][root][INFO] - => Done in 9.391 ms\n",
      "[2023-08-08 19:43:24,090][root][INFO] - \n",
      "[2023-08-08 19:43:24,090][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 19:43:24,746][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 19:43:24,747][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 19:43:24,747][root][INFO] - => Done in 657.003 ms\n",
      "[2023-08-08 19:43:24,747][root][INFO] - \n",
      "[2023-08-08 19:43:24,747][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 19:43:24,747][root][INFO] - => Done in 119.925 us\n",
      "[2023-08-08 19:43:24,747][root][INFO] - \n",
      "[2023-08-08 19:43:24,747][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 19:43:24,747][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 19:43:25,545][root][INFO] - => Done in 798.293 ms\n",
      "[2023-08-08 19:43:25,546][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.913 MB of 0.925 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–…â–†â–†â–†â–†â–…â–‡â–„â–†â–‡â–†â–ˆâ–…â–ˆâ–†â–†â–„â–ˆâ–†â–‡â–ƒâ–…â–†â–…â–†â–‡â–„â–…â–‡â–ˆâ–‡â–†â–†â–ƒâ–…â–ˆâ–‡â–„â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–ƒâ–…â–†â–„â–†â–„â–†â–„â–„â–‚â–…â–„â–…â–‚â–ƒâ–„â–ƒâ–„â–…â–‚â–ƒâ–„â–…â–„â–ƒâ–„â–â–ƒâ–…â–„â–‚â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‡â–‡â–‡â–†â–†â–…â–†â–„â–…â–†â–„â–†â–ƒâ–†â–ƒâ–„â–‚â–…â–„â–„â–‚â–ƒâ–„â–‚â–ƒâ–„â–‚â–‚â–ƒâ–„â–„â–ƒâ–„â–â–ƒâ–…â–ƒâ–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–…â–…â–†â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–†â–‡â–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‡â–‡â–‡â–‡â–†â–…â–†â–„â–…â–†â–„â–†â–„â–†â–„â–„â–‚â–…â–„â–…â–‚â–ƒâ–„â–ƒâ–„â–…â–‚â–ƒâ–„â–…â–„â–ƒâ–„â–â–ƒâ–…â–„â–‚â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–…â–…â–†â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–†â–‡â–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–…â–…â–…â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–…â–„â–ƒâ–…â–ƒâ–…â–ƒâ–…â–…â–†â–„â–…â–„â–‡â–†â–…â–…â–…â–„â–‡â–…â–„â–ƒâ–…â–†â–…â–ˆâ–†â–„â–„â–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–ˆâ–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–â–â–â–†â–…â–…â–â–â–‚â–â–â–â–‡â–â–†â–â–„â–â–â–„â–â–â–â–ˆâ–…â–…â–â–ˆâ–…â–…â–â–â–â–â–â–â–…â–â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–‚â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–…â–…â–…â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–…â–„â–ƒâ–…â–ƒâ–…â–ƒâ–…â–…â–†â–„â–…â–„â–‡â–†â–…â–…â–…â–„â–‡â–…â–„â–ƒâ–…â–†â–…â–ˆâ–†â–„â–„â–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–ˆâ–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–â–â–â–†â–…â–…â–â–â–‚â–â–â–â–‡â–â–†â–â–„â–â–â–„â–â–â–â–ˆâ–…â–…â–â–ˆâ–…â–…â–â–â–â–â–â–â–…â–â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–‚â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–„â–‡â–…â–…â–†â–ƒâ–…â–†â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–ƒâ–â–â–â–â–â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–…â–„â–ƒâ–…â–ƒâ–…â–ƒâ–…â–…â–†â–„â–…â–„â–‡â–†â–…â–…â–…â–„â–‡â–…â–„â–ƒâ–…â–†â–…â–ˆâ–†â–„â–„â–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–ˆâ–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–†â–…â–…â–â–â–‚â–â–â–â–‡â–â–†â–â–„â–â–â–„â–â–â–â–ˆâ–…â–…â–â–ˆâ–…â–…â–â–â–â–â–â–â–…â–â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–‚â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–„â–‡â–…â–…â–†â–ƒâ–…â–†â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–ƒâ–â–â–â–â–â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–…â–„â–ƒâ–…â–ƒâ–…â–ƒâ–…â–…â–†â–„â–…â–„â–‡â–†â–…â–…â–…â–„â–‡â–…â–„â–ƒâ–…â–†â–…â–ˆâ–†â–„â–„â–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–ˆâ–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–†â–…â–…â–â–â–‚â–â–â–â–‡â–â–†â–â–„â–â–â–„â–â–â–â–ˆâ–…â–…â–â–ˆâ–…â–…â–â–â–â–â–â–â–…â–â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–‚â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.761\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.76332\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.90365\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 4.62182\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.7145\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.881\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 4.6875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.79775\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 4.6875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.9255\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0555\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 10.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 1851.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 111.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 8.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.9255\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0555\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 1851\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 111\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s3a1_s4a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/swn50fjp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_194317-swn50fjp/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 19:44:00,926][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s3a1_s5a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_194402-12zfwgwn\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s3a1_s5a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/12zfwgwn\u001b[0m\n",
      "[2023-08-08 19:44:06,997][root][INFO] - => Done in 6.071 s\n",
      "[2023-08-08 19:44:06,997][root][INFO] - \n",
      "[2023-08-08 19:44:06,997][root][INFO] - => Env setup ...\n",
      "[2023-08-08 19:44:07,002][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 19:44:07,002][root][INFO] - => Done in 4.314 ms\n",
      "[2023-08-08 19:44:07,002][root][INFO] - \n",
      "[2023-08-08 19:44:07,002][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 19:44:07,554][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 19:44:07,554][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 19:44:07,555][root][INFO] - => Done in 552.756 ms\n",
      "[2023-08-08 19:44:07,555][root][INFO] - \n",
      "[2023-08-08 19:44:07,555][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 19:44:07,555][root][INFO] - => Done in 110.149 us\n",
      "[2023-08-08 19:44:07,555][root][INFO] - \n",
      "[2023-08-08 19:44:07,555][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 19:44:07,555][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 19:44:08,281][root][INFO] - => Done in 726.073 ms\n",
      "[2023-08-08 19:44:08,281][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 0.915 MB of 0.927 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–‡â–„â–â–„â–…â–ƒâ–†â–ƒâ–â–ƒâ–…â–‚â–‚â–ƒâ–†â–ƒâ–‚â–‚â–…â–†â–â–„â–ƒâ–‚â–ƒâ–„â–†â–‚â–ƒâ–…â–…â–„â–ƒâ–ƒâ–…â–…â–ˆâ–„â–„â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–„â–‚â–„â–…â–„â–†â–„â–ƒâ–„â–…â–ƒâ–ƒâ–„â–ˆâ–ƒâ–„â–‚â–…â–†â–â–„â–ƒâ–‚â–‚â–ƒâ–…â–â–‚â–„â–„â–ƒâ–‚â–‚â–ƒâ–ƒâ–†â–ƒâ–ƒâ–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‡â–ƒâ–…â–„â–‚â–…â–ƒâ–…â–ƒâ–…â–„â–â–ƒâ–…â–„â–‚â–„â–„â–†â–„â–„â–…â–…â–…â–…â–†â–‡â–†â–…â–…â–†â–ƒâ–†â–‡â–ˆâ–ˆâ–†â–‡â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–„â–ƒâ–‚â–„â–„â–ƒâ–…â–ƒâ–â–ƒâ–…â–‚â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–†â–†â–ƒâ–„â–„â–ƒâ–„â–„â–†â–„â–…â–†â–†â–„â–„â–„â–†â–…â–ˆâ–…â–…â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–…â–‚â–„â–…â–ƒâ–…â–ƒâ–ƒâ–ƒâ–…â–‚â–‚â–ƒâ–‡â–ƒâ–ƒâ–‚â–„â–†â–â–ƒâ–ƒâ–‚â–‚â–ƒâ–…â–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–„â–†â–ƒâ–„â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–„â–ƒâ–‚â–„â–„â–ƒâ–…â–ƒâ–â–ƒâ–…â–‚â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–†â–†â–ƒâ–„â–„â–ƒâ–„â–„â–†â–„â–…â–†â–†â–„â–„â–„â–†â–…â–ˆâ–…â–…â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–…â–„â–…â–…â–…â–…â–…â–…â–…â–…â–„â–…â–…â–ˆâ–„â–…â–ƒâ–„â–…â–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–â–‚â–„â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–‚â–„â–ƒâ–„â–ƒâ–ƒâ–„â–‚â–ƒâ–ƒâ–„â–„â–ƒâ–‚â–â–„â–ƒâ–…â–†â–…â–†â–„â–…â–…â–…â–†â–†â–‡â–‡â–…â–‡â–†â–…â–‡â–ˆâ–‡â–‡â–‡â–†â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–…â–‡â–…â–„â–…â–ƒâ–…â–‡â–…â–„â–‡â–†â–…â–‚â–†â–†â–‡â–„â–ƒâ–ˆâ–…â–†â–‡â–‡â–†â–„â–ˆâ–‡â–…â–†â–†â–‡â–‡â–†â–†â–ƒâ–†â–†â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–‚â–ˆâ–â–…â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–…â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–â–â–ƒâ–ˆâ–…â–ˆâ–â–ƒâ–…â–â–â–…â–ƒâ–â–ƒâ–â–ƒâ–â–â–â–â–â–â–ƒâ–ƒâ–â–â–ƒâ–ƒâ–†â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–ˆâ–ƒâ–â–†â–â–â–â–…â–â–â–ƒâ–â–ƒâ–â–â–…â–â–â–â–…â–…â–â–â–â–â–…â–â–â–â–â–â–â–â–â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–…â–„â–…â–…â–…â–…â–…â–…â–…â–…â–„â–…â–…â–ˆâ–„â–…â–ƒâ–„â–…â–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–â–‚â–„â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–‚â–„â–ƒâ–„â–ƒâ–ƒâ–„â–‚â–ƒâ–ƒâ–„â–„â–ƒâ–‚â–â–„â–ƒâ–…â–†â–…â–†â–„â–…â–…â–…â–†â–†â–‡â–‡â–…â–‡â–†â–…â–‡â–ˆâ–‡â–‡â–‡â–†â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–…â–‡â–…â–„â–…â–ƒâ–…â–‡â–…â–„â–‡â–†â–…â–‚â–†â–†â–‡â–…â–ƒâ–ˆâ–…â–†â–‡â–‡â–†â–„â–ˆâ–‡â–…â–†â–†â–‡â–‡â–†â–†â–ƒâ–†â–†â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–‚â–ˆâ–â–…â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–…â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–â–â–ƒâ–ˆâ–…â–ˆâ–â–ƒâ–…â–â–â–…â–ƒâ–â–ƒâ–â–ƒâ–â–â–â–â–â–â–ƒâ–ƒâ–â–â–ƒâ–ƒâ–†â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–ˆâ–ƒâ–â–†â–â–â–â–…â–â–â–ƒâ–â–ƒâ–â–â–…â–â–â–â–…â–…â–â–â–â–â–…â–â–â–â–â–â–â–â–â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–…â–„â–…â–…â–…â–…â–…â–…â–…â–…â–„â–…â–…â–ˆâ–„â–…â–ƒâ–„â–…â–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–â–‚â–„â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–ƒâ–‚â–„â–„â–ƒâ–…â–‚â–â–ƒâ–„â–ƒâ–„â–‚â–‚â–„â–ƒâ–„â–‡â–…â–„â–„â–…â–„â–…â–…â–†â–…â–†â–†â–ˆâ–…â–†â–†â–‡â–†â–ˆâ–†â–†â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–ƒâ–…â–„â–„â–ƒâ–‚â–ƒâ–ƒâ–…â–ƒâ–ƒâ–…â–‚â–ƒâ–â–„â–‚â–…â–ƒâ–ƒâ–†â–„â–…â–†â–…â–…â–„â–ˆâ–†â–„â–…â–†â–„â–‡â–‡â–‡â–„â–†â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–…â–‡â–…â–„â–…â–ƒâ–…â–‡â–…â–„â–‡â–†â–…â–‚â–†â–†â–‡â–„â–ƒâ–ˆâ–…â–†â–‡â–‡â–†â–„â–ˆâ–‡â–…â–†â–†â–‡â–‡â–†â–†â–ƒâ–†â–†â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–‚â–ˆâ–â–…â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–…â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–ˆâ–â–ƒâ–â–â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–â–†â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–â–â–ƒâ–ƒâ–†â–ˆâ–â–ƒâ–ƒâ–â–â–†â–ƒâ–â–ƒâ–â–ƒâ–â–â–â–â–â–â–â–ƒâ–â–â–ƒâ–ƒâ–ƒâ–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–ˆâ–ƒâ–â–†â–â–â–â–…â–â–â–ƒâ–â–ƒâ–â–â–…â–â–â–â–…â–…â–â–â–â–â–…â–â–â–â–â–â–â–â–â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–…â–„â–…â–…â–…â–…â–…â–…â–…â–…â–„â–…â–…â–ˆâ–„â–…â–ƒâ–„â–…â–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–â–‚â–„â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–ƒâ–‚â–„â–„â–ƒâ–…â–‚â–â–ƒâ–„â–ƒâ–„â–‚â–‚â–„â–ƒâ–„â–‡â–…â–„â–„â–…â–„â–…â–…â–†â–…â–†â–†â–ˆâ–…â–†â–†â–‡â–†â–ˆâ–†â–†â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–ƒâ–…â–„â–„â–ƒâ–‚â–ƒâ–ƒâ–…â–ƒâ–ƒâ–…â–‚â–ƒâ–â–„â–‚â–…â–ƒâ–ƒâ–†â–„â–…â–†â–…â–…â–„â–ˆâ–†â–„â–…â–†â–„â–‡â–‡â–‡â–„â–†â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–…â–‡â–…â–„â–…â–ƒâ–…â–‡â–…â–„â–‡â–†â–…â–‚â–†â–†â–‡â–…â–ƒâ–ˆâ–…â–†â–‡â–‡â–†â–„â–ˆâ–‡â–…â–†â–†â–‡â–‡â–†â–†â–ƒâ–†â–†â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–‚â–ˆâ–â–…â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–…â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–ˆâ–â–ƒâ–â–â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–â–†â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–â–â–ƒâ–ƒâ–†â–ˆâ–â–ƒâ–ƒâ–â–â–†â–ƒâ–â–ƒâ–â–ƒâ–â–â–â–â–â–â–â–ƒâ–â–â–ƒâ–ƒâ–ƒâ–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–ˆâ–ƒâ–â–†â–â–â–â–…â–â–â–ƒâ–â–ƒâ–â–â–…â–â–â–â–…â–…â–â–â–â–â–…â–â–â–â–â–â–â–â–â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.28633\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.48324\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.9953\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 3.33552\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.488\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 2.0265\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 3.3445\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.75725\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 3.3445\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.2975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.5905\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 595.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 1181.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 202.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.2975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.5135\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.077\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 595\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 1027\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 154\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 202\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s3a1_s5a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/12zfwgwn\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_194402-12zfwgwn/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 19:44:43,781][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s4a2_s1a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_194445-l8l4lvcx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s4a2_s1a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/l8l4lvcx\u001b[0m\n",
      "[2023-08-08 19:44:49,537][root][INFO] - => Done in 5.756 s\n",
      "[2023-08-08 19:44:49,537][root][INFO] - \n",
      "[2023-08-08 19:44:49,537][root][INFO] - => Env setup ...\n",
      "[2023-08-08 19:44:49,541][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 19:44:49,541][root][INFO] - => Done in 3.160 ms\n",
      "[2023-08-08 19:44:49,541][root][INFO] - \n",
      "[2023-08-08 19:44:49,541][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 19:44:50,078][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 19:44:50,078][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 19:44:50,078][root][INFO] - => Done in 537.551 ms\n",
      "[2023-08-08 19:44:50,078][root][INFO] - \n",
      "[2023-08-08 19:44:50,078][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 19:44:50,079][root][INFO] - => Done in 108.004 us\n",
      "[2023-08-08 19:44:50,079][root][INFO] - \n",
      "[2023-08-08 19:44:50,079][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 19:44:50,079][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 19:44:50,799][root][INFO] - => Done in 720.296 ms\n",
      "[2023-08-08 19:44:50,799][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.916 MB of 0.928 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–ˆâ–‡â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–ˆâ–‡â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–ˆâ–‡â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–ˆâ–‡â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.99751\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.99885\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 4.89838\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 4.9985\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 4.9985\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 1979.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 1979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s4a2_s1a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/l8l4lvcx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_194445-l8l4lvcx/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 19:45:25,010][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s4a2_s2a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_194526-c3gcvh44\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s4a2_s2a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/c3gcvh44\u001b[0m\n",
      "[2023-08-08 19:45:30,943][root][INFO] - => Done in 5.933 s\n",
      "[2023-08-08 19:45:30,943][root][INFO] - \n",
      "[2023-08-08 19:45:30,943][root][INFO] - => Env setup ...\n",
      "[2023-08-08 19:45:30,947][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 19:45:30,947][root][INFO] - => Done in 3.179 ms\n",
      "[2023-08-08 19:45:30,947][root][INFO] - \n",
      "[2023-08-08 19:45:30,947][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 19:45:31,504][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 19:45:31,504][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 19:45:31,504][root][INFO] - => Done in 557.494 ms\n",
      "[2023-08-08 19:45:31,504][root][INFO] - \n",
      "[2023-08-08 19:45:31,504][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 19:45:31,504][root][INFO] - => Done in 113.010 us\n",
      "[2023-08-08 19:45:31,505][root][INFO] - \n",
      "[2023-08-08 19:45:31,505][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 19:45:31,505][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 19:45:32,259][root][INFO] - => Done in 754.774 ms\n",
      "[2023-08-08 19:45:32,260][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 0.917 MB of 0.929 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–†â–†â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–…â–ˆâ–‡â–ˆâ–†â–‡â–†â–‡â–†â–†â–…â–…â–…â–…â–…â–‡â–„â–…â–‡â–‡â–†â–…â–…â–…â–„â–‡â–…â–„â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–„â–†â–…â–ƒâ–†â–…â–†â–„â–…â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–„â–â–‚â–„â–„â–ƒâ–‚â–‚â–‚â–â–„â–ƒâ–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–…â–†â–†â–ƒâ–†â–…â–†â–„â–…â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–„â–â–‚â–„â–„â–ƒâ–‚â–‚â–‚â–â–„â–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–…â–†â–…â–ƒâ–†â–…â–†â–„â–…â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–„â–â–‚â–„â–„â–ƒâ–‚â–‚â–‚â–â–„â–ƒâ–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–…â–ƒâ–„â–†â–ƒâ–„â–ƒâ–…â–„â–†â–…â–†â–†â–‡â–‡â–†â–‡â–‡â–…â–ˆâ–‡â–…â–…â–†â–‡â–‡â–‡â–ˆâ–…â–†â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–…â–ƒâ–„â–†â–ƒâ–„â–ƒâ–…â–„â–†â–…â–†â–†â–‡â–‡â–†â–‡â–‡â–…â–ˆâ–‡â–…â–…â–†â–‡â–‡â–‡â–ˆâ–…â–†â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–ƒâ–‚â–‚â–„â–‚â–…â–ˆâ–…â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–ƒâ–â–â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–â–‚â–‚â–â–â–‚â–â–‚â–â–ƒâ–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–…â–ƒâ–„â–†â–ƒâ–„â–ƒâ–…â–„â–†â–…â–†â–†â–‡â–‡â–†â–‡â–‡â–…â–ˆâ–‡â–…â–…â–†â–‡â–‡â–‡â–ˆâ–…â–†â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–ƒâ–‚â–‚â–„â–‚â–…â–ˆâ–…â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–ƒâ–â–â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–â–‚â–‚â–â–â–‚â–â–‚â–â–ƒâ–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–…â–ƒâ–„â–†â–ƒâ–„â–ƒâ–…â–„â–†â–…â–†â–†â–‡â–‡â–†â–‡â–‡â–…â–ˆâ–‡â–…â–…â–†â–‡â–‡â–‡â–ˆâ–…â–†â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.7355\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.7875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.91788\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 4.6426\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.68\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.872\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 4.6545\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.776\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 4.6545\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0085\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.9175\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.064\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 17.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 1835.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 128.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0085\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.9175\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.064\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 1835\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s4a2_s2a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/c3gcvh44\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_194526-c3gcvh44/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 19:46:07,450][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s4a2_s3a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_194609-oimg4lh2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s4a2_s3a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/oimg4lh2\u001b[0m\n",
      "[2023-08-08 19:46:13,661][root][INFO] - => Done in 6.211 s\n",
      "[2023-08-08 19:46:13,661][root][INFO] - \n",
      "[2023-08-08 19:46:13,661][root][INFO] - => Env setup ...\n",
      "[2023-08-08 19:46:13,665][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 19:46:13,665][root][INFO] - => Done in 3.834 ms\n",
      "[2023-08-08 19:46:13,665][root][INFO] - \n",
      "[2023-08-08 19:46:13,665][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 19:46:14,221][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 19:46:14,221][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 19:46:14,221][root][INFO] - => Done in 556.463 ms\n",
      "[2023-08-08 19:46:14,221][root][INFO] - \n",
      "[2023-08-08 19:46:14,221][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 19:46:14,222][root][INFO] - => Done in 123.262 us\n",
      "[2023-08-08 19:46:14,222][root][INFO] - \n",
      "[2023-08-08 19:46:14,222][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 19:46:14,222][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 19:46:14,975][root][INFO] - => Done in 753.760 ms\n",
      "[2023-08-08 19:46:14,976][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 0.930 MB of 0.930 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.99986\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.9997\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 4.90055\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 4.9985\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 4.9985\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 1979.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 1979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s4a2_s3a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/oimg4lh2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_194609-oimg4lh2/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 19:46:50,665][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s4a2_s4a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_194652-ogf0jb4w\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s4a2_s4a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/ogf0jb4w\u001b[0m\n",
      "[2023-08-08 19:46:56,533][root][INFO] - => Done in 5.867 s\n",
      "[2023-08-08 19:46:56,533][root][INFO] - \n",
      "[2023-08-08 19:46:56,533][root][INFO] - => Env setup ...\n",
      "[2023-08-08 19:46:56,536][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 19:46:56,536][root][INFO] - => Done in 3.110 ms\n",
      "[2023-08-08 19:46:56,536][root][INFO] - \n",
      "[2023-08-08 19:46:56,536][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 19:46:57,110][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 19:46:57,111][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 19:46:57,111][root][INFO] - => Done in 574.650 ms\n",
      "[2023-08-08 19:46:57,111][root][INFO] - \n",
      "[2023-08-08 19:46:57,111][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 19:46:57,111][root][INFO] - => Done in 108.004 us\n",
      "[2023-08-08 19:46:57,111][root][INFO] - \n",
      "[2023-08-08 19:46:57,111][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 19:46:57,111][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 19:46:57,864][root][INFO] - => Done in 752.591 ms\n",
      "[2023-08-08 19:46:57,864][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 0.919 MB of 0.931 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–…â–…â–†â–†â–‡â–†â–†â–„â–†â–‡â–†â–ˆâ–†â–ˆâ–†â–†â–„â–‡â–†â–ˆâ–ƒâ–…â–†â–†â–‡â–ˆâ–„â–†â–†â–ˆâ–‡â–†â–†â–ƒâ–…â–‡â–‡â–„â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–ƒâ–…â–†â–„â–†â–„â–†â–„â–„â–‚â–…â–„â–…â–‚â–ƒâ–„â–„â–„â–…â–‚â–„â–„â–†â–„â–ƒâ–„â–â–ƒâ–…â–…â–‚â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–„â–…â–†â–„â–†â–„â–†â–„â–„â–‚â–…â–„â–…â–‚â–ƒâ–„â–ƒâ–„â–…â–‚â–„â–ƒâ–…â–„â–ƒâ–„â–â–ƒâ–…â–„â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–ˆâ–†â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–‡â–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–„â–…â–†â–„â–†â–„â–†â–„â–„â–‚â–…â–„â–…â–‚â–ƒâ–„â–„â–„â–…â–‚â–„â–„â–…â–„â–ƒâ–„â–â–ƒâ–…â–…â–‚â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–ˆâ–†â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–‡â–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–†â–„â–ƒâ–…â–ƒâ–…â–ƒâ–…â–…â–‡â–„â–…â–„â–‡â–†â–…â–…â–…â–„â–‡â–…â–„â–ƒâ–…â–†â–…â–ˆâ–†â–„â–„â–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–†â–„â–ƒâ–…â–ƒâ–…â–ƒâ–…â–…â–‡â–„â–…â–„â–‡â–†â–…â–…â–…â–„â–‡â–…â–„â–ƒâ–…â–†â–…â–ˆâ–†â–„â–„â–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–…â–‡â–…â–…â–†â–ƒâ–…â–†â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–†â–„â–ƒâ–…â–ƒâ–…â–ƒâ–…â–…â–‡â–„â–…â–„â–‡â–†â–…â–…â–…â–„â–‡â–…â–„â–ƒâ–…â–†â–…â–ˆâ–†â–„â–„â–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–…â–‡â–…â–…â–†â–ƒâ–…â–†â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–†â–„â–ƒâ–…â–ƒâ–…â–ƒâ–…â–…â–‡â–„â–…â–„â–‡â–†â–…â–…â–…â–„â–‡â–…â–„â–ƒâ–…â–†â–…â–ˆâ–†â–„â–„â–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.759\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.76514\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.90985\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 4.63009\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.705\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.882\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 4.69\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.7935\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 4.69\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.926\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.059\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 10.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 1852.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 118.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.926\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.059\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 1852\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 118\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s4a2_s4a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/ogf0jb4w\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_194652-ogf0jb4w/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 19:47:33,451][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s4a2_s5a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_194734-3vrdsmzf\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s4a2_s5a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/3vrdsmzf\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ConnectionError), entering retry loop.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ConnectionError), entering retry loop.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ConnectionError), entering retry loop.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ConnectionError), entering retry loop.\n",
      "[2023-08-08 20:01:38,415][root][INFO] - => Done in 14.083 m\n",
      "[2023-08-08 20:01:38,415][root][INFO] - \n",
      "[2023-08-08 20:01:38,415][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:01:38,421][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:01:38,421][root][INFO] - => Done in 5.476 ms\n",
      "[2023-08-08 20:01:38,421][root][INFO] - \n",
      "[2023-08-08 20:01:38,421][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:01:39,011][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:01:39,012][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:01:39,012][root][INFO] - => Done in 590.822 ms\n",
      "[2023-08-08 20:01:39,012][root][INFO] - \n",
      "[2023-08-08 20:01:39,012][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:01:39,012][root][INFO] - => Done in 111.103 us\n",
      "[2023-08-08 20:01:39,012][root][INFO] - \n",
      "[2023-08-08 20:01:39,012][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:01:39,012][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:01:39,795][root][INFO] - => Done in 783.444 ms\n",
      "[2023-08-08 20:01:39,796][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: | 0.932 MB of 0.932 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–‡â–…â–â–„â–…â–ƒâ–†â–‚â–â–ƒâ–…â–‚â–‚â–ƒâ–†â–ƒâ–„â–â–†â–†â–‚â–„â–ƒâ–‚â–ƒâ–ƒâ–†â–‚â–ƒâ–…â–…â–„â–ƒâ–ƒâ–…â–…â–ˆâ–„â–…â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–…â–‚â–„â–…â–„â–†â–ƒâ–ƒâ–„â–…â–‚â–ƒâ–„â–ˆâ–ƒâ–„â–â–…â–†â–â–„â–ƒâ–‚â–‚â–ƒâ–…â–â–‚â–…â–ƒâ–ƒâ–ƒâ–‚â–„â–ƒâ–†â–‚â–„â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ˆâ–ƒâ–…â–…â–‚â–…â–ƒâ–…â–ƒâ–…â–„â–â–ƒâ–…â–„â–ƒâ–‚â–…â–†â–„â–„â–…â–„â–„â–…â–†â–‡â–†â–…â–…â–†â–„â–‡â–‡â–ˆâ–ˆâ–…â–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–„â–„â–‚â–„â–„â–„â–…â–ƒâ–â–ƒâ–…â–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–‡â–†â–ƒâ–„â–„â–ƒâ–„â–„â–†â–„â–…â–…â–†â–„â–…â–„â–†â–…â–ˆâ–…â–…â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–…â–‚â–„â–…â–ƒâ–…â–ƒâ–ƒâ–ƒâ–…â–‚â–‚â–„â–‡â–ƒâ–„â–â–…â–†â–â–„â–ƒâ–‚â–‚â–ƒâ–…â–‚â–ƒâ–…â–„â–„â–ƒâ–‚â–„â–„â–†â–ƒâ–„â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–„â–„â–‚â–„â–„â–„â–…â–ƒâ–â–ƒâ–…â–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–‡â–†â–ƒâ–„â–„â–ƒâ–„â–„â–†â–„â–…â–…â–†â–„â–…â–„â–†â–…â–ˆâ–…â–…â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–…â–„â–„â–…â–…â–…â–…â–…â–…â–…â–„â–„â–…â–ˆâ–„â–…â–‚â–„â–…â–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–â–‚â–„â–‚â–ƒâ–ƒâ–â–‚â–‚â–ƒâ–‚â–ƒâ–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–‚â–„â–ƒâ–„â–„â–ƒâ–„â–ƒâ–‚â–ƒâ–„â–„â–ƒâ–ƒâ–â–„â–ƒâ–…â–†â–…â–…â–„â–…â–…â–†â–…â–†â–‡â–‡â–…â–‡â–†â–†â–‡â–ˆâ–‡â–‡â–‡â–†â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–„â–‡â–…â–„â–…â–ƒâ–…â–†â–…â–„â–‡â–†â–…â–‚â–†â–…â–ˆâ–„â–ƒâ–ˆâ–…â–†â–‡â–‡â–†â–„â–ˆâ–‡â–„â–†â–†â–†â–‡â–…â–†â–ƒâ–‡â–…â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–„â–‚â–‚â–…â–‚â–„â–„â–â–‚â–„â–„â–â–â–‚â–…â–‚â–â–â–â–â–â–„â–„â–â–â–‚â–â–ˆâ–â–‚â–„â–‚â–…â–â–â–â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–„â–â–ƒâ–ƒâ–ƒâ–…â–†â–„â–„â–…â–ƒâ–ƒâ–…â–ƒâ–‚â–ƒâ–ƒâ–ˆâ–â–ƒâ–ƒâ–ƒâ–â–‚â–„â–ƒâ–â–â–…â–…â–ƒâ–â–‚â–â–‡â–‚â–â–„â–â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–‚â–‚â–‡â–‚â–…â–ƒâ–â–‚â–â–ˆâ–â–‚â–‚â–‡â–ˆâ–‚â–â–ƒâ–â–â–‚â–‚â–ƒâ–â–â–â–‚â–…â–â–â–â–â–â–‚â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–…â–„â–„â–…â–…â–…â–…â–…â–…â–…â–„â–„â–…â–ˆâ–„â–…â–‚â–„â–…â–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–â–‚â–„â–‚â–ƒâ–ƒâ–â–‚â–‚â–ƒâ–‚â–ƒâ–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–‚â–„â–ƒâ–„â–„â–ƒâ–„â–ƒâ–‚â–ƒâ–„â–„â–ƒâ–ƒâ–â–„â–ƒâ–…â–†â–…â–…â–„â–…â–…â–†â–…â–†â–‡â–‡â–…â–‡â–†â–†â–‡â–ˆâ–‡â–‡â–‡â–†â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–„â–‡â–…â–„â–…â–ƒâ–…â–†â–…â–„â–‡â–†â–…â–‚â–†â–…â–ˆâ–„â–ƒâ–ˆâ–…â–†â–‡â–‡â–†â–„â–ˆâ–‡â–„â–†â–†â–†â–‡â–…â–†â–ƒâ–‡â–…â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–„â–‚â–‚â–…â–‚â–„â–„â–â–‚â–„â–„â–â–â–‚â–…â–‚â–â–â–â–â–â–„â–„â–â–â–‚â–â–ˆâ–â–‚â–„â–‚â–…â–â–â–â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–„â–â–ƒâ–ƒâ–ƒâ–…â–†â–„â–„â–…â–ƒâ–ƒâ–…â–ƒâ–‚â–ƒâ–ƒâ–ˆâ–â–ƒâ–ƒâ–ƒâ–â–‚â–„â–ƒâ–â–â–…â–…â–ƒâ–â–‚â–â–‡â–‚â–â–„â–â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–‚â–‚â–‡â–‚â–…â–ƒâ–â–‚â–â–ˆâ–â–‚â–‚â–‡â–ˆâ–‚â–â–ƒâ–â–â–‚â–‚â–ƒâ–â–â–â–‚â–…â–â–â–â–â–â–‚â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–…â–„â–„â–…â–…â–…â–…â–…â–…â–…â–„â–„â–…â–ˆâ–„â–…â–‚â–„â–…â–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–â–‚â–„â–‚â–ƒâ–ƒâ–â–‚â–‚â–ƒâ–‚â–ƒâ–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–‚â–ƒâ–ƒâ–„â–„â–ƒâ–…â–ƒâ–â–ƒâ–„â–ƒâ–„â–ƒâ–‚â–„â–„â–„â–‡â–†â–…â–„â–…â–„â–…â–…â–†â–…â–†â–…â–ˆâ–…â–†â–†â–‡â–†â–ˆâ–†â–†â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–ƒâ–…â–„â–„â–ƒâ–‚â–ƒâ–ƒâ–…â–ƒâ–ƒâ–…â–‚â–ƒâ–â–„â–ƒâ–…â–ƒâ–ƒâ–†â–„â–…â–†â–…â–…â–„â–ˆâ–‡â–ƒâ–…â–†â–„â–‡â–‡â–‡â–„â–†â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–„â–‡â–…â–„â–…â–ƒâ–…â–†â–…â–„â–‡â–†â–…â–‚â–†â–…â–ˆâ–„â–ƒâ–ˆâ–…â–†â–‡â–‡â–†â–„â–ˆâ–‡â–„â–†â–†â–†â–‡â–…â–†â–ƒâ–‡â–…â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–„â–‚â–‚â–…â–‚â–„â–„â–â–‚â–„â–„â–â–â–‚â–…â–‚â–â–â–â–â–â–„â–„â–â–â–‚â–â–ˆâ–â–‚â–„â–‚â–…â–â–â–â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–‚â–â–ƒâ–‚â–ƒâ–…â–†â–…â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–â–‚â–‚â–…â–â–‚â–â–â–â–‚â–ƒâ–‚â–â–â–…â–â–‚â–â–‚â–â–ˆâ–‚â–â–…â–â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–…â–â–â–ƒâ–â–ƒâ–ƒâ–â–ƒâ–…â–â–ƒâ–…â–â–ƒâ–ƒâ–ƒâ–ˆâ–â–ƒâ–…â–…â–â–â–ƒâ–ƒâ–â–â–ƒâ–ˆâ–ƒâ–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–‚â–‚â–‡â–‚â–…â–ƒâ–â–‚â–â–ˆâ–â–‚â–‚â–‡â–ˆâ–‚â–â–ƒâ–â–â–‚â–‚â–ƒâ–â–â–â–‚â–…â–â–â–â–â–â–‚â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–…â–„â–„â–…â–…â–…â–…â–…â–…â–…â–„â–„â–…â–ˆâ–„â–…â–‚â–„â–…â–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–â–‚â–„â–‚â–ƒâ–ƒâ–â–‚â–‚â–ƒâ–‚â–ƒâ–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–‚â–ƒâ–ƒâ–„â–„â–ƒâ–…â–ƒâ–â–ƒâ–„â–ƒâ–„â–ƒâ–‚â–„â–„â–„â–‡â–†â–…â–„â–…â–„â–…â–…â–†â–…â–†â–…â–ˆâ–…â–†â–†â–‡â–†â–ˆâ–†â–†â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–ƒâ–…â–„â–„â–ƒâ–‚â–ƒâ–ƒâ–…â–ƒâ–ƒâ–…â–‚â–ƒâ–â–„â–ƒâ–…â–ƒâ–ƒâ–†â–„â–…â–†â–…â–…â–„â–ˆâ–‡â–ƒâ–…â–†â–…â–‡â–‡â–‡â–„â–†â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–„â–‡â–…â–„â–…â–ƒâ–…â–†â–…â–„â–‡â–†â–…â–‚â–†â–…â–ˆâ–„â–ƒâ–ˆâ–…â–†â–‡â–‡â–†â–„â–ˆâ–‡â–„â–†â–†â–†â–‡â–…â–†â–ƒâ–‡â–…â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–„â–‚â–‚â–…â–‚â–„â–„â–â–‚â–„â–„â–â–â–‚â–…â–‚â–â–â–â–â–â–„â–„â–â–â–‚â–â–ˆâ–â–‚â–„â–‚â–…â–â–â–â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–‚â–â–ƒâ–‚â–ƒâ–…â–†â–…â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–â–‚â–‚â–…â–â–‚â–â–â–â–‚â–ƒâ–‚â–â–â–…â–â–‚â–â–‚â–â–ˆâ–‚â–â–…â–â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–…â–â–â–ƒâ–â–ƒâ–ƒâ–â–ƒâ–…â–â–ƒâ–…â–â–ƒâ–ƒâ–ƒâ–ˆâ–â–ƒâ–…â–…â–â–â–ƒâ–ƒâ–â–â–ƒâ–ˆâ–ƒâ–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–‚â–‚â–‡â–‚â–…â–ƒâ–â–‚â–â–ˆâ–â–‚â–‚â–‡â–ˆâ–‚â–â–ƒâ–â–â–‚â–‚â–ƒâ–â–â–â–‚â–…â–â–â–â–â–â–‚â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.31133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.48745\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.99211\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 3.33233\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.5185\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 2.0405\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 3.375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.7795\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 3.375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.295\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.598\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.095\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 590.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 1196.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 190.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.295\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.52\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.078\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.095\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 590\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 1040\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 156\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 190\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s4a2_s5a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/3vrdsmzf\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_194734-3vrdsmzf/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 20:02:18,422][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s5a2_s1a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_200219-84hb8tow\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s5a2_s1a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/84hb8tow\u001b[0m\n",
      "[2023-08-08 20:02:24,877][root][INFO] - => Done in 6.456 s\n",
      "[2023-08-08 20:02:24,877][root][INFO] - \n",
      "[2023-08-08 20:02:24,877][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:02:24,881][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:02:24,881][root][INFO] - => Done in 3.784 ms\n",
      "[2023-08-08 20:02:24,881][root][INFO] - \n",
      "[2023-08-08 20:02:24,881][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:02:25,450][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:02:25,451][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:02:25,451][root][INFO] - => Done in 569.192 ms\n",
      "[2023-08-08 20:02:25,451][root][INFO] - \n",
      "[2023-08-08 20:02:25,451][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:02:25,451][root][INFO] - => Done in 109.911 us\n",
      "[2023-08-08 20:02:25,451][root][INFO] - \n",
      "[2023-08-08 20:02:25,451][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:02:25,451][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:02:26,209][root][INFO] - => Done in 757.936 ms\n",
      "[2023-08-08 20:02:26,209][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.921 MB of 0.933 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–…â–†â–†â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–‡â–ˆâ–…â–ˆâ–â–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–…â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–„â–ˆâ–ƒâ–ˆâ–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ƒâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–…â–ˆâ–ƒâ–ˆâ–ƒâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–ƒâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–ˆâ–‡â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–…â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–â–â–â–ˆâ–â–…â–â–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–†â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–ˆâ–‡â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–…â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–â–â–â–ˆâ–â–…â–â–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–†â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–ˆâ–‡â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–…â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–ˆâ–â–…â–â–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–†â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–ˆâ–‡â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–…â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–ˆâ–â–…â–â–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–†â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 3.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.99714\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.99791\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 4.89728\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 5.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 5.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s5a2_s1a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/84hb8tow\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_200219-84hb8tow/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 20:03:01,299][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s5a2_s2a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_200302-ah5saqxs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s5a2_s2a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/ah5saqxs\u001b[0m\n",
      "[2023-08-08 20:03:07,187][root][INFO] - => Done in 5.887 s\n",
      "[2023-08-08 20:03:07,187][root][INFO] - \n",
      "[2023-08-08 20:03:07,187][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:03:07,191][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:03:07,191][root][INFO] - => Done in 3.186 ms\n",
      "[2023-08-08 20:03:07,191][root][INFO] - \n",
      "[2023-08-08 20:03:07,191][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:03:07,742][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:03:07,742][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:03:07,742][root][INFO] - => Done in 551.682 ms\n",
      "[2023-08-08 20:03:07,743][root][INFO] - \n",
      "[2023-08-08 20:03:07,743][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:03:07,743][root][INFO] - => Done in 148.058 us\n",
      "[2023-08-08 20:03:07,743][root][INFO] - \n",
      "[2023-08-08 20:03:07,743][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:03:07,743][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:03:08,498][root][INFO] - => Done in 755.408 ms\n",
      "[2023-08-08 20:03:08,498][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.922 MB of 0.934 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–†â–†â–‡â–†â–‡â–‡â–‡â–†â–‡â–‡â–…â–ˆâ–‡â–ˆâ–†â–‡â–†â–‡â–†â–†â–…â–…â–…â–…â–…â–‡â–„â–…â–‡â–‡â–†â–…â–…â–…â–„â–‡â–†â–„â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–…â–†â–…â–ƒâ–†â–…â–†â–„â–…â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–„â–â–‚â–„â–„â–ƒâ–‚â–‚â–‚â–â–„â–ƒâ–â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ˆâ–‡â–‡â–†â–‡â–†â–‡â–…â–†â–†â–ƒâ–†â–…â–†â–„â–…â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–„â–â–‚â–„â–ƒâ–ƒâ–‚â–‚â–â–â–„â–ƒâ–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–‡â–…â–†â–†â–ƒâ–†â–…â–†â–„â–…â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–„â–â–‚â–„â–„â–ƒâ–‚â–‚â–‚â–â–„â–ƒâ–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–„â–ƒâ–„â–†â–ƒâ–„â–ƒâ–…â–„â–†â–…â–†â–†â–‡â–‡â–†â–‡â–‡â–…â–ˆâ–‡â–…â–…â–†â–‡â–‡â–‡â–ˆâ–…â–†â–ˆâ–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–†â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–â–â–â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–…â–â–â–â–â–†â–â–â–â–…â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–„â–ƒâ–„â–†â–ƒâ–„â–ƒâ–…â–„â–†â–…â–†â–†â–‡â–‡â–†â–‡â–‡â–…â–ˆâ–‡â–…â–…â–†â–‡â–‡â–‡â–ˆâ–…â–†â–ˆâ–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–†â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–â–â–â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–…â–â–â–â–â–†â–â–â–â–…â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–ƒâ–‚â–‚â–„â–‚â–…â–ˆâ–…â–‚â–‚â–ƒâ–„â–ƒâ–‚â–‚â–â–ƒâ–â–â–‚â–‚â–â–â–‚â–â–‚â–‚â–â–â–‚â–â–â–â–‚â–â–‚â–â–ƒâ–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–„â–ƒâ–„â–†â–ƒâ–„â–ƒâ–…â–„â–†â–…â–†â–†â–‡â–‡â–†â–‡â–‡â–…â–ˆâ–‡â–…â–…â–†â–‡â–‡â–‡â–ˆâ–…â–†â–ˆâ–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–†â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–…â–â–â–â–â–†â–â–â–â–…â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–ƒâ–‚â–‚â–„â–‚â–…â–ˆâ–…â–‚â–‚â–ƒâ–„â–ƒâ–‚â–‚â–â–ƒâ–â–â–‚â–‚â–â–â–‚â–â–‚â–‚â–â–â–‚â–â–â–â–‚â–â–‚â–â–ƒâ–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–„â–ƒâ–„â–†â–ƒâ–„â–ƒâ–…â–„â–†â–…â–†â–†â–‡â–‡â–†â–‡â–‡â–…â–ˆâ–‡â–…â–…â–†â–‡â–‡â–‡â–ˆâ–…â–†â–ˆâ–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–†â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–…â–â–â–â–â–†â–â–â–â–…â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.737\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.78778\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.91646\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 4.64089\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.6825\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.873\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 4.6555\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.77775\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 4.6555\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.009\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.9175\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0635\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 18.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 1835.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 127.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.009\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.9175\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0635\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 1835\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 127\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s5a2_s2a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/ah5saqxs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_200302-ah5saqxs/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 20:03:43,459][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s5a2_s3a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_200344-vkj8dcc6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s5a2_s3a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/vkj8dcc6\u001b[0m\n",
      "[2023-08-08 20:03:49,467][root][INFO] - => Done in 6.008 s\n",
      "[2023-08-08 20:03:49,467][root][INFO] - \n",
      "[2023-08-08 20:03:49,467][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:03:49,471][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:03:49,471][root][INFO] - => Done in 3.501 ms\n",
      "[2023-08-08 20:03:49,471][root][INFO] - \n",
      "[2023-08-08 20:03:49,471][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:03:50,027][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:03:50,027][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:03:50,027][root][INFO] - => Done in 555.794 ms\n",
      "[2023-08-08 20:03:50,027][root][INFO] - \n",
      "[2023-08-08 20:03:50,027][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:03:50,027][root][INFO] - => Done in 112.295 us\n",
      "[2023-08-08 20:03:50,027][root][INFO] - \n",
      "[2023-08-08 20:03:50,027][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:03:50,027][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:03:50,783][root][INFO] - => Done in 756.264 ms\n",
      "[2023-08-08 20:03:50,784][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 0.923 MB of 0.935 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–…â–†â–†â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–‡â–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–„â–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–…â–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–…â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–â–â–â–ˆâ–â–…â–â–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–†â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–…â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–â–â–â–ˆâ–â–…â–â–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–†â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–…â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–ˆâ–â–…â–â–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–†â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–…â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–ˆâ–â–…â–â–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–†â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.99879\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 4.89975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 4.997\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 4.997\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.989\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 1978.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.989\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 1978\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s5a2_s3a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/vkj8dcc6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_200344-vkj8dcc6/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 20:04:25,896][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s5a2_s4a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_200427-jyytpk5q\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s5a2_s4a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/jyytpk5q\u001b[0m\n",
      "[2023-08-08 20:04:31,673][root][INFO] - => Done in 5.777 s\n",
      "[2023-08-08 20:04:31,673][root][INFO] - \n",
      "[2023-08-08 20:04:31,673][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:04:31,676][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:04:31,676][root][INFO] - => Done in 2.963 ms\n",
      "[2023-08-08 20:04:31,676][root][INFO] - \n",
      "[2023-08-08 20:04:31,676][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:04:32,231][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:04:32,231][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:04:32,231][root][INFO] - => Done in 554.971 ms\n",
      "[2023-08-08 20:04:32,231][root][INFO] - \n",
      "[2023-08-08 20:04:32,231][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:04:32,231][root][INFO] - => Done in 134.230 us\n",
      "[2023-08-08 20:04:32,231][root][INFO] - \n",
      "[2023-08-08 20:04:32,231][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:04:32,231][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:04:32,981][root][INFO] - => Done in 749.883 ms\n",
      "[2023-08-08 20:04:32,982][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 0.930 MB of 0.936 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–…â–†â–†â–†â–‡â–…â–‡â–„â–†â–‡â–†â–ˆâ–†â–ˆâ–†â–†â–„â–ˆâ–†â–ˆâ–ƒâ–…â–†â–†â–‡â–ˆâ–„â–†â–‡â–ˆâ–‡â–†â–†â–‚â–…â–ˆâ–‡â–„â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–„â–…â–†â–„â–†â–…â–†â–„â–„â–ƒâ–…â–„â–…â–‚â–ƒâ–„â–„â–„â–…â–‚â–„â–…â–…â–„â–„â–„â–â–ƒâ–…â–…â–‚â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‡â–‡â–‡â–†â–‡â–…â–‡â–„â–†â–†â–…â–†â–…â–†â–…â–„â–ƒâ–…â–„â–…â–‚â–„â–„â–„â–…â–…â–ƒâ–„â–„â–…â–…â–„â–„â–â–ƒâ–…â–…â–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–ˆâ–†â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–‡â–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–„â–…â–†â–„â–†â–…â–†â–„â–„â–ƒâ–…â–„â–…â–‚â–ƒâ–„â–„â–„â–…â–‚â–„â–„â–…â–…â–„â–„â–â–ƒâ–…â–…â–‚â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–ˆâ–†â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–‡â–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–…â–„â–ƒâ–…â–ƒâ–…â–ƒâ–…â–…â–†â–„â–…â–„â–ˆâ–†â–…â–…â–…â–„â–‡â–…â–„â–ƒâ–…â–†â–…â–ˆâ–†â–„â–„â–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–ˆâ–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–â–â–â–ˆâ–â–…â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‡â–‡â–â–â–â–‡â–â–â–â–â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–…â–„â–ƒâ–…â–ƒâ–…â–ƒâ–…â–…â–†â–„â–…â–„â–ˆâ–†â–…â–…â–…â–„â–‡â–…â–„â–ƒâ–…â–†â–…â–ˆâ–†â–„â–„â–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–ˆâ–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–â–â–â–ˆâ–â–…â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‡â–‡â–â–â–â–‡â–â–â–â–â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–„â–‡â–…â–…â–…â–ƒâ–…â–…â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–ƒâ–â–â–â–â–â–‚â–â–â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–…â–„â–ƒâ–…â–ƒâ–…â–ƒâ–…â–…â–†â–„â–…â–„â–ˆâ–†â–…â–…â–…â–„â–‡â–…â–„â–ƒâ–…â–†â–…â–ˆâ–†â–„â–„â–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–ˆâ–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–ˆâ–â–…â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‡â–‡â–â–â–â–‡â–â–â–â–â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–„â–‡â–…â–…â–…â–ƒâ–…â–…â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–ƒâ–â–â–â–â–â–‚â–â–â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–…â–„â–ƒâ–…â–ƒâ–…â–ƒâ–…â–…â–†â–„â–…â–„â–ˆâ–†â–…â–…â–…â–„â–‡â–…â–„â–ƒâ–…â–†â–…â–ˆâ–†â–„â–„â–‡â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–ˆâ–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–ˆâ–â–…â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‡â–‡â–â–â–â–‡â–â–â–â–â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.758\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.76423\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.90749\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 4.62737\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.7025\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.881\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 4.6905\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.79175\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 4.6905\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.9265\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0595\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 8.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 1853.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 119.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.9265\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0595\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 1853\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s5a2_s4a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/jyytpk5q\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_200427-jyytpk5q/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 20:05:08,238][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s5a2_s5a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_200509-73duypxp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s5a2_s5a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/73duypxp\u001b[0m\n",
      "[2023-08-08 20:05:14,183][root][INFO] - => Done in 5.945 s\n",
      "[2023-08-08 20:05:14,183][root][INFO] - \n",
      "[2023-08-08 20:05:14,183][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:05:14,186][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:05:14,187][root][INFO] - => Done in 3.258 ms\n",
      "[2023-08-08 20:05:14,187][root][INFO] - \n",
      "[2023-08-08 20:05:14,187][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:05:14,744][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:05:14,744][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:05:14,744][root][INFO] - => Done in 557.538 ms\n",
      "[2023-08-08 20:05:14,744][root][INFO] - \n",
      "[2023-08-08 20:05:14,744][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:05:14,745][root][INFO] - => Done in 113.964 us\n",
      "[2023-08-08 20:05:14,745][root][INFO] - \n",
      "[2023-08-08 20:05:14,745][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:05:14,745][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:05:15,529][root][INFO] - => Done in 784.171 ms\n",
      "[2023-08-08 20:05:15,529][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ConnectionError), entering retry loop.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–†â–‚â–†â–…â–ƒâ–‡â–„â–ƒâ–ƒâ–†â–ƒâ–ƒâ–…â–‡â–ƒâ–„â–â–‡â–‡â–‚â–…â–„â–ƒâ–„â–…â–‡â–„â–„â–†â–…â–…â–„â–…â–…â–†â–ˆâ–…â–†â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–…â–‚â–…â–…â–„â–†â–„â–„â–„â–…â–ƒâ–ƒâ–…â–‡â–ƒâ–…â–â–…â–†â–â–„â–ƒâ–‚â–ƒâ–„â–…â–‚â–‚â–…â–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–†â–ƒâ–„â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ˆâ–‚â–†â–‚â–â–…â–ƒâ–…â–â–„â–„â–â–„â–…â–„â–‚â–â–…â–‡â–‚â–„â–„â–„â–„â–…â–†â–ˆâ–…â–…â–„â–†â–„â–‡â–†â–ˆâ–†â–…â–‡â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–„â–„â–‚â–†â–„â–ƒâ–†â–ƒâ–â–ƒâ–…â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–‡â–‡â–‚â–„â–„â–ƒâ–„â–…â–‡â–„â–…â–…â–†â–„â–…â–…â–…â–…â–ˆâ–…â–…â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–†â–‚â–…â–„â–ƒâ–†â–„â–„â–ƒâ–…â–ƒâ–ƒâ–…â–‡â–ƒâ–„â–â–…â–†â–â–„â–ƒâ–ƒâ–ƒâ–„â–…â–ƒâ–ƒâ–…â–„â–„â–ƒâ–„â–„â–…â–†â–„â–…â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–„â–„â–‚â–†â–„â–ƒâ–†â–ƒâ–â–ƒâ–…â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–‡â–‡â–‚â–„â–„â–ƒâ–„â–…â–‡â–„â–…â–…â–†â–„â–…â–…â–…â–…â–ˆâ–…â–…â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–ˆâ–…â–„â–…â–…â–…â–…â–…â–…â–…â–†â–„â–…â–†â–ˆâ–„â–†â–‚â–„â–…â–‚â–…â–ƒâ–ƒâ–ƒâ–ƒâ–„â–‚â–‚â–„â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–‚â–„â–ƒâ–…â–ƒâ–‚â–„â–ƒâ–‚â–‚â–ƒâ–„â–ƒâ–ƒâ–â–„â–‚â–…â–†â–…â–…â–„â–…â–…â–…â–†â–†â–‡â–‡â–…â–‡â–…â–†â–‡â–‡â–‡â–‡â–†â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–„â–‡â–„â–„â–…â–ƒâ–…â–†â–…â–ƒâ–†â–…â–„â–‚â–†â–„â–ˆâ–„â–ƒâ–‡â–…â–‡â–‡â–‡â–†â–„â–‡â–‡â–…â–†â–†â–‡â–‡â–†â–†â–ƒâ–†â–†â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–‚â–â–‚â–‚â–…â–ƒâ–„â–ƒâ–„â–ƒâ–‚â–â–ƒâ–„â–â–„â–‚â–„â–‚â–ƒâ–ƒâ–ƒâ–…â–‚â–…â–ƒâ–‚â–‚â–ƒâ–ƒâ–‡â–…â–ƒâ–‚â–ˆâ–…â–ƒâ–â–‚â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ƒâ–‚â–…â–ƒâ–ˆâ–…â–…â–ƒâ–„â–†â–ƒâ–…â–…â–„â–ƒâ–‚â–…â–†â–‚â–‚â–‡â–ƒâ–„â–ƒâ–…â–„â–â–‚â–…â–„â–…â–‚â–â–‚â–‡â–ƒâ–…â–ƒâ–‚â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–‚â–â–‚â–‚â–‚â–…â–ƒâ–ƒâ–„â–ƒâ–ƒâ–â–†â–ƒâ–‚â–‚â–‡â–ˆâ–‚â–â–…â–â–„â–ƒâ–‚â–ƒâ–â–â–‚â–ƒâ–ƒâ–â–â–ƒâ–‚â–â–‚â–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–ˆâ–…â–„â–…â–…â–…â–…â–…â–…â–…â–†â–„â–…â–†â–ˆâ–„â–†â–‚â–„â–…â–‚â–…â–ƒâ–ƒâ–ƒâ–ƒâ–„â–‚â–‚â–„â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–‚â–„â–ƒâ–…â–ƒâ–‚â–„â–ƒâ–‚â–‚â–ƒâ–„â–ƒâ–ƒâ–â–„â–‚â–…â–†â–…â–…â–„â–…â–…â–…â–†â–†â–‡â–‡â–…â–‡â–…â–†â–‡â–‡â–‡â–‡â–†â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–„â–‡â–„â–„â–…â–ƒâ–…â–†â–…â–ƒâ–†â–…â–„â–‚â–†â–„â–ˆâ–„â–ƒâ–‡â–…â–‡â–‡â–‡â–†â–„â–‡â–‡â–…â–†â–†â–‡â–‡â–†â–†â–ƒâ–†â–†â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–‚â–â–‚â–‚â–…â–ƒâ–„â–ƒâ–„â–ƒâ–‚â–â–ƒâ–„â–â–„â–‚â–„â–‚â–ƒâ–ƒâ–ƒâ–…â–‚â–…â–ƒâ–‚â–‚â–ƒâ–ƒâ–‡â–…â–ƒâ–‚â–ˆâ–…â–ƒâ–â–‚â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ƒâ–‚â–…â–ƒâ–ˆâ–…â–…â–ƒâ–„â–†â–ƒâ–…â–…â–„â–ƒâ–‚â–…â–†â–‚â–‚â–‡â–ƒâ–„â–ƒâ–…â–„â–â–‚â–…â–„â–…â–‚â–â–‚â–‡â–ƒâ–…â–ƒâ–‚â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–‚â–â–‚â–‚â–‚â–…â–ƒâ–ƒâ–„â–ƒâ–ƒâ–â–†â–ƒâ–‚â–‚â–‡â–ˆâ–‚â–â–…â–â–„â–ƒâ–‚â–ƒâ–â–â–‚â–ƒâ–ƒâ–â–â–ƒâ–‚â–â–‚â–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–ˆâ–…â–„â–…â–…â–…â–…â–…â–…â–…â–†â–„â–…â–†â–ˆâ–„â–†â–‚â–„â–…â–‚â–…â–ƒâ–ƒâ–ƒâ–ƒâ–„â–‚â–‚â–„â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–‚â–ƒâ–ƒâ–…â–„â–ƒâ–…â–ƒâ–â–ƒâ–„â–ƒâ–„â–ƒâ–‚â–„â–ƒâ–„â–‡â–†â–„â–„â–…â–„â–…â–…â–‡â–…â–†â–†â–ˆâ–…â–†â–†â–†â–†â–ˆâ–†â–†â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–‚â–…â–„â–„â–‚â–‚â–ƒâ–ƒâ–…â–‚â–ƒâ–…â–‚â–ƒâ–â–„â–‚â–…â–ƒâ–ƒâ–…â–ƒâ–…â–…â–…â–…â–„â–ˆâ–†â–„â–…â–…â–„â–‡â–‡â–‡â–„â–…â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–„â–‡â–„â–„â–…â–ƒâ–…â–†â–…â–ƒâ–†â–…â–„â–‚â–†â–„â–ˆâ–„â–ƒâ–‡â–…â–‡â–‡â–‡â–†â–„â–‡â–‡â–…â–†â–†â–‡â–‡â–†â–†â–ƒâ–†â–†â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–‚â–â–‚â–‚â–…â–ƒâ–„â–ƒâ–„â–ƒâ–‚â–â–ƒâ–„â–â–„â–‚â–„â–‚â–ƒâ–ƒâ–ƒâ–…â–‚â–…â–ƒâ–‚â–‚â–ƒâ–ƒâ–‡â–…â–ƒâ–‚â–ˆâ–…â–ƒâ–â–‚â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–‚â–‚â–„â–ƒâ–ˆâ–…â–…â–ƒâ–ƒâ–„â–ƒâ–„â–„â–ƒâ–ƒâ–‚â–ƒâ–…â–‚â–â–…â–‚â–„â–‚â–…â–ƒâ–â–ƒâ–…â–ƒâ–„â–‚â–â–‚â–‡â–„â–ƒâ–ƒâ–‚â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–…â–â–ƒâ–‚â–ƒâ–„â–„â–‚â–„â–†â–‚â–ƒâ–…â–ƒâ–‚â–‚â–†â–†â–â–ƒâ–ˆâ–„â–‚â–„â–‚â–„â–â–â–ƒâ–„â–„â–ƒâ–â–â–‚â–â–…â–‚â–â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–‚â–â–‚â–‚â–‚â–…â–ƒâ–ƒâ–„â–ƒâ–ƒâ–â–†â–ƒâ–‚â–‚â–‡â–ˆâ–‚â–â–…â–â–„â–ƒâ–‚â–ƒâ–â–â–‚â–ƒâ–ƒâ–â–â–ƒâ–‚â–â–‚â–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–ˆâ–…â–„â–…â–…â–…â–…â–…â–…â–…â–†â–„â–…â–†â–ˆâ–„â–†â–‚â–„â–…â–‚â–…â–ƒâ–ƒâ–ƒâ–ƒâ–„â–‚â–‚â–„â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–‚â–ƒâ–ƒâ–…â–„â–ƒâ–…â–ƒâ–â–ƒâ–„â–ƒâ–„â–ƒâ–‚â–„â–ƒâ–„â–‡â–†â–„â–„â–…â–„â–…â–…â–‡â–…â–†â–†â–ˆâ–…â–†â–†â–†â–†â–ˆâ–†â–†â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–‚â–…â–„â–„â–‚â–‚â–ƒâ–ƒâ–…â–‚â–ƒâ–…â–‚â–ƒâ–â–„â–‚â–…â–ƒâ–ƒâ–…â–ƒâ–…â–…â–…â–…â–„â–ˆâ–†â–„â–…â–…â–„â–‡â–‡â–‡â–„â–…â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–„â–‡â–„â–„â–…â–ƒâ–…â–†â–…â–ƒâ–†â–…â–„â–‚â–†â–„â–ˆâ–„â–ƒâ–‡â–…â–‡â–‡â–‡â–†â–„â–‡â–‡â–…â–†â–†â–‡â–‡â–†â–†â–ƒâ–†â–†â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–‚â–â–‚â–‚â–…â–ƒâ–„â–ƒâ–„â–ƒâ–‚â–â–ƒâ–„â–â–„â–‚â–„â–‚â–ƒâ–ƒâ–ƒâ–…â–‚â–…â–ƒâ–‚â–‚â–ƒâ–ƒâ–‡â–…â–ƒâ–‚â–ˆâ–…â–ƒâ–â–‚â–„\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–‚â–‚â–„â–ƒâ–ˆâ–…â–…â–ƒâ–ƒâ–„â–ƒâ–„â–„â–ƒâ–ƒâ–‚â–ƒâ–…â–‚â–â–…â–‚â–„â–‚â–…â–ƒâ–â–ƒâ–…â–ƒâ–„â–‚â–â–‚â–‡â–„â–ƒâ–ƒâ–‚â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–…â–â–ƒâ–‚â–ƒâ–„â–„â–‚â–„â–†â–‚â–ƒâ–…â–ƒâ–‚â–‚â–†â–†â–â–ƒâ–ˆâ–„â–‚â–„â–‚â–„â–â–â–ƒâ–„â–„â–ƒâ–â–â–‚â–â–…â–‚â–â–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–‚â–â–‚â–‚â–‚â–…â–ƒâ–ƒâ–„â–ƒâ–ƒâ–â–†â–ƒâ–‚â–‚â–‡â–ˆâ–‚â–â–…â–â–„â–ƒâ–‚â–ƒâ–â–â–‚â–ƒâ–ƒâ–â–â–ƒâ–‚â–â–‚â–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.28017\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.50541\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.97855\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 3.31926\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.509\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 3.3365\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.752\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 3.3365\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.2995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.586\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.094\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0085\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 599.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 1172.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 188.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 17.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.2995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.514\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.072\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.094\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 599\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 1028\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 144\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 188\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s5a2_s5a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/73duypxp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_200509-73duypxp/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 20:07:15,964][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s1a2_s1a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_200717-2ltv0iid\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s1a2_s1a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/2ltv0iid\u001b[0m\n",
      "[2023-08-08 20:07:22,409][root][INFO] - => Done in 6.445 s\n",
      "[2023-08-08 20:07:22,409][root][INFO] - \n",
      "[2023-08-08 20:07:22,409][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:07:22,413][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:07:22,413][root][INFO] - => Done in 4.117 ms\n",
      "[2023-08-08 20:07:22,413][root][INFO] - \n",
      "[2023-08-08 20:07:22,414][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:07:22,964][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:07:22,964][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:07:22,964][root][INFO] - => Done in 550.318 ms\n",
      "[2023-08-08 20:07:22,964][root][INFO] - \n",
      "[2023-08-08 20:07:22,964][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:07:22,964][root][INFO] - => Done in 111.818 us\n",
      "[2023-08-08 20:07:22,964][root][INFO] - \n",
      "[2023-08-08 20:07:22,964][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:07:22,964][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:07:23,720][root][INFO] - => Done in 755.534 ms\n",
      "[2023-08-08 20:07:23,720][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.929 MB of 0.939 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–‚â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–‚â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–„â–„â–ƒâ–‚â–‚â–â–„â–‚â–„â–‚â–„â–‡â–‚â–…â–„â–„â–‚â–„â–‚â–‚â–„â–…â–ˆâ–„â–‡â–„â–…â–‡â–…â–„â–‚â–…â–…â–„â–…â–„â–‚â–‡â–‡â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–‚â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–„â–„â–ƒâ–‚â–‚â–â–„â–‚â–„â–‚â–„â–‡â–‚â–…â–„â–„â–‚â–„â–‚â–‚â–„â–…â–ˆâ–„â–‡â–„â–…â–‡â–…â–„â–‚â–…â–…â–„â–…â–„â–‚â–‡â–‡â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–‚â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.95633\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 4.88074\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.91734\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 1.91653\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 4.945\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.949\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.46\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.949\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.9795\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0105\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 1959.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 21.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.9795\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 1959\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s1a2_s1a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/2ltv0iid\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_200717-2ltv0iid/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 20:07:58,638][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s1a2_s2a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_200800-xkazm4qp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s1a2_s2a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/xkazm4qp\u001b[0m\n",
      "[2023-08-08 20:08:04,480][root][INFO] - => Done in 5.842 s\n",
      "[2023-08-08 20:08:04,481][root][INFO] - \n",
      "[2023-08-08 20:08:04,481][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:08:04,484][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:08:04,484][root][INFO] - => Done in 3.238 ms\n",
      "[2023-08-08 20:08:04,484][root][INFO] - \n",
      "[2023-08-08 20:08:04,484][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:08:05,060][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:08:05,060][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:08:05,060][root][INFO] - => Done in 575.790 ms\n",
      "[2023-08-08 20:08:05,060][root][INFO] - \n",
      "[2023-08-08 20:08:05,060][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:08:05,060][root][INFO] - => Done in 109.911 us\n",
      "[2023-08-08 20:08:05,060][root][INFO] - \n",
      "[2023-08-08 20:08:05,060][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:08:05,060][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:08:05,813][root][INFO] - => Done in 752.352 ms\n",
      "[2023-08-08 20:08:05,813][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.928 MB of 0.936 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.99833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 4.94426\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.94451\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 1.9778\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 4.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.4975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s1a2_s2a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/xkazm4qp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_200800-xkazm4qp/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 20:08:40,737][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s1a2_s3a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_200842-v1yjznes\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s1a2_s3a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/v1yjznes\u001b[0m\n",
      "[2023-08-08 20:08:46,553][root][INFO] - => Done in 5.816 s\n",
      "[2023-08-08 20:08:46,553][root][INFO] - \n",
      "[2023-08-08 20:08:46,553][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:08:46,556][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:08:46,556][root][INFO] - => Done in 3.172 ms\n",
      "[2023-08-08 20:08:46,556][root][INFO] - \n",
      "[2023-08-08 20:08:46,556][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:08:47,140][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:08:47,141][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:08:47,141][root][INFO] - => Done in 584.270 ms\n",
      "[2023-08-08 20:08:47,141][root][INFO] - \n",
      "[2023-08-08 20:08:47,141][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:08:47,141][root][INFO] - => Done in 116.825 us\n",
      "[2023-08-08 20:08:47,141][root][INFO] - \n",
      "[2023-08-08 20:08:47,141][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:08:47,141][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:08:47,898][root][INFO] - => Done in 756.499 ms\n",
      "[2023-08-08 20:08:47,898][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.929 MB of 0.932 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ƒâ–â–â–â–‚â–â–â–â–â–â–ˆâ–ˆâ–â–ˆâ–â–â–â–â–ˆâ–â–ˆâ–ˆâ–â–ˆâ–â–ˆâ–ˆâ–â–ˆâ–â–â–ˆâ–â–â–ˆâ–â–â–ˆâ–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ƒâ–â–â–â–‚â–â–â–â–â–â–ˆâ–ˆâ–â–ˆâ–â–â–â–â–ˆâ–â–ˆâ–ˆâ–â–ˆâ–â–ˆâ–ˆâ–â–ˆâ–â–â–ˆâ–â–â–ˆâ–â–â–ˆâ–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.99633\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 4.93568\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.94087\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 1.96953\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 4.995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.495\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 1979.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 1979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s1a2_s3a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/v1yjznes\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_200842-v1yjznes/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 20:09:22,918][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s1a2_s4a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_200924-viobektg\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s1a2_s4a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/viobektg\u001b[0m\n",
      "[2023-08-08 20:09:28,666][root][INFO] - => Done in 5.749 s\n",
      "[2023-08-08 20:09:28,667][root][INFO] - \n",
      "[2023-08-08 20:09:28,667][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:09:28,670][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:09:28,670][root][INFO] - => Done in 3.029 ms\n",
      "[2023-08-08 20:09:28,670][root][INFO] - \n",
      "[2023-08-08 20:09:28,670][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:09:29,251][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:09:29,251][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:09:29,251][root][INFO] - => Done in 581.590 ms\n",
      "[2023-08-08 20:09:29,251][root][INFO] - \n",
      "[2023-08-08 20:09:29,252][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:09:29,252][root][INFO] - => Done in 108.004 us\n",
      "[2023-08-08 20:09:29,252][root][INFO] - \n",
      "[2023-08-08 20:09:29,252][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:09:29,252][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:09:30,002][root][INFO] - => Done in 750.534 ms\n",
      "[2023-08-08 20:09:30,002][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: | 0.930 MB of 0.930 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.99833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 4.94416\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.94491\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 1.97738\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 4.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.4975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s1a2_s4a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/viobektg\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_200924-viobektg/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 20:10:08,482][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s1a2_s5a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_201010-7j9uu9oz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s1a2_s5a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/7j9uu9oz\u001b[0m\n",
      "[2023-08-08 20:10:14,269][root][INFO] - => Done in 5.787 s\n",
      "[2023-08-08 20:10:14,269][root][INFO] - \n",
      "[2023-08-08 20:10:14,269][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:10:14,273][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:10:14,273][root][INFO] - => Done in 3.670 ms\n",
      "[2023-08-08 20:10:14,273][root][INFO] - \n",
      "[2023-08-08 20:10:14,273][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:10:14,851][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:10:14,851][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:10:14,851][root][INFO] - => Done in 578.319 ms\n",
      "[2023-08-08 20:10:14,851][root][INFO] - \n",
      "[2023-08-08 20:10:14,851][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:10:14,851][root][INFO] - => Done in 109.911 us\n",
      "[2023-08-08 20:10:14,851][root][INFO] - \n",
      "[2023-08-08 20:10:14,851][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:10:14,852][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:10:15,604][root][INFO] - => Done in 752.038 ms\n",
      "[2023-08-08 20:10:15,604][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.931 MB of 0.943 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–â–â–â–â–â–ï¿½ï¿½ï¿½â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.99833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 4.94237\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.94449\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 1.9756\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 4.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.4975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s1a2_s5a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/7j9uu9oz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_201010-7j9uu9oz/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 20:10:49,683][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s2a1_s1a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_201051-u2lh1osx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s2a1_s1a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/u2lh1osx\u001b[0m\n",
      "[2023-08-08 20:10:55,673][root][INFO] - => Done in 5.990 s\n",
      "[2023-08-08 20:10:55,673][root][INFO] - \n",
      "[2023-08-08 20:10:55,673][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:10:55,676][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:10:55,676][root][INFO] - => Done in 2.969 ms\n",
      "[2023-08-08 20:10:55,676][root][INFO] - \n",
      "[2023-08-08 20:10:55,676][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:10:56,256][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:10:56,257][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:10:56,257][root][INFO] - => Done in 580.714 ms\n",
      "[2023-08-08 20:10:56,257][root][INFO] - \n",
      "[2023-08-08 20:10:56,257][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:10:56,257][root][INFO] - => Done in 113.964 us\n",
      "[2023-08-08 20:10:56,257][root][INFO] - \n",
      "[2023-08-08 20:10:56,257][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:10:56,257][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:10:57,016][root][INFO] - => Done in 758.918 ms\n",
      "[2023-08-08 20:10:57,016][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: | 0.944 MB of 0.944 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–‚â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–‚â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–„â–„â–ƒâ–‚â–‚â–â–„â–‚â–„â–‚â–„â–‡â–‚â–…â–„â–„â–‚â–„â–‚â–‚â–„â–…â–ˆâ–„â–‡â–„â–…â–‡â–…â–„â–‚â–…â–…â–„â–…â–„â–‚â–‡â–‡â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–‚â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–„â–„â–ƒâ–‚â–‚â–â–„â–‚â–„â–‚â–„â–‡â–‚â–…â–„â–„â–‚â–„â–‚â–‚â–„â–…â–ˆâ–„â–‡â–„â–…â–‡â–…â–„â–‚â–…â–…â–„â–…â–„â–‚â–‡â–‡â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–‚â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.95833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 4.881\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.91739\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 1.91649\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 4.9475\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.9775\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.4625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.98\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 1960.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.98\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 1960\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s2a1_s1a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/u2lh1osx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_201051-u2lh1osx/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 20:11:34,636][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s2a1_s2a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_201135-thw1pmb8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s2a1_s2a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/thw1pmb8\u001b[0m\n",
      "[2023-08-08 20:11:43,584][root][INFO] - => Done in 8.949 s\n",
      "[2023-08-08 20:11:43,584][root][INFO] - \n",
      "[2023-08-08 20:11:43,585][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:11:43,588][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:11:43,588][root][INFO] - => Done in 3.304 ms\n",
      "[2023-08-08 20:11:43,588][root][INFO] - \n",
      "[2023-08-08 20:11:43,588][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:11:44,156][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:11:44,156][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:11:44,157][root][INFO] - => Done in 568.576 ms\n",
      "[2023-08-08 20:11:44,157][root][INFO] - \n",
      "[2023-08-08 20:11:44,157][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:11:44,157][root][INFO] - => Done in 116.110 us\n",
      "[2023-08-08 20:11:44,157][root][INFO] - \n",
      "[2023-08-08 20:11:44,157][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:11:44,157][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:11:44,904][root][INFO] - => Done in 747.628 ms\n",
      "[2023-08-08 20:11:44,905][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.99833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 4.94448\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.94449\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 1.97778\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 4.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.4975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s2a1_s2a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/thw1pmb8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_201135-thw1pmb8/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 20:13:14,930][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s2a1_s3a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_201316-ugk04zzc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s2a1_s3a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/ugk04zzc\u001b[0m\n",
      "[2023-08-08 20:13:22,241][root][INFO] - => Done in 7.312 s\n",
      "[2023-08-08 20:13:22,242][root][INFO] - \n",
      "[2023-08-08 20:13:22,242][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:13:22,245][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:13:22,245][root][INFO] - => Done in 3.423 ms\n",
      "[2023-08-08 20:13:22,245][root][INFO] - \n",
      "[2023-08-08 20:13:22,245][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:13:22,814][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:13:22,814][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:13:22,814][root][INFO] - => Done in 568.738 ms\n",
      "[2023-08-08 20:13:22,814][root][INFO] - \n",
      "[2023-08-08 20:13:22,814][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:13:22,814][root][INFO] - => Done in 160.933 us\n",
      "[2023-08-08 20:13:22,814][root][INFO] - \n",
      "[2023-08-08 20:13:22,814][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:13:22,815][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:13:23,589][root][INFO] - => Done in 774.873 ms\n",
      "[2023-08-08 20:13:23,590][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 0.934 MB of 0.934 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ƒâ–â–â–â–‚â–â–â–â–â–â–ˆâ–ˆâ–â–ˆâ–â–â–â–â–ˆâ–â–ˆâ–ˆâ–â–ˆâ–â–ˆâ–ˆâ–â–ˆâ–‚â–â–ˆâ–â–â–ˆâ–â–â–ˆâ–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ƒâ–â–â–â–‚â–â–â–â–â–â–ˆâ–ˆâ–â–ˆâ–â–â–â–â–ˆâ–â–ˆâ–ˆâ–â–ˆâ–â–ˆâ–ˆâ–â–ˆâ–‚â–â–ˆâ–â–â–ˆâ–â–â–ˆâ–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.99833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 4.93603\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.941\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 1.96955\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 4.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.4975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s2a1_s3a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/ugk04zzc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_201316-ugk04zzc/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 20:14:00,212][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s2a1_s4a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_201401-h9ov544n\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s2a1_s4a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/h9ov544n\u001b[0m\n",
      "[2023-08-08 20:14:06,404][root][INFO] - => Done in 6.192 s\n",
      "[2023-08-08 20:14:06,405][root][INFO] - \n",
      "[2023-08-08 20:14:06,405][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:14:06,408][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:14:06,408][root][INFO] - => Done in 3.088 ms\n",
      "[2023-08-08 20:14:06,408][root][INFO] - \n",
      "[2023-08-08 20:14:06,408][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:14:06,975][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:14:06,975][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:14:06,975][root][INFO] - => Done in 566.958 ms\n",
      "[2023-08-08 20:14:06,975][root][INFO] - \n",
      "[2023-08-08 20:14:06,975][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:14:06,975][root][INFO] - => Done in 114.918 us\n",
      "[2023-08-08 20:14:06,975][root][INFO] - \n",
      "[2023-08-08 20:14:06,975][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:14:06,975][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:14:07,730][root][INFO] - => Done in 754.500 ms\n",
      "[2023-08-08 20:14:07,730][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.935 MB of 0.943 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.99833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 4.94416\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.94468\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 1.97728\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 4.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.4975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s2a1_s4a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/h9ov544n\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_201401-h9ov544n/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 20:14:42,641][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s2a1_s5a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_201444-yco0a73a\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s2a1_s5a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/yco0a73a\u001b[0m\n",
      "[2023-08-08 20:14:48,535][root][INFO] - => Done in 5.894 s\n",
      "[2023-08-08 20:14:48,535][root][INFO] - \n",
      "[2023-08-08 20:14:48,535][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:14:48,539][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:14:48,539][root][INFO] - => Done in 3.159 ms\n",
      "[2023-08-08 20:14:48,539][root][INFO] - \n",
      "[2023-08-08 20:14:48,539][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:14:49,110][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:14:49,110][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:14:49,110][root][INFO] - => Done in 571.396 ms\n",
      "[2023-08-08 20:14:49,110][root][INFO] - \n",
      "[2023-08-08 20:14:49,110][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:14:49,110][root][INFO] - => Done in 142.097 us\n",
      "[2023-08-08 20:14:49,110][root][INFO] - \n",
      "[2023-08-08 20:14:49,110][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:14:49,111][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:14:49,869][root][INFO] - => Done in 758.268 ms\n",
      "[2023-08-08 20:14:49,869][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.936 MB of 0.948 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.99833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 4.94274\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.94463\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 1.97564\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 4.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.4975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s2a1_s5a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/yco0a73a\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_201444-yco0a73a/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 20:15:24,847][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s3a2_s1a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_201526-1pfhlsh6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s3a2_s1a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/1pfhlsh6\u001b[0m\n",
      "[2023-08-08 20:15:30,839][root][INFO] - => Done in 5.991 s\n",
      "[2023-08-08 20:15:30,839][root][INFO] - \n",
      "[2023-08-08 20:15:30,839][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:15:30,842][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:15:30,842][root][INFO] - => Done in 2.964 ms\n",
      "[2023-08-08 20:15:30,842][root][INFO] - \n",
      "[2023-08-08 20:15:30,842][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:15:31,416][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:15:31,417][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:15:31,417][root][INFO] - => Done in 574.775 ms\n",
      "[2023-08-08 20:15:31,417][root][INFO] - \n",
      "[2023-08-08 20:15:31,417][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:15:31,417][root][INFO] - => Done in 123.024 us\n",
      "[2023-08-08 20:15:31,417][root][INFO] - \n",
      "[2023-08-08 20:15:31,417][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:15:31,417][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:15:32,173][root][INFO] - => Done in 756.404 ms\n",
      "[2023-08-08 20:15:32,174][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 0.949 MB of 0.949 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–‚â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–‚â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–„â–„â–ƒâ–‚â–‚â–â–„â–‚â–„â–‚â–„â–‡â–‚â–…â–„â–„â–‚â–„â–‚â–‚â–„â–…â–ˆâ–„â–‡â–„â–…â–‡â–…â–„â–‚â–…â–…â–„â–…â–„â–‚â–‡â–‡â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–‚â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–„â–„â–ƒâ–‚â–‚â–â–„â–‚â–„â–‚â–„â–‡â–‚â–…â–„â–„â–‚â–„â–‚â–‚â–„â–…â–ˆâ–„â–‡â–„â–…â–‡â–…â–„â–‚â–…â–…â–„â–…â–„â–‚â–‡â–‡â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–‚â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 4.88102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.91745\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 1.91651\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 4.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.98\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.465\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.95\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.98\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 1960.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.98\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 1960\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s3a2_s1a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/1pfhlsh6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_201526-1pfhlsh6/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 20:16:07,400][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s3a2_s2a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_201608-ohf178yd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s3a2_s2a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/ohf178yd\u001b[0m\n",
      "[2023-08-08 20:16:13,142][root][INFO] - => Done in 5.742 s\n",
      "[2023-08-08 20:16:13,143][root][INFO] - \n",
      "[2023-08-08 20:16:13,143][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:16:13,146][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:16:13,146][root][INFO] - => Done in 3.048 ms\n",
      "[2023-08-08 20:16:13,146][root][INFO] - \n",
      "[2023-08-08 20:16:13,146][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:16:13,720][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:16:13,721][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:16:13,721][root][INFO] - => Done in 574.737 ms\n",
      "[2023-08-08 20:16:13,721][root][INFO] - \n",
      "[2023-08-08 20:16:13,721][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:16:13,721][root][INFO] - => Done in 108.957 us\n",
      "[2023-08-08 20:16:13,721][root][INFO] - \n",
      "[2023-08-08 20:16:13,721][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:16:13,721][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:16:14,476][root][INFO] - => Done in 754.646 ms\n",
      "[2023-08-08 20:16:14,476][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 0.939 MB of 0.950 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.99833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 4.94445\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.94449\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 1.97778\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 4.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.4975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s3a2_s2a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/ohf178yd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_201608-ohf178yd/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 20:16:49,455][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s3a2_s3a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_201650-yx22p40d\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s3a2_s3a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/yx22p40d\u001b[0m\n",
      "[2023-08-08 20:16:55,763][root][INFO] - => Done in 6.308 s\n",
      "[2023-08-08 20:16:55,763][root][INFO] - \n",
      "[2023-08-08 20:16:55,764][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:16:55,768][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:16:55,768][root][INFO] - => Done in 4.161 ms\n",
      "[2023-08-08 20:16:55,768][root][INFO] - \n",
      "[2023-08-08 20:16:55,768][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:16:56,346][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:16:56,346][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:16:56,346][root][INFO] - => Done in 578.618 ms\n",
      "[2023-08-08 20:16:56,346][root][INFO] - \n",
      "[2023-08-08 20:16:56,347][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:16:56,347][root][INFO] - => Done in 110.149 us\n",
      "[2023-08-08 20:16:56,347][root][INFO] - \n",
      "[2023-08-08 20:16:56,347][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:16:56,347][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:16:57,096][root][INFO] - => Done in 749.602 ms\n",
      "[2023-08-08 20:16:57,097][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.\n",
      "Error executing job with overrides: ['+experiment=multi-shapers/comp/n3pl_2shap_tc_comp_eval', '++run_path1=ucl-dark/tensor-tc/8v8vokho', '++run_path2=ucl-dark/tensor-tc/8v8vokho', '++model_path1=exp/3pl-2shap-tc/3pl_2shap_tc_3/2023-08-02_14.38.10.878306/generation_299_agent_1', '++model_path2=exp/3pl-2shap-tc/3pl_2shap_tc_3/2023-08-02_14.38.10.878306/generation_299_agent_0', '++wandb.name=3pl_2shap_tc_s3a2_s3a1_eval', '++wandb.group=3pl_2shap_tc-comp-mean_v_nice']\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/ssl.py\", line 1242, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/ssl.py\", line 1100, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/requests/adapters.py\", line 489, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/urllib3/packages/six.py\", line 770, in reraise\n",
      "    raise value\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 451, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/urllib3/connectionpool.py\", line 340, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='api.wandb.ai', port=443): Read timed out. (read timeout=9)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/apis/normalize.py\", line 26, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/apis/public.py\", line 870, in run\n",
      "    entity, project, run_id = self._parse_path(path)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/apis/public.py\", line 631, in _parse_path\n",
      "    entity = self.settings[\"entity\"] or self.default_entity\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/apis/public.py\", line 533, in default_entity\n",
      "    res = self._client.execute(self.VIEWER_QUERY)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/sdk/lib/retry.py\", line 209, in wrapped_fn\n",
      "    return retrier(*args, **kargs)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/sdk/lib/retry.py\", line 128, in __call__\n",
      "    result = self._call_fn(*args, **kwargs)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/apis/public.py\", line 240, in execute\n",
      "    return self._client.execute(*args, **kwargs)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py\", line 52, in execute\n",
      "    result = self._get_result(document, *args, **kwargs)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py\", line 60, in _get_result\n",
      "    return self.transport.execute(document, *args, **kwargs)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/transport/requests.py\", line 38, in execute\n",
      "    request = requests.post(self.url, **post_args)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/requests/api.py\", line 115, in post\n",
      "    return request(\"post\", url, data=data, json=json, **kwargs)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/requests/api.py\", line 59, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/requests/sessions.py\", line 587, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/requests/sessions.py\", line 701, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/requests/adapters.py\", line 578, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='api.wandb.ai', port=443): Read timed out. (read timeout=9)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alexandrasouly/code/pax/pax/experiment.py\", line 823, in main\n",
      "    runner.run_loop(env_params, agent_pair, watchers)\n",
      "  File \"/Users/alexandrasouly/code/pax/pax/runners/runner_eval_multipshaper.py\", line 519, in run_loop\n",
      "    wandb.restore(\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3636, in restore\n",
      "    api_run = api.run(run_path)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/apis/normalize.py\", line 64, in wrapper\n",
      "    raise CommError(message, err).with_traceback(sys.exc_info()[2])\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/apis/normalize.py\", line 26, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/apis/public.py\", line 870, in run\n",
      "    entity, project, run_id = self._parse_path(path)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/apis/public.py\", line 631, in _parse_path\n",
      "    entity = self.settings[\"entity\"] or self.default_entity\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/apis/public.py\", line 533, in default_entity\n",
      "    res = self._client.execute(self.VIEWER_QUERY)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/sdk/lib/retry.py\", line 209, in wrapped_fn\n",
      "    return retrier(*args, **kargs)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/sdk/lib/retry.py\", line 128, in __call__\n",
      "    result = self._call_fn(*args, **kwargs)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/apis/public.py\", line 240, in execute\n",
      "    return self._client.execute(*args, **kwargs)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py\", line 52, in execute\n",
      "    result = self._get_result(document, *args, **kwargs)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py\", line 60, in _get_result\n",
      "    return self.transport.execute(document, *args, **kwargs)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/transport/requests.py\", line 38, in execute\n",
      "    request = requests.post(self.url, **post_args)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/requests/api.py\", line 115, in post\n",
      "    return request(\"post\", url, data=data, json=json, **kwargs)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/requests/api.py\", line 59, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/requests/sessions.py\", line 587, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/requests/sessions.py\", line 701, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/requests/adapters.py\", line 578, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "wandb.errors.CommError: HTTPSConnectionPool(host='api.wandb.ai', port=443): Read timed out. (read timeout=9)\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ConnectionError), entering retry loop.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s3a2_s3a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/yx22p40d\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_201650-yx22p40d/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 20:18:20,756][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s3a2_s4a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_201822-lpzk1l8q\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s3a2_s4a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/lpzk1l8q\u001b[0m\n",
      "[2023-08-08 20:18:28,604][root][INFO] - => Done in 7.848 s\n",
      "[2023-08-08 20:18:28,604][root][INFO] - \n",
      "[2023-08-08 20:18:28,604][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:18:28,610][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:18:28,610][root][INFO] - => Done in 5.499 ms\n",
      "[2023-08-08 20:18:28,610][root][INFO] - \n",
      "[2023-08-08 20:18:28,610][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:18:29,189][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:18:29,189][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:18:29,189][root][INFO] - => Done in 578.782 ms\n",
      "[2023-08-08 20:18:29,189][root][INFO] - \n",
      "[2023-08-08 20:18:29,189][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:18:29,189][root][INFO] - => Done in 115.871 us\n",
      "[2023-08-08 20:18:29,189][root][INFO] - \n",
      "[2023-08-08 20:18:29,189][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:18:29,189][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:18:29,962][root][INFO] - => Done in 772.597 ms\n",
      "[2023-08-08 20:18:29,962][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 0.941 MB of 0.953 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.99833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 4.94422\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.94476\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 1.97731\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 4.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.4975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s3a2_s4a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/lpzk1l8q\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_201822-lpzk1l8q/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 20:19:05,728][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s3a2_s5a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_201907-zb42f3h5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s3a2_s5a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/zb42f3h5\u001b[0m\n",
      "[2023-08-08 20:19:12,099][root][INFO] - => Done in 6.372 s\n",
      "[2023-08-08 20:19:12,100][root][INFO] - \n",
      "[2023-08-08 20:19:12,100][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:19:12,106][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:19:12,107][root][INFO] - => Done in 6.607 ms\n",
      "[2023-08-08 20:19:12,107][root][INFO] - \n",
      "[2023-08-08 20:19:12,107][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:19:12,687][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:19:12,688][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:19:12,688][root][INFO] - => Done in 581.084 ms\n",
      "[2023-08-08 20:19:12,688][root][INFO] - \n",
      "[2023-08-08 20:19:12,688][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:19:12,688][root][INFO] - => Done in 166.178 us\n",
      "[2023-08-08 20:19:12,688][root][INFO] - \n",
      "[2023-08-08 20:19:12,688][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:19:12,688][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:19:13,447][root][INFO] - => Done in 758.552 ms\n",
      "[2023-08-08 20:19:13,447][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.99833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 4.94264\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.94455\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 1.97561\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 4.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.4975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s3a2_s5a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/zb42f3h5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_201907-zb42f3h5/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 20:19:52,864][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s4a1_s1a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_201954-g89ot0y0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s4a1_s1a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/g89ot0y0\u001b[0m\n",
      "[2023-08-08 20:19:59,039][root][INFO] - => Done in 6.175 s\n",
      "[2023-08-08 20:19:59,040][root][INFO] - \n",
      "[2023-08-08 20:19:59,040][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:19:59,043][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:19:59,043][root][INFO] - => Done in 3.196 ms\n",
      "[2023-08-08 20:19:59,043][root][INFO] - \n",
      "[2023-08-08 20:19:59,043][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:19:59,604][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:19:59,604][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:19:59,604][root][INFO] - => Done in 560.965 ms\n",
      "[2023-08-08 20:19:59,604][root][INFO] - \n",
      "[2023-08-08 20:19:59,604][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:19:59,604][root][INFO] - => Done in 113.010 us\n",
      "[2023-08-08 20:19:59,604][root][INFO] - \n",
      "[2023-08-08 20:19:59,604][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:19:59,604][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:20:00,360][root][INFO] - => Done in 755.380 ms\n",
      "[2023-08-08 20:20:00,360][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 0.955 MB of 0.955 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–‚â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–‚â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–„â–„â–ƒâ–‚â–‚â–â–„â–‚â–„â–‚â–„â–‡â–‚â–…â–„â–„â–‚â–„â–‚â–‚â–„â–…â–ˆâ–„â–‡â–„â–…â–‡â–…â–„â–‚â–…â–…â–„â–…â–„â–‚â–‡â–‡â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–‚â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–„â–„â–ƒâ–‚â–‚â–â–„â–‚â–„â–‚â–„â–‡â–‚â–…â–„â–„â–‚â–„â–‚â–‚â–„â–…â–ˆâ–„â–‡â–„â–…â–‡â–…â–„â–‚â–…â–…â–„â–…â–„â–‚â–‡â–‡â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–‚â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.95633\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 4.88023\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.91725\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 1.9165\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 4.945\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.949\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.46\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.949\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.9795\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0105\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 1959.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 21.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.9795\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 1959\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s4a1_s1a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/g89ot0y0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_201954-g89ot0y0/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 20:20:35,770][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s4a1_s2a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_202037-ia7d8b6x\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s4a1_s2a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/ia7d8b6x\u001b[0m\n",
      "[2023-08-08 20:20:41,519][root][INFO] - => Done in 5.749 s\n",
      "[2023-08-08 20:20:41,519][root][INFO] - \n",
      "[2023-08-08 20:20:41,519][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:20:41,522][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:20:41,522][root][INFO] - => Done in 2.970 ms\n",
      "[2023-08-08 20:20:41,522][root][INFO] - \n",
      "[2023-08-08 20:20:41,522][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:20:42,110][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:20:42,110][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:20:42,111][root][INFO] - => Done in 588.104 ms\n",
      "[2023-08-08 20:20:42,111][root][INFO] - \n",
      "[2023-08-08 20:20:42,111][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:20:42,111][root][INFO] - => Done in 109.673 us\n",
      "[2023-08-08 20:20:42,111][root][INFO] - \n",
      "[2023-08-08 20:20:42,111][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:20:42,111][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:20:42,864][root][INFO] - => Done in 753.579 ms\n",
      "[2023-08-08 20:20:42,865][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 0.955 MB of 0.956 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.99833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 4.94383\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.94449\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 1.97779\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 4.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.4975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s4a1_s2a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/ia7d8b6x\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_202037-ia7d8b6x/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 20:21:19,013][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s4a1_s3a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_202120-a9xbx0hr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s4a1_s3a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/a9xbx0hr\u001b[0m\n",
      "[2023-08-08 20:21:25,122][root][INFO] - => Done in 6.109 s\n",
      "[2023-08-08 20:21:25,122][root][INFO] - \n",
      "[2023-08-08 20:21:25,122][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:21:25,125][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:21:25,126][root][INFO] - => Done in 3.091 ms\n",
      "[2023-08-08 20:21:25,126][root][INFO] - \n",
      "[2023-08-08 20:21:25,126][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:21:25,682][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:21:25,683][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:21:25,683][root][INFO] - => Done in 557.099 ms\n",
      "[2023-08-08 20:21:25,683][root][INFO] - \n",
      "[2023-08-08 20:21:25,683][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:21:25,683][root][INFO] - => Done in 114.918 us\n",
      "[2023-08-08 20:21:25,683][root][INFO] - \n",
      "[2023-08-08 20:21:25,683][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:21:25,683][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:21:26,439][root][INFO] - => Done in 755.570 ms\n",
      "[2023-08-08 20:21:26,439][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.945 MB of 0.953 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ƒâ–â–â–â–‚â–â–â–â–â–â–ˆâ–ˆâ–â–ˆâ–â–â–â–â–ˆâ–â–ˆâ–ˆâ–â–ˆâ–â–ˆâ–ˆâ–â–ˆâ–‚â–â–ˆâ–â–â–ˆâ–â–â–ˆâ–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ƒâ–â–â–â–‚â–â–â–â–â–â–ˆâ–ˆâ–â–ˆâ–â–â–â–â–ˆâ–â–ˆâ–ˆâ–â–ˆâ–â–ˆâ–ˆâ–â–ˆâ–‚â–â–ˆâ–â–â–ˆâ–â–â–ˆâ–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.99833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 4.93525\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.94084\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 1.96952\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 4.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.4975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s4a1_s3a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/a9xbx0hr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_202120-a9xbx0hr/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 20:46:13,494][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s4a1_s4a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_204615-c1ha0f51\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s4a1_s4a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/c1ha0f51\u001b[0m\n",
      "[2023-08-08 20:46:20,067][root][INFO] - => Done in 6.573 s\n",
      "[2023-08-08 20:46:20,067][root][INFO] - \n",
      "[2023-08-08 20:46:20,067][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:46:20,071][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:46:20,071][root][INFO] - => Done in 4.363 ms\n",
      "[2023-08-08 20:46:20,071][root][INFO] - \n",
      "[2023-08-08 20:46:20,071][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:46:20,723][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:46:20,723][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:46:20,723][root][INFO] - => Done in 652.094 ms\n",
      "[2023-08-08 20:46:20,723][root][INFO] - \n",
      "[2023-08-08 20:46:20,724][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:46:20,724][root][INFO] - => Done in 110.149 us\n",
      "[2023-08-08 20:46:20,724][root][INFO] - \n",
      "[2023-08-08 20:46:20,724][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:46:20,724][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:46:21,564][root][INFO] - => Done in 840.679 ms\n",
      "[2023-08-08 20:46:21,565][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 0.946 MB of 0.958 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.99833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 4.94374\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.9449\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 1.97738\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 4.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.4975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s4a1_s4a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/c1ha0f51\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_204615-c1ha0f51/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 20:46:57,769][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s4a1_s5a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_204658-tlovi4k0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s4a1_s5a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/tlovi4k0\u001b[0m\n",
      "[2023-08-08 20:47:02,794][root][INFO] - => Done in 5.024 s\n",
      "[2023-08-08 20:47:02,794][root][INFO] - \n",
      "[2023-08-08 20:47:02,794][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:47:02,797][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:47:02,797][root][INFO] - => Done in 3.074 ms\n",
      "[2023-08-08 20:47:02,797][root][INFO] - \n",
      "[2023-08-08 20:47:02,797][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:47:03,365][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:47:03,365][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:47:03,366][root][INFO] - => Done in 568.120 ms\n",
      "[2023-08-08 20:47:03,366][root][INFO] - \n",
      "[2023-08-08 20:47:03,366][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:47:03,366][root][INFO] - => Done in 127.077 us\n",
      "[2023-08-08 20:47:03,366][root][INFO] - \n",
      "[2023-08-08 20:47:03,366][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:47:03,366][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:47:04,143][root][INFO] - => Done in 776.781 ms\n",
      "[2023-08-08 20:47:04,143][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.99833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 4.94199\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.94452\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 1.97561\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 4.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.4975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s4a1_s5a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/tlovi4k0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_204658-tlovi4k0/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 20:47:38,424][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s5a1_s1a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_204739-1gsyr4eg\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s5a1_s1a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/1gsyr4eg\u001b[0m\n",
      "[2023-08-08 20:47:43,231][root][INFO] - => Done in 4.807 s\n",
      "[2023-08-08 20:47:43,231][root][INFO] - \n",
      "[2023-08-08 20:47:43,231][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:47:43,234][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:47:43,234][root][INFO] - => Done in 2.926 ms\n",
      "[2023-08-08 20:47:43,234][root][INFO] - \n",
      "[2023-08-08 20:47:43,234][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:47:43,816][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:47:43,816][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:47:43,816][root][INFO] - => Done in 582.051 ms\n",
      "[2023-08-08 20:47:43,816][root][INFO] - \n",
      "[2023-08-08 20:47:43,816][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:47:43,816][root][INFO] - => Done in 108.957 us\n",
      "[2023-08-08 20:47:43,816][root][INFO] - \n",
      "[2023-08-08 20:47:43,817][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:47:43,817][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:47:44,602][root][INFO] - => Done in 785.200 ms\n",
      "[2023-08-08 20:47:44,602][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–ˆâ–â–â–â–â–â–ˆâ–â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆï¿½ï¿½ï¿½\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–‚â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–ˆâ–â–â–â–â–â–ˆâ–â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–‚â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–ˆâ–â–â–â–â–â–ˆâ–â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–„â–„â–ƒâ–‚â–‚â–â–„â–‚â–„â–‚â–„â–‡â–‚â–…â–„â–„â–‚â–„â–‚â–‚â–„â–…â–ˆâ–„â–‡â–„â–…â–‡â–…â–„â–‚â–…â–…â–„â–…â–„â–‚â–‡â–‡â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–‚â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–ˆâ–â–â–â–â–â–ˆâ–â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–„â–„â–ƒâ–‚â–‚â–â–„â–‚â–„â–‚â–„â–‡â–‚â–…â–„â–„â–‚â–„â–‚â–‚â–„â–…â–ˆâ–„â–‡â–„â–…â–‡â–…â–„â–‚â–…â–…â–„â–…â–„â–‚â–‡â–‡â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–‚â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.95633\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 4.87853\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.91723\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 1.91657\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 4.945\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.949\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.46\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.949\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.9795\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0105\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 1959.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 21.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.9795\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 1959\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s5a1_s1a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/1gsyr4eg\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_204739-1gsyr4eg/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 20:48:18,618][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s5a1_s2a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_204819-i769bxo2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s5a1_s2a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/i769bxo2\u001b[0m\n",
      "[2023-08-08 20:48:23,676][root][INFO] - => Done in 5.058 s\n",
      "[2023-08-08 20:48:23,677][root][INFO] - \n",
      "[2023-08-08 20:48:23,677][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:48:23,679][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:48:23,679][root][INFO] - => Done in 2.902 ms\n",
      "[2023-08-08 20:48:23,680][root][INFO] - \n",
      "[2023-08-08 20:48:23,680][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:48:24,244][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:48:24,244][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:48:24,244][root][INFO] - => Done in 564.399 ms\n",
      "[2023-08-08 20:48:24,244][root][INFO] - \n",
      "[2023-08-08 20:48:24,244][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:48:24,244][root][INFO] - => Done in 108.957 us\n",
      "[2023-08-08 20:48:24,244][root][INFO] - \n",
      "[2023-08-08 20:48:24,244][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:48:24,244][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:48:25,012][root][INFO] - => Done in 767.994 ms\n",
      "[2023-08-08 20:48:25,013][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–ˆâ–â–â–â–â–â–ˆâ–â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–ˆâ–â–â–â–â–â–ˆâ–â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–ˆâ–â–â–â–â–â–ˆâ–â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–ˆâ–â–â–â–â–â–ˆâ–â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.99833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 4.94203\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.94432\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 1.97774\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 4.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.4975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s5a1_s2a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/i769bxo2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_204819-i769bxo2/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 20:49:01,456][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s5a1_s3a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_204902-rb3y7myy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s5a1_s3a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/rb3y7myy\u001b[0m\n",
      "[2023-08-08 20:49:07,610][root][INFO] - => Done in 6.154 s\n",
      "[2023-08-08 20:49:07,610][root][INFO] - \n",
      "[2023-08-08 20:49:07,610][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:49:07,615][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:49:07,616][root][INFO] - => Done in 5.434 ms\n",
      "[2023-08-08 20:49:07,616][root][INFO] - \n",
      "[2023-08-08 20:49:07,616][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:49:08,183][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:49:08,183][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:49:08,183][root][INFO] - => Done in 567.171 ms\n",
      "[2023-08-08 20:49:08,183][root][INFO] - \n",
      "[2023-08-08 20:49:08,183][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:49:08,183][root][INFO] - => Done in 111.103 us\n",
      "[2023-08-08 20:49:08,183][root][INFO] - \n",
      "[2023-08-08 20:49:08,183][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:49:08,183][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:49:08,945][root][INFO] - => Done in 761.746 ms\n",
      "[2023-08-08 20:49:08,945][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: | 0.951 MB of 0.963 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–ˆâ–â–â–â–â–â–ˆâ–â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–ˆâ–â–â–â–â–â–ˆâ–â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–ˆâ–â–â–â–â–â–ˆâ–â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ƒâ–â–â–â–‚â–â–â–â–â–â–ˆâ–ˆâ–â–ˆâ–â–â–â–â–ˆâ–â–ˆâ–ˆâ–â–ˆâ–â–ˆâ–ˆâ–â–ˆâ–â–â–ˆâ–â–â–ˆâ–â–â–ˆâ–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–ˆâ–â–â–â–â–â–ˆâ–â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ƒâ–â–â–â–‚â–â–â–â–â–â–ˆâ–ˆâ–â–ˆâ–â–â–â–â–ˆâ–â–ˆâ–ˆâ–â–ˆâ–â–ˆâ–ˆâ–â–ˆâ–â–â–ˆâ–â–â–ˆâ–â–â–ˆâ–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.99833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 4.93343\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.94068\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 1.96947\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 4.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.4975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s5a1_s3a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/rb3y7myy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_204902-rb3y7myy/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 20:49:45,639][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s5a1_s4a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_204946-5xo0rlbr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s5a1_s4a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/5xo0rlbr\u001b[0m\n",
      "[2023-08-08 20:49:51,188][root][INFO] - => Done in 5.549 s\n",
      "[2023-08-08 20:49:51,189][root][INFO] - \n",
      "[2023-08-08 20:49:51,189][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:49:51,194][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:49:51,194][root][INFO] - => Done in 5.015 ms\n",
      "[2023-08-08 20:49:51,194][root][INFO] - \n",
      "[2023-08-08 20:49:51,194][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:49:51,769][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:49:51,769][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:49:51,769][root][INFO] - => Done in 575.132 ms\n",
      "[2023-08-08 20:49:51,769][root][INFO] - \n",
      "[2023-08-08 20:49:51,769][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:49:51,769][root][INFO] - => Done in 114.918 us\n",
      "[2023-08-08 20:49:51,770][root][INFO] - \n",
      "[2023-08-08 20:49:51,770][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:49:51,770][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:49:52,533][root][INFO] - => Done in 763.221 ms\n",
      "[2023-08-08 20:49:52,533][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–ˆâ–â–â–â–â–â–ˆâ–â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–ˆâ–â–â–â–â–â–ˆâ–â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–ˆâ–â–â–â–â–â–ˆâ–â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–ˆâ–â–â–â–â–â–ˆâ–â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.99833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 4.94195\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.94475\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 1.97733\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 4.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.4975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s5a1_s4a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/5xo0rlbr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_204946-5xo0rlbr/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-08 20:50:28,187][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s5a1_s5a2_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230808_205029-m7sb7gh7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s5a1_s5a2_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/m7sb7gh7\u001b[0m\n",
      "[2023-08-08 20:50:34,041][root][INFO] - => Done in 5.853 s\n",
      "[2023-08-08 20:50:34,041][root][INFO] - \n",
      "[2023-08-08 20:50:34,041][root][INFO] - => Env setup ...\n",
      "[2023-08-08 20:50:34,048][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-08 20:50:34,048][root][INFO] - => Done in 7.313 ms\n",
      "[2023-08-08 20:50:34,049][root][INFO] - \n",
      "[2023-08-08 20:50:34,049][root][INFO] - => Agent setup ...\n",
      "[2023-08-08 20:50:34,618][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-08 20:50:34,618][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-08 20:50:34,618][root][INFO] - => Done in 569.468 ms\n",
      "[2023-08-08 20:50:34,618][root][INFO] - \n",
      "[2023-08-08 20:50:34,618][root][INFO] - => Watcher setup ...\n",
      "[2023-08-08 20:50:34,618][root][INFO] - => Done in 110.149 us\n",
      "[2023-08-08 20:50:34,618][root][INFO] - \n",
      "[2023-08-08 20:50:34,618][root][INFO] - => Runner setup ...\n",
      "[2023-08-08 20:50:34,619][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-08 20:50:35,381][root][INFO] - => Done in 762.939 ms\n",
      "[2023-08-08 20:50:35,382][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–ˆâ–â–â–â–â–â–ˆâ–â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–ˆâ–â–â–â–â–â–ˆâ–â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–ˆâ–â–â–â–â–â–ˆâ–â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–ˆâ–â–â–â–â–â–ˆâ–â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 3.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 4.94045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.94461\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 1.97566\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 5.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s5a1_s5a2_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/m7sb7gh7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230808_205029-m7sb7gh7/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# # they all did dcc or cdc so I expect the shapers to have two categories: mean and nice once\n",
    "\n",
    "import yaml\n",
    "game= \"tc\"\n",
    "num_pl = 3\n",
    "num_shap = 2\n",
    "\n",
    "mean = [(1,2),(2,1),(3,2),(4,1),(5,1)]\n",
    "nice = [(1,1), (2,2), (3,1),(4,2),(5,2)]\n",
    "\n",
    "# mean v mean\n",
    "for seed1,agent1 in mean:\n",
    "    for seed2,agent2 in mean:\n",
    "        ########## shaper1\n",
    "        yaml_f = f\"/Users/alexandrasouly/code/pax/pax/conf/experiment/multi-shapers/eval/n{num_pl}pl_{num_shap}shap_{game}_eval{seed1}.yaml\"\n",
    "        with open(yaml_f) as f:\n",
    "            config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        run_path1 = config[f'run_path{agent1}']\n",
    "        agent_path1 =   config[f'model_path{agent1}']\n",
    "        ########## shaper 2\n",
    "        yaml_f = f\"/Users/alexandrasouly/code/pax/pax/conf/experiment/multi-shapers/eval/n{num_pl}pl_{num_shap}shap_{game}_eval{seed2}.yaml\"\n",
    "        with open(yaml_f) as f:\n",
    "            config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        run_path2 = config[f'run_path{agent2}']\n",
    "        agent_path2 =   config[f'model_path{agent2}']\n",
    "        ############# run experiment\n",
    "        name = f\"{num_pl}pl_{num_shap}shap_{game}_s{seed1}a{agent1}_s{seed2}a{agent2}_eval\"\n",
    "        !/Users/alexandrasouly/miniconda3/envs/pax/bin/python3 -m pax.experiment +experiment=multi-shapers/comp/n{num_pl}pl_{num_shap}shap_{game}_comp_eval ++run_path1={run_path1} ++run_path2={run_path2} ++model_path1={agent_path1} ++model_path2={agent_path2} ++wandb.name={name} ++wandb.group='3pl_2shap_tc-comp-mean_v_mean'\n",
    "\n",
    "\n",
    "# nice v nice\n",
    "for seed1,agent1 in nice:\n",
    "    for seed2,agent2 in nice:\n",
    "        ########## shaper1\n",
    "        yaml_f = f\"/Users/alexandrasouly/code/pax/pax/conf/experiment/multi-shapers/eval/n{num_pl}pl_{num_shap}shap_{game}_eval{seed1}.yaml\"\n",
    "        with open(yaml_f) as f:\n",
    "            config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        run_path1 = config[f'run_path{agent1}']\n",
    "        agent_path1 =   config[f'model_path{agent1}']\n",
    "        ########## shaper 2\n",
    "        yaml_f = f\"/Users/alexandrasouly/code/pax/pax/conf/experiment/multi-shapers/eval/n{num_pl}pl_{num_shap}shap_{game}_eval{seed2}.yaml\"\n",
    "        with open(yaml_f) as f:\n",
    "            config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        run_path2 = config[f'run_path{agent2}']\n",
    "        agent_path2 =   config[f'model_path{agent2}']\n",
    "        ############# run experiment\n",
    "        name = f\"{num_pl}pl_{num_shap}shap_{game}_s{seed1}a{agent1}_s{seed2}a{agent2}_eval\"\n",
    "        !/Users/alexandrasouly/miniconda3/envs/pax/bin/python3 -m pax.experiment +experiment=multi-shapers/comp/n{num_pl}pl_{num_shap}shap_{game}_comp_eval ++run_path1={run_path1} ++run_path2={run_path2} ++model_path1={agent_path1} ++model_path2={agent_path2} ++wandb.name={name} ++wandb.group='3pl_2shap_tc-comp-nice_v_nice'\n",
    "\n",
    "# mean v nice\n",
    "for seed1,agent1 in mean:\n",
    "    for seed2,agent2 in nice:\n",
    "        ########## shaper1\n",
    "        yaml_f = f\"/Users/alexandrasouly/code/pax/pax/conf/experiment/multi-shapers/eval/n{num_pl}pl_{num_shap}shap_{game}_eval{seed1}.yaml\"\n",
    "        with open(yaml_f) as f:\n",
    "            config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        run_path1 = config[f'run_path{agent1}']\n",
    "        agent_path1 =   config[f'model_path{agent1}']\n",
    "        ########## shaper 2\n",
    "        yaml_f = f\"/Users/alexandrasouly/code/pax/pax/conf/experiment/multi-shapers/eval/n{num_pl}pl_{num_shap}shap_{game}_eval{seed2}.yaml\"\n",
    "        with open(yaml_f) as f:\n",
    "            config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        run_path2 = config[f'run_path{agent2}']\n",
    "        agent_path2 =   config[f'model_path{agent2}']\n",
    "        ############# run experiment\n",
    "        name = f\"{num_pl}pl_{num_shap}shap_{game}_s{seed1}a{agent1}_s{seed2}a{agent2}_eval\"\n",
    "        !/Users/alexandrasouly/miniconda3/envs/pax/bin/python3 -m pax.experiment +experiment=multi-shapers/comp/n{num_pl}pl_{num_shap}shap_{game}_comp_eval ++run_path1={run_path1} ++run_path2={run_path2} ++model_path1={agent_path1} ++model_path2={agent_path2} ++wandb.name={name} ++wandb.group='3pl_2shap_tc-comp-mean_v_nice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 08:56:43,832][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s1a2_s1a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_085645-m06fjzow\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s1a2_s1a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/m06fjzow\u001b[0m\n",
      "[2023-08-09 08:56:50,418][root][INFO] - => Done in 6.587 s\n",
      "[2023-08-09 08:56:50,419][root][INFO] - \n",
      "[2023-08-09 08:56:50,419][root][INFO] - => Env setup ...\n",
      "[2023-08-09 08:56:50,422][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 08:56:50,422][root][INFO] - => Done in 3.222 ms\n",
      "[2023-08-09 08:56:50,422][root][INFO] - \n",
      "[2023-08-09 08:56:50,422][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 08:56:51,142][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 08:56:51,143][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 08:56:51,143][root][INFO] - => Done in 720.664 ms\n",
      "[2023-08-09 08:56:51,143][root][INFO] - \n",
      "[2023-08-09 08:56:51,143][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 08:56:51,143][root][INFO] - => Done in 113.010 us\n",
      "[2023-08-09 08:56:51,143][root][INFO] - \n",
      "[2023-08-09 08:56:51,143][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 08:56:51,143][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 08:56:52,078][root][INFO] - => Done in 934.924 ms\n",
      "[2023-08-09 08:56:52,078][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: | 1.036 MB of 1.036 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01525\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.0152\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99244\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1979.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s1a2_s1a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/m06fjzow\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_085645-m06fjzow/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 08:57:30,523][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s2a2_s2a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_085731-y0lep3ac\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s2a2_s2a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/y0lep3ac\u001b[0m\n",
      "[2023-08-09 08:57:36,005][root][INFO] - => Done in 5.482 s\n",
      "[2023-08-09 08:57:36,005][root][INFO] - \n",
      "[2023-08-09 08:57:36,006][root][INFO] - => Env setup ...\n",
      "[2023-08-09 08:57:36,009][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 08:57:36,009][root][INFO] - => Done in 3.656 ms\n",
      "[2023-08-09 08:57:36,009][root][INFO] - \n",
      "[2023-08-09 08:57:36,009][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 08:57:36,832][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 08:57:36,833][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 08:57:36,833][root][INFO] - => Done in 823.364 ms\n",
      "[2023-08-09 08:57:36,833][root][INFO] - \n",
      "[2023-08-09 08:57:36,833][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 08:57:36,833][root][INFO] - => Done in 111.103 us\n",
      "[2023-08-09 08:57:36,833][root][INFO] - \n",
      "[2023-08-09 08:57:36,833][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 08:57:36,833][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 08:57:37,736][root][INFO] - => Done in 902.597 ms\n",
      "[2023-08-09 08:57:37,736][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 1.049 MB of 1.049 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01524\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01526\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99238\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1979.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s2a2_s2a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/y0lep3ac\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_085731-y0lep3ac/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 08:58:19,097][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s3a2_s3a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_085820-ell4qvr1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s3a2_s3a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/ell4qvr1\u001b[0m\n",
      "[2023-08-09 08:58:24,134][root][INFO] - => Done in 5.037 s\n",
      "[2023-08-09 08:58:24,134][root][INFO] - \n",
      "[2023-08-09 08:58:24,134][root][INFO] - => Env setup ...\n",
      "[2023-08-09 08:58:24,137][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 08:58:24,137][root][INFO] - => Done in 3.335 ms\n",
      "[2023-08-09 08:58:24,137][root][INFO] - \n",
      "[2023-08-09 08:58:24,137][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 08:58:24,799][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 08:58:24,799][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 08:58:24,799][root][INFO] - => Done in 662.200 ms\n",
      "[2023-08-09 08:58:24,800][root][INFO] - \n",
      "[2023-08-09 08:58:24,800][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 08:58:24,800][root][INFO] - => Done in 108.957 us\n",
      "[2023-08-09 08:58:24,800][root][INFO] - \n",
      "[2023-08-09 08:58:24,800][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 08:58:24,800][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 08:58:25,705][root][INFO] - => Done in 905.300 ms\n",
      "[2023-08-09 08:58:25,705][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 1.050 MB of 1.050 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01534\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01542\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99264\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 0.9995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1979.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.9895\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s3a2_s3a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/ell4qvr1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_085820-ell4qvr1/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 08:59:05,230][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s4a2_s4a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_085906-pc9qh8vk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s4a2_s4a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/pc9qh8vk\u001b[0m\n",
      "[2023-08-09 08:59:11,601][root][INFO] - => Done in 6.370 s\n",
      "[2023-08-09 08:59:11,601][root][INFO] - \n",
      "[2023-08-09 08:59:11,601][root][INFO] - => Env setup ...\n",
      "[2023-08-09 08:59:11,605][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 08:59:11,605][root][INFO] - => Done in 3.846 ms\n",
      "[2023-08-09 08:59:11,605][root][INFO] - \n",
      "[2023-08-09 08:59:11,605][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 08:59:12,279][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 08:59:12,279][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 08:59:12,279][root][INFO] - => Done in 673.750 ms\n",
      "[2023-08-09 08:59:12,279][root][INFO] - \n",
      "[2023-08-09 08:59:12,279][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 08:59:12,279][root][INFO] - => Done in 109.911 us\n",
      "[2023-08-09 08:59:12,279][root][INFO] - \n",
      "[2023-08-09 08:59:12,279][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 08:59:12,279][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 08:59:13,185][root][INFO] - => Done in 905.754 ms\n",
      "[2023-08-09 08:59:13,185][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01517\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.0155\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99262\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s4a2_s4a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/pc9qh8vk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_085906-pc9qh8vk/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 08:59:51,378][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_ipd_s5a2_s5a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_085952-uam9zirr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_ipd_s5a2_s5a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/uam9zirr\u001b[0m\n",
      "[2023-08-09 08:59:57,203][root][INFO] - => Done in 5.825 s\n",
      "[2023-08-09 08:59:57,203][root][INFO] - \n",
      "[2023-08-09 08:59:57,203][root][INFO] - => Env setup ...\n",
      "[2023-08-09 08:59:57,206][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 08:59:57,206][root][INFO] - => Done in 2.956 ms\n",
      "[2023-08-09 08:59:57,206][root][INFO] - \n",
      "[2023-08-09 08:59:57,206][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 08:59:57,862][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 08:59:57,862][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 08:59:57,863][root][INFO] - => Done in 656.611 ms\n",
      "[2023-08-09 08:59:57,863][root][INFO] - \n",
      "[2023-08-09 08:59:57,863][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 08:59:57,863][root][INFO] - => Done in 118.017 us\n",
      "[2023-08-09 08:59:57,863][root][INFO] - \n",
      "[2023-08-09 08:59:57,863][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 08:59:57,863][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 08:59:58,774][root][INFO] - => Done in 911.522 ms\n",
      "[2023-08-09 08:59:58,775][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.01516\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.01579\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 0.99303\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_ipd_s5a2_s5a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-ipd/runs/uam9zirr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_085952-uam9zirr/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# switch agents\n",
    "import yaml\n",
    "game= \"ipd\"\n",
    "num_pl = 3\n",
    "num_shap = 2\n",
    "\n",
    "# mean v mean\n",
    "for seed in range(1,6):\n",
    "    seed2=seed\n",
    "    seed1=seed\n",
    "    agent1=2\n",
    "    agent2=1\n",
    "\n",
    "    ########## shaper1\n",
    "    yaml_f = f\"/Users/alexandrasouly/code/pax/pax/conf/experiment/multi-shapers/eval/n{num_pl}pl_{num_shap}shap_{game}_eval{seed1}.yaml\"\n",
    "    with open(yaml_f) as f:\n",
    "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    run_path1 = config[f'run_path{agent1}']\n",
    "    agent_path1 =   config[f'model_path{agent1}']\n",
    "    ########## shaper 2\n",
    "    yaml_f = f\"/Users/alexandrasouly/code/pax/pax/conf/experiment/multi-shapers/eval/n{num_pl}pl_{num_shap}shap_{game}_eval{seed2}.yaml\"\n",
    "    with open(yaml_f) as f:\n",
    "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    run_path2 = config[f'run_path{agent2}']\n",
    "    agent_path2 =   config[f'model_path{agent2}']\n",
    "    ############# run experiment\n",
    "    name = f\"{num_pl}pl_{num_shap}shap_{game}_s{seed1}a{agent1}_s{seed2}a{agent2}_eval\"\n",
    "    group = f'{num_pl}pl_{num_shap}shap_{game}-comp-switch_agents'\n",
    "    !/Users/alexandrasouly/miniconda3/envs/pax/bin/python3 -m pax.experiment +experiment=multi-shapers/comp/n{num_pl}pl_{num_shap}shap_{game}_comp_eval ++run_path1={run_path1} ++run_path2={run_path2} ++model_path1={agent_path1} ++model_path2={agent_path2} ++wandb.name={name} ++wandb.group={group}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 09:00:38,209][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s1a2_s1a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_090039-qh03tm8b\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s1a2_s1a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/qh03tm8b\u001b[0m\n",
      "[2023-08-09 09:00:44,355][root][INFO] - => Done in 6.146 s\n",
      "[2023-08-09 09:00:44,356][root][INFO] - \n",
      "[2023-08-09 09:00:44,356][root][INFO] - => Env setup ...\n",
      "[2023-08-09 09:00:44,359][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 09:00:44,359][root][INFO] - => Done in 3.788 ms\n",
      "[2023-08-09 09:00:44,359][root][INFO] - \n",
      "[2023-08-09 09:00:44,360][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 09:00:45,013][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 09:00:45,013][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 09:00:45,013][root][INFO] - => Done in 653.375 ms\n",
      "[2023-08-09 09:00:45,013][root][INFO] - \n",
      "[2023-08-09 09:00:45,013][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 09:00:45,013][root][INFO] - => Done in 120.878 us\n",
      "[2023-08-09 09:00:45,013][root][INFO] - \n",
      "[2023-08-09 09:00:45,013][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 09:00:45,013][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 09:00:45,926][root][INFO] - => Done in 912.919 ms\n",
      "[2023-08-09 09:00:45,926][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 1.041 MB of 1.041 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–‚â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–‚â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–„â–„â–ƒâ–‚â–‚â–â–„â–‚â–„â–‚â–„â–‡â–‚â–…â–„â–„â–‚â–„â–‚â–‚â–„â–…â–ˆâ–„â–‡â–„â–…â–‡â–…â–„â–‚â–…â–…â–„â–…â–„â–‚â–‡â–‡â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–‚â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–„â–„â–ƒâ–‚â–‚â–â–„â–‚â–„â–‚â–„â–‡â–‚â–…â–„â–„â–‚â–„â–‚â–‚â–„â–…â–ˆâ–„â–‡â–„â–…â–‡â–…â–„â–‚â–…â–…â–„â–…â–„â–‚â–‡â–‡â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–‚â–ˆâ–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.95633\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 4.88074\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.91734\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 1.91653\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 4.945\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.949\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.46\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.949\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.9795\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0105\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 1959.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 21.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.9795\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 1959\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s1a2_s1a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/qh03tm8b\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_090039-qh03tm8b/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 09:01:25,478][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s2a2_s2a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_090126-3w47ak5c\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s2a2_s2a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/3w47ak5c\u001b[0m\n",
      "[2023-08-09 09:01:30,599][root][INFO] - => Done in 5.121 s\n",
      "[2023-08-09 09:01:30,599][root][INFO] - \n",
      "[2023-08-09 09:01:30,600][root][INFO] - => Env setup ...\n",
      "[2023-08-09 09:01:30,603][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 09:01:30,603][root][INFO] - => Done in 3.490 ms\n",
      "[2023-08-09 09:01:30,603][root][INFO] - \n",
      "[2023-08-09 09:01:30,603][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 09:01:31,263][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 09:01:31,263][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 09:01:31,263][root][INFO] - => Done in 660.025 ms\n",
      "[2023-08-09 09:01:31,263][root][INFO] - \n",
      "[2023-08-09 09:01:31,263][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 09:01:31,264][root][INFO] - => Done in 197.172 us\n",
      "[2023-08-09 09:01:31,264][root][INFO] - \n",
      "[2023-08-09 09:01:31,264][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 09:01:31,264][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 09:01:32,174][root][INFO] - => Done in 910.187 ms\n",
      "[2023-08-09 09:01:32,174][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–†â–†â–†â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–†â–…â–…â–†â–†â–‡â–†â–‡â–…â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–†â–‡â–†â–ˆâ–ˆâ–†â–‡â–‡â–ˆâ–‡â–†â–‡â–…â–‡â–ˆâ–‡â–†â–ˆâ–…â–†â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–†â–†â–†â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–†â–…â–…â–†â–†â–‡â–†â–‡â–…â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–†â–‡â–†â–ˆâ–ˆâ–†â–‡â–‡â–ˆâ–‡â–†â–‡â–…â–‡â–ˆâ–‡â–†â–ˆâ–…â–†â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–â–ƒâ–„â–†â–…â–…â–…â–†â–…â–ˆâ–…â–†â–†â–†â–†â–„â–†â–…â–‡â–…â–ˆâ–„â–„â–‡â–†â–†â–„â–…â–‡â–†â–‡â–†â–„â–†â–‡â–„â–ˆâ–‡â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–‡â–†â–ˆâ–†â–„â–†â–…â–„â–…â–…â–…â–‚â–â–ƒâ–ƒâ–‚â–ƒâ–‚â–‡â–‚â–„â–â–â–‚â–‚â–ƒâ–‚â–‚â–â–â–‚â–ƒâ–‚â–ƒâ–…â–…â–‚â–ƒâ–â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–â–ƒâ–„â–†â–…â–…â–…â–†â–…â–ˆâ–…â–†â–†â–†â–†â–„â–†â–…â–‡â–…â–ˆâ–„â–„â–‡â–†â–†â–„â–…â–‡â–†â–‡â–†â–„â–†â–‡â–„â–ˆâ–‡â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–‡â–†â–ˆâ–†â–„â–†â–…â–„â–…â–…â–…â–‚â–â–ƒâ–ƒâ–‚â–ƒâ–‚â–‡â–‚â–„â–â–â–‚â–‚â–ƒâ–‚â–‚â–â–â–‚â–ƒâ–‚â–ƒâ–…â–…â–‚â–ƒâ–â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–â–ƒâ–„â–†â–…â–…â–…â–†â–…â–ˆâ–…â–†â–†â–†â–†â–„â–†â–…â–‡â–…â–ˆâ–„â–„â–‡â–†â–†â–„â–…â–‡â–†â–‡â–†â–„â–†â–‡â–„â–ˆâ–‡â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–‡â–†â–ˆâ–†â–„â–†â–…â–„â–…â–…â–…â–‚â–â–ƒâ–ƒâ–‚â–ƒâ–‚â–‡â–‚â–„â–â–â–‚â–‚â–ƒâ–‚â–‚â–â–â–‚â–ƒâ–‚â–ƒâ–…â–…â–‚â–ƒâ–â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–â–ƒâ–„â–†â–…â–…â–…â–†â–…â–ˆâ–…â–†â–†â–†â–†â–„â–†â–…â–‡â–…â–ˆâ–„â–„â–‡â–†â–†â–„â–…â–‡â–†â–‡â–†â–„â–†â–‡â–„â–ˆâ–‡â–†â–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–‡â–†â–ˆâ–†â–„â–†â–…â–„â–…â–…â–…â–‚â–â–ƒâ–ƒâ–‚â–ƒâ–‚â–‡â–‚â–„â–â–â–‚â–‚â–ƒâ–‚â–‚â–â–â–‚â–ƒâ–‚â–ƒâ–…â–…â–‚â–ƒâ–â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.61583\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.74197\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 4.58268\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 1.67786\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.759\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 4.5175\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.571\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.13825\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.571\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.894\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0155\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.079\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 1788.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 31.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 158.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 3.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.894\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0155\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.079\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 1788\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 31\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 158\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s2a2_s2a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/3w47ak5c\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_090126-3w47ak5c/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 09:02:10,200][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s3a2_s3a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_090211-aod97xhk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s3a2_s3a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/aod97xhk\u001b[0m\n",
      "[2023-08-09 09:02:16,235][root][INFO] - => Done in 6.035 s\n",
      "[2023-08-09 09:02:16,235][root][INFO] - \n",
      "[2023-08-09 09:02:16,235][root][INFO] - => Env setup ...\n",
      "[2023-08-09 09:02:16,238][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 09:02:16,238][root][INFO] - => Done in 3.055 ms\n",
      "[2023-08-09 09:02:16,238][root][INFO] - \n",
      "[2023-08-09 09:02:16,238][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 09:02:16,872][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 09:02:16,873][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 09:02:16,873][root][INFO] - => Done in 634.615 ms\n",
      "[2023-08-09 09:02:16,873][root][INFO] - \n",
      "[2023-08-09 09:02:16,873][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 09:02:16,873][root][INFO] - => Done in 120.163 us\n",
      "[2023-08-09 09:02:16,873][root][INFO] - \n",
      "[2023-08-09 09:02:16,873][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 09:02:16,873][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 09:02:17,767][root][INFO] - => Done in 894.268 ms\n",
      "[2023-08-09 09:02:17,768][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: | 1.043 MB of 1.055 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ƒâ–â–â–â–‚â–â–â–â–â–â–ˆâ–ˆâ–â–ˆâ–â–â–â–â–ˆâ–â–ˆâ–ˆâ–â–ˆâ–â–ˆâ–ˆâ–â–ˆâ–â–â–ˆâ–â–â–ˆâ–â–â–ˆâ–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ƒâ–â–â–â–‚â–â–â–â–â–â–ˆâ–ˆâ–â–ˆâ–â–â–â–â–ˆâ–â–ˆâ–ˆâ–â–ˆâ–â–ˆâ–ˆâ–â–ˆâ–â–â–ˆâ–â–â–ˆâ–â–â–ˆâ–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.99833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 4.93592\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 1.94092\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 1.96952\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 4.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 1.9975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.4975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 2.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 1980.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.99\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 1980\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s3a2_s3a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/aod97xhk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_090211-aod97xhk/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 09:02:56,292][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s4a2_s4a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_090257-ibpoj3xx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s4a2_s4a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/ibpoj3xx\u001b[0m\n",
      "[2023-08-09 09:03:02,628][root][INFO] - => Done in 6.336 s\n",
      "[2023-08-09 09:03:02,629][root][INFO] - \n",
      "[2023-08-09 09:03:02,629][root][INFO] - => Env setup ...\n",
      "[2023-08-09 09:03:02,632][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 09:03:02,632][root][INFO] - => Done in 3.751 ms\n",
      "[2023-08-09 09:03:02,632][root][INFO] - \n",
      "[2023-08-09 09:03:02,633][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 09:03:03,299][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 09:03:03,300][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 09:03:03,300][root][INFO] - => Done in 667.143 ms\n",
      "[2023-08-09 09:03:03,300][root][INFO] - \n",
      "[2023-08-09 09:03:03,300][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 09:03:03,300][root][INFO] - => Done in 106.096 us\n",
      "[2023-08-09 09:03:03,300][root][INFO] - \n",
      "[2023-08-09 09:03:03,300][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 09:03:03,300][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 09:03:04,196][root][INFO] - => Done in 896.379 ms\n",
      "[2023-08-09 09:03:04,197][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–â–†â–†â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–…â–…â–…â–†â–†â–‡â–†â–‡â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–†â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–†â–‡â–†â–‡â–ˆâ–‡â–‡â–‡â–…â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–…â–…â–…â–†â–†â–‡â–†â–‡â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–†â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–†â–‡â–†â–‡â–ˆâ–‡â–‡â–‡â–…â–‡â–‡â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–…â–„â–…â–…â–„â–„â–ƒâ–†â–„â–‡â–„â–„â–„â–„â–„â–ƒâ–„â–ƒâ–†â–„â–†â–‚â–‚â–„â–‚â–„â–‚â–ƒâ–…â–ƒâ–†â–„â–â–„â–„â–ƒâ–ˆâ–„â–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–…â–„â–…â–…â–„â–„â–ƒâ–†â–„â–‡â–„â–„â–„â–„â–„â–ƒâ–„â–ƒâ–†â–„â–†â–‚â–‚â–„â–‚â–„â–‚â–ƒâ–…â–ƒâ–†â–„â–â–„â–„â–ƒâ–ˆâ–„â–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–…â–„â–…â–…â–„â–„â–ƒâ–†â–„â–‡â–„â–„â–„â–„â–„â–ƒâ–„â–ƒâ–†â–„â–†â–‚â–‚â–„â–‚â–„â–‚â–ƒâ–…â–ƒâ–†â–„â–â–„â–„â–ƒâ–ˆâ–„â–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–…â–„â–…â–…â–„â–„â–ƒâ–†â–„â–‡â–„â–„â–„â–„â–„â–ƒâ–„â–ƒâ–†â–„â–†â–‚â–‚â–„â–‚â–„â–‚â–ƒâ–…â–ƒâ–†â–„â–â–„â–„â–ƒâ–ˆâ–„â–ƒâ–ƒ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep 2.64683\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 1.80763\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 4.63606\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 1.68713\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 1.814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 4.5575\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 1.569\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep 3.18575\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep 1.569\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.902\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.0025\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.085\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 1804.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 5.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 170.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.902\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.0025\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.085\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 1804\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 170\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s4a2_s4a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/ibpoj3xx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_090257-ibpoj3xx/logs\u001b[0m\n",
      "/Users/alexandrasouly/code/pax/pax/experiment.py:774: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=\"conf\", config_name=\"config\")\n",
      "/Users/alexandrasouly/miniconda3/envs/pax/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[2023-08-09 09:03:43,339][root][INFO] - => Global setup ...\n",
      "name 3pl_2shap_tc_s5a2_s5a1_eval\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandrasouly\u001b[0m (\u001b[33mucl-dark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.8 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/alexandrasouly/code/pax/wandb/run-20230809_090344-ltlvez9d\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m3pl_2shap_tc_s5a2_s5a1_eval\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/ltlvez9d\u001b[0m\n",
      "[2023-08-09 09:03:48,337][root][INFO] - => Done in 4.998 s\n",
      "[2023-08-09 09:03:48,337][root][INFO] - \n",
      "[2023-08-09 09:03:48,337][root][INFO] - => Env setup ...\n",
      "[2023-08-09 09:03:48,340][root][INFO] - Env Type: meta s| Inner Episode Length: 100\n",
      "[2023-08-09 09:03:48,341][root][INFO] - => Done in 3.793 ms\n",
      "[2023-08-09 09:03:48,341][root][INFO] - \n",
      "[2023-08-09 09:03:48,341][root][INFO] - => Agent setup ...\n",
      "[2023-08-09 09:03:48,996][root][INFO] - Agent Pair: ['PPO_memory', 'PPO_memory', 'PPO_memory']\n",
      "[2023-08-09 09:03:48,996][root][INFO] - Agent seeds: [0, 1, 2]\n",
      "[2023-08-09 09:03:48,996][root][INFO] - => Done in 655.361 ms\n",
      "[2023-08-09 09:03:48,996][root][INFO] - \n",
      "[2023-08-09 09:03:48,996][root][INFO] - => Watcher setup ...\n",
      "[2023-08-09 09:03:48,996][root][INFO] - => Done in 142.097 us\n",
      "[2023-08-09 09:03:48,996][root][INFO] - \n",
      "[2023-08-09 09:03:48,996][root][INFO] - => Runner setup ...\n",
      "[2023-08-09 09:03:48,997][root][INFO] - Training with multishaper eval Runner\n",
      "[2023-08-09 09:03:49,908][root][INFO] - => Done in 911.286 ms\n",
      "[2023-08-09 09:03:49,908][root][INFO] - \n",
      "Number of Training Iterations: 1\n",
      "Training\n",
      "-----------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: - 1.058 MB of 1.058 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep â–â–„â–…â–…â–‚â–†â–ƒâ–â–‚â–ƒâ–‡â–„â–†â–ˆâ–‡â–…â–ƒâ–„â–‚â–†â–…â–…â–ƒâ–…â–ˆâ–†â–„â–‡â–…â–†â–…â–…â–„â–…â–†â–†â–…â–ˆâ–„â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 â–ˆâ–…â–…â–…â–â–†â–‚â–â–‚â–ƒâ–†â–„â–†â–‡â–‡â–„â–ƒâ–„â–â–…â–…â–„â–ƒâ–„â–‡â–†â–ƒâ–†â–…â–†â–…â–„â–‚â–…â–†â–…â–„â–‡â–ƒâ–†\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 â–ˆâ–ƒâ–â–â–‚â–â–‚â–â–‚â–â–â–‚â–â–â–â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–â–â–‚â–…â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 â–â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep â–ˆâ–„â–„â–„â–â–…â–‚â–â–‚â–‚â–…â–ƒâ–„â–…â–…â–ƒâ–‚â–ƒâ–â–„â–„â–ƒâ–ƒâ–ƒâ–†â–„â–ƒâ–…â–„â–„â–„â–ƒâ–ƒâ–„â–„â–„â–„â–…â–ƒâ–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep â–â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D â–ˆâ–ƒâ–â–â–‚â–â–ƒâ–‚â–‚â–â–â–‚â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–ƒâ–‚â–‚â–ƒâ–â–‚â–â–â–‚â–…â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D â–‚â–„â–„â–ƒâ–ˆâ–‚â–‡â–ˆâ–‡â–…â–‚â–…â–ƒâ–â–‚â–…â–†â–…â–‡â–ƒâ–„â–„â–†â–…â–â–ƒâ–†â–‚â–„â–‚â–ƒâ–„â–ˆâ–„â–ƒâ–ƒâ–…â–â–…â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D â–â–…â–†â–‡â–„â–‡â–…â–„â–…â–†â–‡â–†â–‡â–ˆâ–ˆâ–†â–†â–†â–…â–‡â–†â–†â–…â–…â–ˆâ–‡â–…â–‡â–‡â–‡â–‡â–†â–„â–†â–‡â–‡â–†â–ˆâ–…â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D â–ˆâ–ƒâ–â–â–‚â–â–ƒâ–‚â–‚â–â–â–‚â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–ƒâ–‚â–‚â–ƒâ–â–‚â–â–â–‚â–…â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D â–‚â–„â–„â–ƒâ–ˆâ–‚â–‡â–ˆâ–‡â–…â–‚â–…â–ƒâ–â–‚â–…â–†â–…â–‡â–ƒâ–„â–„â–†â–…â–â–ƒâ–†â–‚â–„â–‚â–ƒâ–„â–ˆâ–„â–ƒâ–ƒâ–…â–â–…â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D â–â–…â–†â–‡â–„â–‡â–…â–„â–…â–†â–‡â–†â–‡â–ˆâ–ˆâ–†â–†â–†â–…â–‡â–†â–†â–…â–…â–ˆâ–‡â–…â–‡â–‡â–‡â–‡â–†â–„â–†â–‡â–‡â–†â–ˆâ–…â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD â–â–â–â–â–…â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC â–ˆâ–ƒâ–â–â–‚â–â–‚â–‚â–‚â–â–â–‚â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–ƒâ–‚â–‚â–ƒâ–â–‚â–â–â–‚â–…â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD â–‚â–„â–„â–ƒâ–ˆâ–‚â–‡â–ˆâ–‡â–…â–‚â–…â–ƒâ–â–‚â–…â–†â–…â–‡â–ƒâ–„â–„â–†â–…â–â–ƒâ–†â–‚â–„â–‚â–ƒâ–„â–ˆâ–„â–ƒâ–ƒâ–…â–â–…â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD â–â–â–â–„â–…â–â–„â–…â–â–â–â–â–â–â–â–â–â–â–…â–â–ˆâ–â–â–â–â–…â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–…â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD â–â–…â–†â–‡â–„â–‡â–…â–„â–…â–†â–‡â–†â–‡â–ˆâ–ˆâ–†â–†â–†â–…â–‡â–†â–†â–…â–…â–ˆâ–‡â–…â–‡â–‡â–‡â–‡â–†â–„â–†â–‡â–‡â–†â–ˆâ–…â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD â–â–â–â–â–…â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC â–ˆâ–ƒâ–â–â–‚â–â–‚â–‚â–‚â–â–â–‚â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–ƒâ–‚â–‚â–ƒâ–â–‚â–â–â–‚â–…â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD â–‚â–„â–„â–ƒâ–ˆâ–‚â–‡â–ˆâ–‡â–…â–‚â–…â–ƒâ–â–‚â–…â–†â–…â–‡â–ƒâ–„â–„â–†â–…â–â–ƒâ–†â–‚â–„â–‚â–ƒâ–„â–ˆâ–„â–ƒâ–ƒâ–…â–â–…â–‚\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD â–â–â–â–„â–…â–â–„â–…â–â–â–â–â–â–â–â–â–â–â–…â–â–ˆâ–â–â–â–â–…â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–…â–…\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD â–â–…â–†â–‡â–„â–‡â–…â–„â–…â–†â–‡â–†â–‡â–ˆâ–ˆâ–†â–†â–†â–…â–‡â–†â–†â–…â–…â–ˆâ–‡â–…â–‡â–‡â–‡â–‡â–†â–„â–†â–‡â–‡â–†â–ˆâ–…â–‡\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                          episodes 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/global_welfare_per_timestep -0.119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper1 -0.46431\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/shaper2 0.03967\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/meta_reward/target1 -0.01922\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_1 -0.415\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/shaper_2 0.065\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: eval/reward_per_timestep/target_1 -0.007\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/shaper_welfare_per_timestep -0.175\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/target_welfare_per_timestep -0.007\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C1D 0.013\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/C2D 0.147\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D1D 0.011\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     grouped_state_probability/D2D 0.819\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   grouped_state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C1D 26.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/C2D 294.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D0D 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D1D 22.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      grouped_state_visitation/D2D 1638.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    grouped_state_visitation/START 20.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDC 0.013\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/CDD 0.147\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCC 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DCD 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDC 0.011\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             state_probability/DDD 0.819\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           state_probability/START 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDC 26\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/CDD 294\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCC 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DCD 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDC 22\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              state_visitation/DDD 1638\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            state_visitation/START 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   train_iteration 999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m3pl_2shap_tc_s5a2_s5a1_eval\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ucl-dark/tensor-tc/runs/ltlvez9d\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230809_090344-ltlvez9d/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# switch agents\n",
    "import yaml\n",
    "game= \"tc\"\n",
    "num_pl = 3\n",
    "num_shap = 2\n",
    "\n",
    "# mean v mean\n",
    "for seed in range(1,6):\n",
    "    seed2=seed\n",
    "    seed1=seed\n",
    "    agent1=2\n",
    "    agent2=1\n",
    "\n",
    "    ########## shaper1\n",
    "    yaml_f = f\"/Users/alexandrasouly/code/pax/pax/conf/experiment/multi-shapers/eval/n{num_pl}pl_{num_shap}shap_{game}_eval{seed1}.yaml\"\n",
    "    with open(yaml_f) as f:\n",
    "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    run_path1 = config[f'run_path{agent1}']\n",
    "    agent_path1 =   config[f'model_path{agent1}']\n",
    "    ########## shaper 2\n",
    "    yaml_f = f\"/Users/alexandrasouly/code/pax/pax/conf/experiment/multi-shapers/eval/n{num_pl}pl_{num_shap}shap_{game}_eval{seed2}.yaml\"\n",
    "    with open(yaml_f) as f:\n",
    "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    run_path2 = config[f'run_path{agent2}']\n",
    "    agent_path2 =   config[f'model_path{agent2}']\n",
    "    ############# run experiment\n",
    "    name = f\"{num_pl}pl_{num_shap}shap_{game}_s{seed1}a{agent1}_s{seed2}a{agent2}_eval\"\n",
    "    group = f'{num_pl}pl_{num_shap}shap_{game}-comp-switch_agents'\n",
    "    !/Users/alexandrasouly/miniconda3/envs/pax/bin/python3 -m pax.experiment +experiment=multi-shapers/comp/n{num_pl}pl_{num_shap}shap_{game}_comp_eval ++run_path1={run_path1} ++run_path2={run_path2} ++model_path1={agent_path1} ++model_path2={agent_path2} ++wandb.name={name} ++wandb.group={group}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
