hydra:
  run:
    dir: .
  sweep:
    dir: .
    subdir: .
  job_logging:
    root:
      level: INFO

# Global variables 
seed: 0
save_dir: "./exp/${wandb.group}/${wandb.name}"
save: True
save_interval: 100
debug: False

# Agents  
agent1: 'PPO'
agent2: 'PPO'

# Environment
env_id: ipd
env_type: coin_game
env_discount: 0.96
payoff: [[-1, -1], [-3, 0], [0, -3], [-2, -2]]

# Runner
runner: rl 

# Training hyperparameters
# env_batch_size = num_envs * num_opponents
num_envs: 100
num_generations: 100
num_opps: 1
num_steps: 16 # total number of steps per episode (this is num_inner_steps * num_outer_steps)
num_inner_steps: 16 # number of inner steps
total_timesteps: 1.0e8
eval_every: 1.0e8 # timesteps 

# Useful information
# num_episodes = total_timesteps / (num_steps * num_envs) 
# num_updates = num_episodes / eval_every
# train_batch_size = num_envs * num_opps * num_steps


# Logging setup
wandb:
  entity: "ucl-dark"
  project: ipd
  group: ??
  name: run-seed-${seed}
  log: True
