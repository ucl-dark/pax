method: random
metric:
  name: train/episode_reward/player_1
  goal: maximize
  
entity: "ucl-dark"
project: "cg"
parameters:
  ppo.num_minibatches:
    values: [1, 2, 4, 8]
  ppo.num_epochs:
    values: [1, 2, 4]
  ppo.ppo_clipping_epsilon:
    values: [0.2, 0.1, 0.5]
  ppo.value_coeff:
    values: [0.1, 0.5, 1, 2]
  ppo.gamma:
    values: [0.9, 0.96, 0.99]  
  ppo.learning_rate:
    values: [0.5, 0.05, 3e-4, 0.005, 0.001]
  ppo.entropy_coeff_start:
    values: [0.2, 0.1, 0.05]
  ppo.with_cnn:
    values: [True, False]
  ppo.separate:
    values: [True, False]
  num_envs:
    values: [5, 50, 100, 500, 1000, 4000]
  ppo.hidden:
    values: [5, 25, 50, 100, 150]
  ppo.output_channels:
    values: [1, 8, 16, 32]
command:
  - python3
  - -m
  - pax.experiment
  - +experiment=cg/sanity
  - ${args_no_hyphens}